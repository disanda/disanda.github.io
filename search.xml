<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[DCGAN的PyTorch实现]]></title>
    <url>%2F2019%2F11%2F08%2FAI%2FGAN%2F1.DCGAN%2F</url>
    <content type="text"><![CDATA[DCGAN1.什么是GANGAN是一个框架，让深度模型可以学习到数据的分布，从而通过数据的分布生成新的数据(服从同一分布)。 其由一个判别器和一个生成器构成，生成器负责生成“仿造数据”，判别器负责判断“仿造数据”的质量。两者一起进化，导致造假货和识别假货的两个模型G/D都能有超强的造假和识别假货的能力。 最终训练达到类似纳什均衡的平衡状态，就是分辨器已经分辨不出真假，其分别真假的成功率只有50%(和瞎猜没有区别)。 假设原数据分布为x(可以是一张真实图片等多维数据)，判别器D(),随机变量Z，生成器为G()。D(x)生成一个标量代表x来自真实分布的概率。Z是一个随机噪声，G(Z)代表随机噪声Z(也称为隐空间向量)到真实分布P_data的映射。G(Z)的生成数据的概率分布记作P_G. 所以D(G(z))就是一个标量代表其生成图片是真实图片的概率,同时D和G在玩一个你最小(G)我最大(D)的游戏。D想把自己分别真假图片x的成功率最大化 logD(x) G想把造假图片z和真实图片x的差距最小化 log(1-D(G(x))。 总目标函数(loss function)可以写成: 2.什么是DCGANDCGAN是GAN的一个扩展，卷积网络做判别器，反卷积做生成器。 判别器通过大幅步的卷积网络、批量正则化、LeakyRelu激活函数构成。输入一个364 64的图片，输出一个真假概率值。 生成器由一个反卷积网络、批量正则化、Relu激活函数构成，通过输入一个隐变量z(如标准正态分布)。同时输出一个364 64的图片。 同时《 Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks》的原作者还给出如何设置优化器(optimizers)，如何计算损失函数，如何初始化模型weights等技巧。 初始导入代码如下: 12345678910111213141516171819202122232425from __future__ import print_function#%matplotlib inlineimport argparseimport osimport randomimport torchimport torch.nn as nnimport torch.nn.parallelimport torch.backends.cudnn as cudnnimport torch.optim as optimimport torch.utils.dataimport torchvision.datasets as dsetimport torchvision.transforms as transformsimport torchvision.utils as vutilsimport numpy as npimport matplotlib.pyplot as pltimport matplotlib.animation as animationfrom IPython.display import HTML# Set random seed for reproducibilitymanualSeed = 999#manualSeed = random.randint(1, 10000) # use if you want new resultsprint("Random Seed: ", manualSeed)random.seed(manualSeed)torch.manual_seed(manualSeed) 3.输入设置输入参数设置 dataroot - the path to the root of the dataset folder. We will talk more about the dataset in the next section workers - the number of worker threads for loading the data with the DataLoader batch_size - the batch size used in training. The DCGAN paper uses a batch size of 128 image_size - the spatial size of the images used for training. This implementation defaults to 64x64. If another size is desired, the structures of D and G must be changed. nc - number of color channels in the input images. For color images this is 3 nz - length of latent vector ngf - relates to the depth of feature maps carried through the generator ndf - sets the depth of feature maps propagated through the discriminator num_epochs - number of training epochs to run. Training for longer will probably lead to better results but will also take much longer lr - learning rate for training. As described in the DCGAN paper, this number should be 0.0002 beta1 - beta1 hyperparameter for Adam optimizers. As described in paper, this number should be 0.5 ngpu - number of GPUs available. If this is 0, code will run in CPU mode. If this number is greater than 0 it will run on that number of GPUs 123456789101112131415161718192021222324252627282930313233343536# Root directory for datasetdataroot = "data/celeba"# Number of workers for dataloaderworkers = 2# Batch size during trainingbatch_size = 128# Spatial size of training images. All images will be resized to this# size using a transformer.image_size = 64# Number of channels in the training images. For color images this is 3nc = 3# Size of z latent vector (i.e. size of generator input)nz = 100# Size of feature maps in generatorngf = 64# Size of feature maps in discriminatorndf = 64# Number of training epochsnum_epochs = 5# Learning rate for optimizerslr = 0.0002# Beta1 hyperparam for Adam optimizersbeta1 = 0.5# Number of GPUs available. Use 0 for CPU mode.ngpu = 1 4.数据数据集用的是港中文的Celeb-A 12345678910111213141516171819202122232425262728# We can use an image folder dataset the way we have it setup.# Create the datasetdataset = dset.ImageFolder(root=dataroot, transform=transforms.Compose([ transforms.Resize(image_size), transforms.CenterCrop(image_size), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ]))# Create the dataloaderdataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers)# Decide which device we want to run ondevice = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu &gt; 0) else "cpu")# Plot some training imagesreal_batch = next(iter(dataloader))#real_batch是一个列表#第一个元素real_batch[0]是[128,3,64,64]的tensor，就是标准的一个batch的4D结构：128张图，3个通道，64长，64宽#第二个元素real_batch[1]是第一个元素的标签，有128个label值全为0plt.figure(figsize=(8,8))plt.axis("off")plt.title("Training Images")plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))#这个函数能让图片显示#plt.show() 5.实现(Implementation)5.1 参数初始化(Weight Initialization)w初始化为均值为0，标准差为0.02的正态分布 12345678# custom weights initialization called on netG and netDdef weights_init(m): classname = m.__class__.__name__ if classname.find('Conv') != -1: nn.init.normal_(m.weight.data, 0.0, 0.02) elif classname.find('BatchNorm') != -1: nn.init.normal_(m.weight.data, 1.0, 0.02) nn.init.constant_(m.bias.data, 0) 5.2 生成器(Generator)生成器G是构造一个由向量Z(隐空间)到真实数据空间的映射(map) nz=100,z输入时的长度 nc=3,输出时的chanel，彩色是RGB三通道 ngf=64,指的是生成的特征为64*64 反卷积的函数为: ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1) 参数为:1.输入、2.输出、3.核函数、4.卷积核步数、5.输入边填充、6.输出边填充、7.group、8.偏置、9.膨胀 123456789101112131415161718192021222324252627282930313233343536class Generator(nn.Module): def __init__(self, ngpu): super(Generator, self).__init__() self.ngpu = ngpu self.main = nn.Sequential( # input is Z, going into a convolution nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False), #输入100，输出64*8,核函数是4*4 nn.BatchNorm2d(ngf * 8), nn.ReLU(True), # state size. (ngf*8) x 4 x 4 nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(ngf * 4), nn.ReLU(True), # state size. (ngf*4) x 8 x 8 nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(ngf * 2), nn.ReLU(True), # state size. (ngf*2) x 16 x 16 nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False), nn.BatchNorm2d(ngf), nn.ReLU(True), # state size. (ngf) x 32 x 32 nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False), nn.Tanh() # state size. (nc) x 64 x 64 ) def forward(self, input): return self.main(input) 实例化生成器，初始化参数w 12345678910111213# Create the generatornetG = Generator(ngpu).to(device)# Handle multi-gpu if desiredif (device.type == 'cuda') and (ngpu &gt; 1): netG = nn.DataParallel(netG, list(range(ngpu)))# Apply the weights_init function to randomly initialize all weights# to mean=0, stdev=0.2.netG.apply(weights_init)# Print the modelprint(netG) out:123456789101112131415161718Generator( (main): Sequential( (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (5): ReLU(inplace=True) (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (8): ReLU(inplace=True) (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (11): ReLU(inplace=True) (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (13): Tanh() )) 5.3 判别器(Discriminator)判别器D是一个二元分类器，判别输入的图片真假。通过输入图片进入一连串的卷积层中，经过卷积(Strided Convolution)、批量正则(BatchNorm)、LeakyReLu激活，最终通过Sigmoid激活函数输出一个概率选择。 以上的结构如有必要可以扩展更多的层，不过DCGAN的设计者通过实验发现调整步幅的卷积层比池化的下采样效果要好，因为通过卷积网络可以学习到自己的池化函数。同时批量正则化和leakly relu函数都可以提高梯度下降的质量，这些效果在同时训练G和D时显得更为突出。 123456789101112131415161718192021222324252627class Discriminator(nn.Module): def __init__(self, ngpu): super(Discriminator, self).__init__() self.ngpu = ngpu self.main = nn.Sequential( # input is (nc) x 64 x 64 nn.Conv2d(nc, ndf, 4, 2, 1, bias=False), nn.LeakyReLU(0.2, inplace=True), # state size. (ndf) x 32 x 32 nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf * 2), nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*2) x 16 x 16 nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf * 4), nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*4) x 8 x 8 nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf * 8), nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*8) x 4 x 4 nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False), nn.Sigmoid() ) def forward(self, input): return self.main(input) 构建D，并初始化w方程，并且输出模型的结构。 12345678910111213# Create the DiscriminatornetD = Discriminator(ngpu).to(device)# Handle multi-gpu if desiredif (device.type == 'cuda') and (ngpu &gt; 1): netD = nn.DataParallel(netD, list(range(ngpu)))# Apply the weights_init function to randomly initialize all weights# to mean=0, stdev=0.2.netD.apply(weights_init)# Print the modelprint(netD) out: 1234567891011121314151617Discriminator( (main): Sequential( (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (1): LeakyReLU(negative_slope=0.2, inplace=True) (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (4): LeakyReLU(negative_slope=0.2, inplace=True) (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (7): LeakyReLU(negative_slope=0.2, inplace=True) (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (10): LeakyReLU(negative_slope=0.2, inplace=True) (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False) (12): Sigmoid() )) 5.4 损失函数&amp;优化器(loss&amp;optimizer)用Pytorch自带的损失函数Binary Corss Entropy(BCELoss),其定义如下： 我们定义真图片real为1，假图片fake为0。同时设置两个优化器optimizer。在本例中都是adam优化器，其学习率是0.0002且Beta1=0.5。为了保持生成学习的过程，我们从一个高斯分布中生成一个修正的批量数据。同时在训练过程中，我们定期放入修正的噪音给生成器G以提高拟合能力。 1234567891011121314# Initialize BCELoss functioncriterion = nn.BCELoss()# Create batch of latent vectors that we will use to visualize# the progression of the generatorfixed_noise = torch.randn(64, nz, 1, 1, device=device)# Establish convention for real and fake labels during trainingreal_label = 1fake_label = 0# Setup Adam optimizers for both G and DoptimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999)) 5.5 训练训练GAN是一种艺术，用不好超参数容易造成模式崩溃。我们通过D建立不同批次图片的真假差异，以及构建生成G函数以最大化logD(G(z))。 5.5.1 判别器D训练判别器D的目的是让D能最大化识别真假图片的概率，通过随机梯度上升(ascending its stochastic gradient SGD)更新判别器。在实践中就是最大化log(D(x))+log(1-D(G(z)))。 以上步骤分为两步实现，第一步是从训练数据集中拿出一批真实图片作为样本，通过模型D，计算其loss即损失函数log(D(x))，然后再通过反向传播计算梯度更新损失函数。 第二步是通过生成器建立一批假样本，也通过D进行前向传播得到另一半loss值。即损失函数log(1-D（G(z))的值，同时也通过反向传播更新loss，通过1个batches的迭代更新，我们称为一次D的优化(optimizer) 5.5.2 生成器G在GAN原始版本中G的实现是通过最小化log(1-D(G(z)))以增加更好的造假能力。值得注意的是原始版本并没有提供足够的梯度更新策略，特别在早期的训练学习过程中。作为修正，我们用最大化log(D(G(z)))来替代原先的策略。其中关键名词如下: Loss_D 计算所以批次的真假图片的判别函数，即loss= log(D(x))+log(D(G(Z)) Loss_G 生成图片的损失函数即log(D(G(z))) D(x) 输出真样本批次的为真概率，从一开始的1到理论上的拟合至0.5（即G训练好的时候） D(G(z)) 判别输出生成图片为真的概率，从一开始的0到理论上拟合至0.5(同为G训练好的时候) 训练时间和训练整体样本的次数(epoch)，和样本的大小有关,代码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081# Training Loop# Lists to keep track of progressimg_list = []G_losses = []D_losses = []iters = 0print("Starting Training Loop...")# For each epochfor epoch in range(num_epochs): # For each batch in the dataloader for i, data in enumerate(dataloader, 0): ############################ # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z))) ########################### ## Train with all-real batch netD.zero_grad() # Format batch real_cpu = data[0].to(device) b_size = real_cpu.size(0) label = torch.full((b_size,), real_label, device=device) # Forward pass real batch through D output = netD(real_cpu).view(-1) # Calculate loss on all-real batch errD_real = criterion(output, label) # Calculate gradients for D in backward pass errD_real.backward() D_x = output.mean().item() ## Train with all-fake batch # Generate batch of latent vectors noise = torch.randn(b_size, nz, 1, 1, device=device) # Generate fake image batch with G fake = netG(noise) label.fill_(fake_label) # Classify all fake batch with D output = netD(fake.detach()).view(-1) # Calculate D's loss on the all-fake batch errD_fake = criterion(output, label) # Calculate the gradients for this batch errD_fake.backward() D_G_z1 = output.mean().item() # Add the gradients from the all-real and all-fake batches errD = errD_real + errD_fake # Update D optimizerD.step() ############################ # (2) Update G network: maximize log(D(G(z))) ########################### netG.zero_grad() label.fill_(real_label) # fake labels are real for generator cost # Since we just updated D, perform another forward pass of all-fake batch through D output = netD(fake).view(-1) # Calculate G's loss based on this output errG = criterion(output, label) # Calculate gradients for G errG.backward() D_G_z2 = output.mean().item() # Update G optimizerG.step() # Output training stats if i % 50 == 0: print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f' % (epoch, num_epochs, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2)) # Save Losses for plotting later G_losses.append(errG.item()) D_losses.append(errD.item()) # Check how the generator is doing by saving G's output on fixed_noise if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)): with torch.no_grad(): fake = netG(fixed_noise).detach().cpu() img_list.append(vutils.make_grid(fake, padding=2, normalize=True)) iters += 1 out: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161Starting Training Loop...[0/5][0/1583] Loss_D: 2.0937 Loss_G: 5.2060 D(x): 0.5704 D(G(z)): 0.6680 / 0.0090[0/5][50/1583] Loss_D: 0.1916 Loss_G: 9.5846 D(x): 0.9472 D(G(z)): 0.0364 / 0.0002[0/5][100/1583] Loss_D: 4.0207 Loss_G: 21.2494 D(x): 0.2445 D(G(z)): 0.0000 / 0.0000[0/5][150/1583] Loss_D: 0.5569 Loss_G: 3.1977 D(x): 0.7294 D(G(z)): 0.0974 / 0.0609[0/5][200/1583] Loss_D: 0.2320 Loss_G: 3.3187 D(x): 0.9009 D(G(z)): 0.0805 / 0.0659[0/5][250/1583] Loss_D: 0.7203 Loss_G: 5.9229 D(x): 0.8500 D(G(z)): 0.3485 / 0.0062[0/5][300/1583] Loss_D: 0.6775 Loss_G: 4.0545 D(x): 0.8330 D(G(z)): 0.3379 / 0.0353[0/5][350/1583] Loss_D: 0.7549 Loss_G: 5.9064 D(x): 0.9227 D(G(z)): 0.4109 / 0.0084[0/5][400/1583] Loss_D: 1.0655 Loss_G: 2.5097 D(x): 0.4933 D(G(z)): 0.0269 / 0.1286[0/5][450/1583] Loss_D: 0.6321 Loss_G: 2.7811 D(x): 0.6453 D(G(z)): 0.0610 / 0.1026[0/5][500/1583] Loss_D: 0.5064 Loss_G: 4.1399 D(x): 0.9475 D(G(z)): 0.3009 / 0.0350[0/5][550/1583] Loss_D: 0.3838 Loss_G: 4.0321 D(x): 0.8221 D(G(z)): 0.1218 / 0.0331[0/5][600/1583] Loss_D: 0.5549 Loss_G: 4.6055 D(x): 0.8230 D(G(z)): 0.2049 / 0.0171[0/5][650/1583] Loss_D: 0.2821 Loss_G: 6.8137 D(x): 0.8276 D(G(z)): 0.0164 / 0.0027[0/5][700/1583] Loss_D: 0.6422 Loss_G: 5.0119 D(x): 0.8267 D(G(z)): 0.2827 / 0.0146[0/5][750/1583] Loss_D: 0.4332 Loss_G: 4.3659 D(x): 0.9239 D(G(z)): 0.2307 / 0.0291[0/5][800/1583] Loss_D: 0.5344 Loss_G: 3.4145 D(x): 0.7208 D(G(z)): 0.0891 / 0.0744[0/5][850/1583] Loss_D: 0.8094 Loss_G: 2.9318 D(x): 0.5903 D(G(z)): 0.0602 / 0.0979[0/5][900/1583] Loss_D: 0.1598 Loss_G: 6.4141 D(x): 0.9228 D(G(z)): 0.0630 / 0.0046[0/5][950/1583] Loss_D: 0.5083 Loss_G: 5.5467 D(x): 0.9226 D(G(z)): 0.2916 / 0.0112[0/5][1000/1583] Loss_D: 0.6738 Loss_G: 3.9958 D(x): 0.7622 D(G(z)): 0.2480 / 0.0410[0/5][1050/1583] Loss_D: 0.2155 Loss_G: 3.8838 D(x): 0.9092 D(G(z)): 0.0819 / 0.0432[0/5][1100/1583] Loss_D: 1.1708 Loss_G: 1.9610 D(x): 0.4709 D(G(z)): 0.0064 / 0.2448[0/5][1150/1583] Loss_D: 0.7506 Loss_G: 6.9292 D(x): 0.8797 D(G(z)): 0.3728 / 0.0019[0/5][1200/1583] Loss_D: 0.2133 Loss_G: 5.5082 D(x): 0.9436 D(G(z)): 0.1272 / 0.0102[0/5][1250/1583] Loss_D: 0.5156 Loss_G: 3.8660 D(x): 0.8073 D(G(z)): 0.1993 / 0.0357[0/5][1300/1583] Loss_D: 0.4848 Loss_G: 5.0770 D(x): 0.9170 D(G(z)): 0.2847 / 0.0109[0/5][1350/1583] Loss_D: 0.6596 Loss_G: 4.7626 D(x): 0.8414 D(G(z)): 0.3232 / 0.0145[0/5][1400/1583] Loss_D: 0.2799 Loss_G: 5.1604 D(x): 0.9154 D(G(z)): 0.1494 / 0.0156[0/5][1450/1583] Loss_D: 0.4756 Loss_G: 2.9344 D(x): 0.8164 D(G(z)): 0.1785 / 0.0955[0/5][1500/1583] Loss_D: 0.3904 Loss_G: 2.3755 D(x): 0.7652 D(G(z)): 0.0587 / 0.1328[0/5][1550/1583] Loss_D: 1.2817 Loss_G: 1.2689 D(x): 0.3769 D(G(z)): 0.0221 / 0.3693[1/5][0/1583] Loss_D: 0.5365 Loss_G: 3.0092 D(x): 0.7437 D(G(z)): 0.1574 / 0.0836[1/5][50/1583] Loss_D: 0.4959 Loss_G: 5.4086 D(x): 0.9422 D(G(z)): 0.2960 / 0.0086[1/5][100/1583] Loss_D: 0.2685 Loss_G: 3.6553 D(x): 0.8455 D(G(z)): 0.0640 / 0.0457[1/5][150/1583] Loss_D: 0.6243 Loss_G: 4.6128 D(x): 0.8467 D(G(z)): 0.2878 / 0.0203[1/5][200/1583] Loss_D: 0.4369 Loss_G: 2.8268 D(x): 0.7591 D(G(z)): 0.0871 / 0.0871[1/5][250/1583] Loss_D: 0.4244 Loss_G: 3.7669 D(x): 0.8641 D(G(z)): 0.1952 / 0.0369[1/5][300/1583] Loss_D: 0.7487 Loss_G: 2.5417 D(x): 0.6388 D(G(z)): 0.0948 / 0.1263[1/5][350/1583] Loss_D: 0.5359 Loss_G: 2.9435 D(x): 0.6996 D(G(z)): 0.0836 / 0.0864[1/5][400/1583] Loss_D: 0.3469 Loss_G: 2.7581 D(x): 0.8046 D(G(z)): 0.0755 / 0.1036[1/5][450/1583] Loss_D: 0.5065 Loss_G: 2.8547 D(x): 0.7491 D(G(z)): 0.1494 / 0.0879[1/5][500/1583] Loss_D: 0.3959 Loss_G: 3.3236 D(x): 0.8292 D(G(z)): 0.1328 / 0.0554[1/5][550/1583] Loss_D: 0.6679 Loss_G: 5.8782 D(x): 0.9178 D(G(z)): 0.3802 / 0.0075[1/5][600/1583] Loss_D: 0.8844 Loss_G: 1.9449 D(x): 0.5367 D(G(z)): 0.0326 / 0.1984[1/5][650/1583] Loss_D: 0.8474 Loss_G: 2.0978 D(x): 0.6395 D(G(z)): 0.1883 / 0.1803[1/5][700/1583] Loss_D: 0.4682 Loss_G: 5.1056 D(x): 0.8963 D(G(z)): 0.2520 / 0.0137[1/5][750/1583] Loss_D: 0.4315 Loss_G: 4.0099 D(x): 0.8957 D(G(z)): 0.2441 / 0.0304[1/5][800/1583] Loss_D: 0.4492 Loss_G: 4.1587 D(x): 0.9090 D(G(z)): 0.2656 / 0.0231[1/5][850/1583] Loss_D: 0.7694 Loss_G: 1.2065 D(x): 0.5726 D(G(z)): 0.0254 / 0.3785[1/5][900/1583] Loss_D: 0.3543 Loss_G: 4.0476 D(x): 0.8919 D(G(z)): 0.1873 / 0.0284[1/5][950/1583] Loss_D: 0.5111 Loss_G: 2.3574 D(x): 0.7082 D(G(z)): 0.0835 / 0.1288[1/5][1000/1583] Loss_D: 0.5802 Loss_G: 5.4608 D(x): 0.9395 D(G(z)): 0.3649 / 0.0077[1/5][1050/1583] Loss_D: 1.0051 Loss_G: 2.4068 D(x): 0.5352 D(G(z)): 0.0322 / 0.1486[1/5][1100/1583] Loss_D: 0.3509 Loss_G: 3.6524 D(x): 0.9101 D(G(z)): 0.2070 / 0.0387[1/5][1150/1583] Loss_D: 0.9412 Loss_G: 5.4059 D(x): 0.9597 D(G(z)): 0.5325 / 0.0080[1/5][1200/1583] Loss_D: 0.5332 Loss_G: 3.1298 D(x): 0.7943 D(G(z)): 0.2138 / 0.0630[1/5][1250/1583] Loss_D: 0.6025 Loss_G: 3.5758 D(x): 0.8679 D(G(z)): 0.3182 / 0.0428[1/5][1300/1583] Loss_D: 0.7154 Loss_G: 2.1555 D(x): 0.5657 D(G(z)): 0.0379 / 0.1685[1/5][1350/1583] Loss_D: 0.4168 Loss_G: 2.1878 D(x): 0.7452 D(G(z)): 0.0645 / 0.1534[1/5][1400/1583] Loss_D: 0.8991 Loss_G: 5.3523 D(x): 0.9256 D(G(z)): 0.4967 / 0.0074[1/5][1450/1583] Loss_D: 0.4778 Loss_G: 3.8499 D(x): 0.8844 D(G(z)): 0.2655 / 0.0350[1/5][1500/1583] Loss_D: 0.5049 Loss_G: 2.5450 D(x): 0.7880 D(G(z)): 0.1906 / 0.1010[1/5][1550/1583] Loss_D: 1.0468 Loss_G: 1.9007 D(x): 0.4378 D(G(z)): 0.0346 / 0.2260[2/5][0/1583] Loss_D: 0.5008 Loss_G: 3.5294 D(x): 0.9006 D(G(z)): 0.2844 / 0.0466[2/5][50/1583] Loss_D: 0.5024 Loss_G: 2.3252 D(x): 0.7413 D(G(z)): 0.1450 / 0.1267[2/5][100/1583] Loss_D: 0.7520 Loss_G: 2.0230 D(x): 0.5753 D(G(z)): 0.0835 / 0.1797[2/5][150/1583] Loss_D: 0.3734 Loss_G: 2.7221 D(x): 0.8502 D(G(z)): 0.1689 / 0.0889[2/5][200/1583] Loss_D: 0.5891 Loss_G: 2.6314 D(x): 0.7453 D(G(z)): 0.2076 / 0.1032[2/5][250/1583] Loss_D: 1.1471 Loss_G: 3.5814 D(x): 0.8959 D(G(z)): 0.5563 / 0.0545[2/5][300/1583] Loss_D: 0.5756 Loss_G: 3.1905 D(x): 0.8738 D(G(z)): 0.3128 / 0.0605[2/5][350/1583] Loss_D: 0.5971 Loss_G: 2.9928 D(x): 0.8177 D(G(z)): 0.2657 / 0.0739[2/5][400/1583] Loss_D: 0.6856 Loss_G: 3.8514 D(x): 0.8880 D(G(z)): 0.3835 / 0.0298[2/5][450/1583] Loss_D: 0.6088 Loss_G: 1.7919 D(x): 0.6660 D(G(z)): 0.1227 / 0.2189[2/5][500/1583] Loss_D: 0.7147 Loss_G: 2.6453 D(x): 0.8321 D(G(z)): 0.3531 / 0.1007[2/5][550/1583] Loss_D: 0.5759 Loss_G: 2.9074 D(x): 0.8269 D(G(z)): 0.2833 / 0.0738[2/5][600/1583] Loss_D: 0.5678 Loss_G: 2.6149 D(x): 0.7928 D(G(z)): 0.2516 / 0.0956[2/5][650/1583] Loss_D: 0.9501 Loss_G: 1.1814 D(x): 0.5916 D(G(z)): 0.2322 / 0.3815[2/5][700/1583] Loss_D: 0.4551 Loss_G: 2.5074 D(x): 0.8331 D(G(z)): 0.2047 / 0.1129[2/5][750/1583] Loss_D: 0.4560 Loss_G: 2.3947 D(x): 0.7525 D(G(z)): 0.1240 / 0.1147[2/5][800/1583] Loss_D: 1.1853 Loss_G: 5.1657 D(x): 0.9202 D(G(z)): 0.6049 / 0.0091[2/5][850/1583] Loss_D: 0.5514 Loss_G: 3.0085 D(x): 0.8497 D(G(z)): 0.2890 / 0.0685[2/5][900/1583] Loss_D: 0.6882 Loss_G: 1.8971 D(x): 0.6970 D(G(z)): 0.2332 / 0.1909[2/5][950/1583] Loss_D: 1.1220 Loss_G: 0.7904 D(x): 0.4095 D(G(z)): 0.0570 / 0.4975[2/5][1000/1583] Loss_D: 1.3335 Loss_G: 0.3115 D(x): 0.3347 D(G(z)): 0.0262 / 0.7661[2/5][1050/1583] Loss_D: 1.7281 Loss_G: 0.8212 D(x): 0.2437 D(G(z)): 0.0261 / 0.5179[2/5][1100/1583] Loss_D: 0.9401 Loss_G: 3.7894 D(x): 0.9033 D(G(z)): 0.5104 / 0.0349[2/5][1150/1583] Loss_D: 0.8078 Loss_G: 3.9862 D(x): 0.9178 D(G(z)): 0.4608 / 0.0286[2/5][1200/1583] Loss_D: 0.5182 Loss_G: 3.1859 D(x): 0.8568 D(G(z)): 0.2787 / 0.0554[2/5][1250/1583] Loss_D: 0.5092 Loss_G: 2.3530 D(x): 0.8015 D(G(z)): 0.2122 / 0.1188[2/5][1300/1583] Loss_D: 1.2668 Loss_G: 0.5543 D(x): 0.3424 D(G(z)): 0.0165 / 0.6271[2/5][1350/1583] Loss_D: 0.7197 Loss_G: 3.8595 D(x): 0.9043 D(G(z)): 0.4208 / 0.0299[2/5][1400/1583] Loss_D: 0.5428 Loss_G: 2.6526 D(x): 0.8873 D(G(z)): 0.3056 / 0.0961[2/5][1450/1583] Loss_D: 0.6610 Loss_G: 4.2385 D(x): 0.9272 D(G(z)): 0.3985 / 0.0211[2/5][1500/1583] Loss_D: 0.8172 Loss_G: 3.2164 D(x): 0.8811 D(G(z)): 0.4422 / 0.0612[2/5][1550/1583] Loss_D: 0.6449 Loss_G: 3.8452 D(x): 0.9130 D(G(z)): 0.3813 / 0.0325[3/5][0/1583] Loss_D: 0.7677 Loss_G: 1.7745 D(x): 0.5928 D(G(z)): 0.1388 / 0.2182[3/5][50/1583] Loss_D: 0.7981 Loss_G: 2.9624 D(x): 0.8315 D(G(z)): 0.4131 / 0.0735[3/5][100/1583] Loss_D: 0.5679 Loss_G: 1.8958 D(x): 0.7173 D(G(z)): 0.1667 / 0.1914[3/5][150/1583] Loss_D: 0.8576 Loss_G: 1.5904 D(x): 0.5391 D(G(z)): 0.1158 / 0.2699[3/5][200/1583] Loss_D: 0.8644 Loss_G: 1.6487 D(x): 0.5868 D(G(z)): 0.1933 / 0.2319[3/5][250/1583] Loss_D: 0.5331 Loss_G: 3.0401 D(x): 0.8831 D(G(z)): 0.3022 / 0.0608[3/5][300/1583] Loss_D: 1.2449 Loss_G: 2.9489 D(x): 0.8759 D(G(z)): 0.5865 / 0.0828[3/5][350/1583] Loss_D: 1.7188 Loss_G: 0.5466 D(x): 0.2664 D(G(z)): 0.0539 / 0.6320[3/5][400/1583] Loss_D: 0.5794 Loss_G: 2.7556 D(x): 0.7984 D(G(z)): 0.2640 / 0.0787[3/5][450/1583] Loss_D: 0.6916 Loss_G: 3.1434 D(x): 0.8813 D(G(z)): 0.3955 / 0.0578[3/5][500/1583] Loss_D: 0.8415 Loss_G: 1.9770 D(x): 0.6981 D(G(z)): 0.3120 / 0.1639[3/5][550/1583] Loss_D: 0.6394 Loss_G: 2.4790 D(x): 0.8093 D(G(z)): 0.2990 / 0.1082[3/5][600/1583] Loss_D: 0.7545 Loss_G: 1.6259 D(x): 0.6042 D(G(z)): 0.1454 / 0.2401[3/5][650/1583] Loss_D: 0.5494 Loss_G: 2.1957 D(x): 0.8292 D(G(z)): 0.2727 / 0.1414[3/5][700/1583] Loss_D: 1.5095 Loss_G: 5.1368 D(x): 0.9269 D(G(z)): 0.6897 / 0.0095[3/5][750/1583] Loss_D: 0.4714 Loss_G: 2.1401 D(x): 0.8137 D(G(z)): 0.2101 / 0.1501[3/5][800/1583] Loss_D: 0.7118 Loss_G: 3.2356 D(x): 0.8190 D(G(z)): 0.3579 / 0.0540[3/5][850/1583] Loss_D: 0.6392 Loss_G: 1.6740 D(x): 0.6650 D(G(z)): 0.1402 / 0.2391[3/5][900/1583] Loss_D: 0.5303 Loss_G: 2.8854 D(x): 0.7900 D(G(z)): 0.2204 / 0.0740[3/5][950/1583] Loss_D: 0.6333 Loss_G: 2.1030 D(x): 0.6946 D(G(z)): 0.1882 / 0.1572[3/5][1000/1583] Loss_D: 0.8715 Loss_G: 1.6630 D(x): 0.5222 D(G(z)): 0.0890 / 0.2590[3/5][1050/1583] Loss_D: 0.6139 Loss_G: 3.1772 D(x): 0.8609 D(G(z)): 0.3400 / 0.0558[3/5][1100/1583] Loss_D: 0.6673 Loss_G: 3.4143 D(x): 0.9044 D(G(z)): 0.3910 / 0.0435[3/5][1150/1583] Loss_D: 0.6554 Loss_G: 3.4282 D(x): 0.8429 D(G(z)): 0.3347 / 0.0484[3/5][1200/1583] Loss_D: 0.6184 Loss_G: 1.7371 D(x): 0.6531 D(G(z)): 0.1177 / 0.2132[3/5][1250/1583] Loss_D: 0.8293 Loss_G: 3.1246 D(x): 0.7821 D(G(z)): 0.3883 / 0.0594[3/5][1300/1583] Loss_D: 0.5211 Loss_G: 2.0112 D(x): 0.7308 D(G(z)): 0.1503 / 0.1637[3/5][1350/1583] Loss_D: 0.7389 Loss_G: 1.4238 D(x): 0.5854 D(G(z)): 0.1181 / 0.2935[3/5][1400/1583] Loss_D: 0.6608 Loss_G: 3.1928 D(x): 0.7803 D(G(z)): 0.2922 / 0.0580[3/5][1450/1583] Loss_D: 0.6381 Loss_G: 3.4123 D(x): 0.8340 D(G(z)): 0.3337 / 0.0450[3/5][1500/1583] Loss_D: 0.7027 Loss_G: 3.1943 D(x): 0.9058 D(G(z)): 0.4113 / 0.0556[3/5][1550/1583] Loss_D: 0.6849 Loss_G: 2.9714 D(x): 0.8258 D(G(z)): 0.3499 / 0.0704[4/5][0/1583] Loss_D: 0.7685 Loss_G: 1.7204 D(x): 0.5788 D(G(z)): 0.1084 / 0.2252[4/5][50/1583] Loss_D: 0.6194 Loss_G: 1.4702 D(x): 0.6214 D(G(z)): 0.0700 / 0.2812[4/5][100/1583] Loss_D: 0.5243 Loss_G: 2.4332 D(x): 0.8206 D(G(z)): 0.2515 / 0.1099[4/5][150/1583] Loss_D: 0.8506 Loss_G: 1.0129 D(x): 0.5094 D(G(z)): 0.0647 / 0.4126[4/5][200/1583] Loss_D: 1.1715 Loss_G: 2.5120 D(x): 0.5642 D(G(z)): 0.3481 / 0.1214[4/5][250/1583] Loss_D: 0.4317 Loss_G: 2.7731 D(x): 0.8405 D(G(z)): 0.2088 / 0.0791[4/5][300/1583] Loss_D: 1.2310 Loss_G: 0.4177 D(x): 0.3812 D(G(z)): 0.0576 / 0.6799[4/5][350/1583] Loss_D: 0.5565 Loss_G: 2.7405 D(x): 0.8525 D(G(z)): 0.3005 / 0.0810[4/5][400/1583] Loss_D: 0.4918 Loss_G: 3.5705 D(x): 0.8863 D(G(z)): 0.2833 / 0.0371[4/5][450/1583] Loss_D: 0.6403 Loss_G: 2.7691 D(x): 0.8543 D(G(z)): 0.3406 / 0.0812[4/5][500/1583] Loss_D: 0.5944 Loss_G: 1.4696 D(x): 0.6849 D(G(z)): 0.1325 / 0.2682[4/5][550/1583] Loss_D: 0.8678 Loss_G: 4.1990 D(x): 0.9529 D(G(z)): 0.5105 / 0.0202[4/5][600/1583] Loss_D: 0.8326 Loss_G: 1.1841 D(x): 0.5175 D(G(z)): 0.0679 / 0.3628[4/5][650/1583] Loss_D: 0.5198 Loss_G: 2.4393 D(x): 0.7668 D(G(z)): 0.1943 / 0.1148[4/5][700/1583] Loss_D: 0.8029 Loss_G: 4.0836 D(x): 0.8791 D(G(z)): 0.4448 / 0.0229[4/5][750/1583] Loss_D: 0.8636 Loss_G: 2.0386 D(x): 0.5234 D(G(z)): 0.0899 / 0.1846[4/5][800/1583] Loss_D: 0.5041 Loss_G: 3.0354 D(x): 0.8302 D(G(z)): 0.2301 / 0.0609[4/5][850/1583] Loss_D: 0.7514 Loss_G: 1.2513 D(x): 0.5578 D(G(z)): 0.0899 / 0.3480[4/5][900/1583] Loss_D: 0.6650 Loss_G: 1.2806 D(x): 0.6675 D(G(z)): 0.1925 / 0.3201[4/5][950/1583] Loss_D: 0.5754 Loss_G: 3.0898 D(x): 0.8730 D(G(z)): 0.3233 / 0.0597[4/5][1000/1583] Loss_D: 0.9327 Loss_G: 0.7588 D(x): 0.4674 D(G(z)): 0.0434 / 0.5174[4/5][1050/1583] Loss_D: 0.9255 Loss_G: 0.9513 D(x): 0.5029 D(G(z)): 0.1161 / 0.4196[4/5][1100/1583] Loss_D: 0.6573 Loss_G: 3.4663 D(x): 0.8755 D(G(z)): 0.3674 / 0.0403[4/5][1150/1583] Loss_D: 0.9803 Loss_G: 1.2451 D(x): 0.4602 D(G(z)): 0.0978 / 0.3432[4/5][1200/1583] Loss_D: 0.5560 Loss_G: 2.5421 D(x): 0.7617 D(G(z)): 0.2097 / 0.1020[4/5][1250/1583] Loss_D: 0.7573 Loss_G: 1.9034 D(x): 0.6477 D(G(z)): 0.2158 / 0.1890[4/5][1300/1583] Loss_D: 0.4733 Loss_G: 2.7071 D(x): 0.8271 D(G(z)): 0.2169 / 0.0882[4/5][1350/1583] Loss_D: 1.0812 Loss_G: 1.1500 D(x): 0.5225 D(G(z)): 0.2278 / 0.3626[4/5][1400/1583] Loss_D: 1.5454 Loss_G: 5.2881 D(x): 0.9620 D(G(z)): 0.7085 / 0.0089[4/5][1450/1583] Loss_D: 0.3576 Loss_G: 3.1023 D(x): 0.8687 D(G(z)): 0.1726 / 0.0584[4/5][1500/1583] Loss_D: 0.5330 Loss_G: 1.9979 D(x): 0.7277 D(G(z)): 0.1597 / 0.1680[4/5][1550/1583] Loss_D: 0.8927 Loss_G: 4.1379 D(x): 0.9345 D(G(z)): 0.5081 / 0.0224 5.6 结果从三个不同方面看实验结果: 看G和D两个损失函数的变化 看每轮epoch训练G生成图片的结果 对比一批生成图片和一批真实图片(64张) a.loss变化 12345678plt.figure(figsize=(10,5))plt.title("Generator and Discriminator Loss During Training")plt.plot(G_losses,label="G")plt.plot(D_losses,label="D")plt.xlabel("iterations")plt.ylabel("Loss")plt.legend()plt.show() b.图片生成变化 1234567#%%capturefig = plt.figure(figsize=(8,8))plt.axis("off")ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)HTML(ani.to_jshtml()) c.对比真假图片 12345678910111213141516# Grab a batch of real images from the dataloaderreal_batch = next(iter(dataloader))# Plot the real imagesplt.figure(figsize=(15,15))plt.subplot(1,2,1)plt.axis("off")plt.title("Real Images")plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))# Plot the fake images from the last epochplt.subplot(1,2,2)plt.axis("off")plt.title("Fake Images")plt.imshow(np.transpose(img_list[-1],(1,2,0)))plt.show() 6.下一步 Train for longer to see how good the results get 多训练几次，如增加epoch看效果 Modify this model to take a different dataset and possibly change the size of the images and the model architecture 换其他数据集、或者调整一些模型结构 Check out some other cool GAN projects here 试试其他有趣的GAN应用—https://github.com/nashory/gans-awesome-applications Create GANs that generate music 用GAN生成音乐 7.参考:https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html# https://github.com/soumith/ganhacks#authors]]></content>
      <categories>
        <category>AI</category>
        <category>GAN</category>
      </categories>
      <tags>
        <tag>GAN</tag>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow 1.简介]]></title>
    <url>%2F2019%2F06%2F02%2FAI%2Ftf%2F1.tf%2F</url>
    <content type="text"><![CDATA[TensorFlow基础介绍 1.基本结构 计算图graph 表示计算任务 会话Session 表示执行计算图的上下文，执行时需要初始化所有变量(initializer)，会话完成时需要关闭(sess.close) 张量(Tensor) 表示数据，图中的线条。包括常量constant,变量variable,以及通过占位符(placeholder),其中占位符只在运行时才放入具体的值 操作(op) 图中的节点,构建图包括构建数据(因为本身不保存数据)和完成计算，因此定义一个Tensor也是一个计算。 2.代码及运行方式 tf本身不完成运算，而是定义图来描述计算，把计算放在Python之外进行以提高计算效率 2.1 Tensor(张量)张量是tensorflow里面的数据结构，可分为常量和变量，所有的数据都通过张量来表示，可以简短理解为多维数组。那么0阶张量表示一个数，1阶张量表示一个向量(即一维数组)，n阶张量表示n维数组。 张量主要保存了三个属性:1.名字，2.维度，3.类型 张量中并不是直接保存数据，而是保存数据的计算过程。如下： 12345678import tensorflow as tfa = tf.constant([1.0,2.0],name='a')b = tf.constant([2.0,3.0],name='b')result = tf.ddd(a,b,name="add")print(result)#输出结果为:#&lt;tf.Tensor 'add:0' shape=(2,) dtype=float32&gt; 123456import tensorflow as tfa = tf.constant([1.0,2,0],name='a')#定义常量ab = tf.constant([2.0,3.0],name='b')#定义常量bresult = tf.add(a,b,name='add')print(result) 变量 变量的声明函数tf.Variable()是一个运算，是一种特殊的张量 神经网络中的参数是神经网络实现分类或者回归问题中的重要部分，变量的作用就是保存和更新神经网络中的参数(边)。 tf.Variable是一个运算，运算的输出结果是一个张量，所以变量是一种特殊的张量。 定义一个2*3矩阵变量(元素值默认为0，标准差为2的随机数): weights=tf.Variable(tf.random_normal([2,3],stddev=2)) 变量一个小应用：1234567891011121314151617import tensorflow as tfw1 = tf.Variable(tf.random_normal([2,3],stddev=1,seed=1))w2 = tf.Variable(tf.random_normal([2,3],stddev=1,seed=1))x = tf.constant([0.7,0.9])a = tf.matmul(x,w1)y = tf.matmul(a,w2)sess = tf.Session()sess.run(w1.initializer)sess.run(w2.initializer)print(sess.run(y))sess.close() 2.2 Session(会话)会话作用是执行定义好的运算，会话可以管理tensorflow运行时的所有资源。当所以计算完成后需要关闭会话回收资源。包含三个要点: 定义会话对象(tf.Session) 启动会话完成计算(run) 会话关闭(sess.close()) 使用会话如下：123sess = tf.Session()sess.run(...)ses.close() 可以使用python上下文管理机制自动关闭会话: 12with tf.Sesssion() as sess(): sess.run(...) 总结:123456789import tensorflow as tfsess = tf.Session()sess.run()sess.close()#以上代码等同于with tf.Session() as sess() sess.run() 2.3 placeholder(占位符)反向传播的机制就是迭代(循环执行某一个流程图)如果每一次迭代都要用到常量，计算量就过大(一个神经元网络的训练过程需要几百万轮甚至几亿轮迭代)，placeholder相当于定义了一个位置，这个位置中的数据在程序运行时再指定。和张量一样，placeholder的类型也是不可以改变的。 无placeholder的代码: 有placeholder: 总结: placeholder通过一个指针来表示该节点的输入数据，这样可以在运行时再计算该节点的数据 比直接用张量来作为输入数据节省内存 需要在Session的run()中通过字典类型参数feed_dict赋值 2.4 initializer(初始化) tf中变量是保存和更新神经网络参数的值，变量的操作分为变量定义和变量初始化 需要注意的是变量定义时只是给出变量赋值的方法，并没有被真正执行，需要通过会话初始化变量已完成赋值 12345678w1 = tf.Variable(tf.random_normal([2,3],stddev=2)) #随机数定义biases = tf.Variable(tf.zeors([3])) # 常数定义w2 = tf.Variable(weights.initialized_Value()) #通过其他变量定义sess = tf.Session()sess.run(w1.initializer) #初始化sess.run(w2.initializer) 2.5 graph(计算图)计算图是tensorflow计算的流程图，里面包括数据和计算，其中节点代表数据，节点和节点直接的连线代表计算。可以通过不同的计算图来管理模型。 以下代码会发现不同计算图的变量值不一样，就说明不同的图是一独立的运算流程12345678910111213141516171819202122232425import tensorflow as tf#定义一个计算图g1，其中变量v的值为0g1 = tf.Graph()with g1.as_default(): v = tf.get_variable("v", shape=[1], initializer=tf.zeros_initializer)#定义一个计算图g2，其中变量v的值为1g2 = tf.Graph()with g2.as_default(): v = tf.get_variable("v",shape=[1],initializer=tf.ones_initializer) #读取计算图g1中v的值with tf.Session(graph=g1) as sess: tf.initialize_all_variables().run() with tf.variable_scope("",reuse=True): print(sess.run(tf.get.variable("v"))) #读取计算图g2中v的值with tf.Session(graph=g2) as sess: tf.initialize_all_variables().run() with tf.variable_scope("",reuse=True): print(sess.run(tf.get.variable("v")))]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
        <tag>计算框架(AI)</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CIFAR 1.简介&可视化]]></title>
    <url>%2F2019%2F06%2F02%2FAI%2Fcifar%2F1.cifar%2F</url>
    <content type="text"><![CDATA[cifarCIFAR数据集是 Visual Dictionary(Teaching computers to recognize objects) 的子集，由三个教授收集，主要来自google和各类搜索引擎的图片。 备注：cifar官网 1.cifar10由10个类的60000的32*32彩色图像组成，每个类有6000个图像。有50000个训练图像和10000个测试图像。 类型如下: 2.cifar100这个数据集和cifar10类似，它有100个类，每个类包含600个图像，600个图像中有500个训练图像和100个测试图像。100类实际是由20个类(每个类又包含5个子类)构成(5*20=100)。 类型如下： 3.数据结构(Python版本) cifar10 数据格式如下： 123&lt;1×标签&gt; &lt;3072×像素&gt;...&lt;1×标签&gt; &lt;3072×像素&gt; 第一个字节是第一个图像的标签，它是一个0-9范围内的数字。接下来的3072个字节是图像像素的值。前1024个字节是红色通道值，下1024个绿色，最后1024个蓝色。 CIFAR-100 二进制版本与CIFAR-10的二进制版本相似，只是每个图像都有两个标签字节（粗略和细小）和3072像素字节，所以二进制文件如下所示： 123&lt;1 x粗标签&gt; &lt;1 x精标签&gt; &lt;3072 x像素&gt;...&lt;1 x粗标签&gt; &lt;1 x精标签&gt; &lt;3072 x像素&gt; 12345678#查看cifar100 python版本的数据结构def unpickle(file): import pickle with open(file, 'rb') as fo: dict = pickle.load(fo, encoding='bytes') return dictdict.keys()#dict_keys([b'data', b'coarse_labels', b'fine_labels', b'filenames', b'batch_label']) 4.可视化 pickle模块 pickle模块实现了基本的数据序列化和反序列化。 序列化过程将文本信息转变为二进制数据流，便于存储在硬盘之中，当需要读取文件的时候，从硬盘中读取数据。 反序列可以从文件中得到原始的数据，如字符串、列表、字典等数据。 PIL 负责将三色像素合并为一张图片保存 matplotlib.image 负责将单色道二维数组保存为一张图片 4.1 cifar10可视化:12345678910111213141516171819202122232425262728293031323334353637383940414243444546import numpy as npfrom PIL import Imageimport pickleimport osimport matplotlib.image as plimgCHANNEL = 3WIDTH = 32HEIGHT = 32 data = []labels=[]classification = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'] for i in range(5): with open("./cifar-10-batches-py/data_batch_"+ str(i+1),mode='rb') as file: #数据集在当脚本前文件夹下 data_dict = pickle.load(file, encoding='bytes') data+= list(data_dict[b'data']) labels+= list(data_dict[b'labels']) img = np.reshape(data,[-1,CHANNEL, WIDTH, HEIGHT]) #代码创建文件夹，也可以自行创建 data_path = "./pic3/"if not os.path.exists(data_path): os.makedirs(data_path)for i in range(100): r = img[i][0] g = img[i][1] b = img[i][2] plimg.imsave("./pic4/" +str(i)+"r"+".png",r) plimg.imsave("./pic4/" +str(i)+"g"+".png",g) plimg.imsave("./pic4/" +str(i) +"b"+".png",b) ir = Image.fromarray(r) ig = Image.fromarray(g) ib = Image.fromarray(b) rgb = Image.merge("RGB", (ir, ig, ib)) name = "img-" + str(i) +"-"+ classification[labels[i]]+ ".png" rgb.save(data_path + name, "PNG") 4.2 cifar100cifar100的文件结构和cifar10不同，数据只有一个文件夹里面有50000个图片，且有两个标签，可以从返回的dict的key查看其标签(前文有提到)。 知道其与cifar10后，改写前段代码即可实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344# -*- coding:utf-8 -*-import pickle as pimport numpy as npimport matplotlib.pyplot as pltimport matplotlib.image as plimgfrom PIL import Imagedef load_CIFAR_batch(filename): """ load single batch of cifar """ with open(filename, 'rb')as f: datadict = p.load(f,encoding='bytes') #X = datadict[b'data'] #Y = datadict[b'labels'] #X = X.reshape(10000, 3, 32, 32) X = datadict[b'data'] Y = datadict[b'coarse_labels']+datadict[b'fine_labels'] X = X.reshape(50000, 3, 32, 32) Y = np.array(Y) return X, Yif __name__ == "__main__": #imgX, imgY = load_CIFAR_batch("./cifar-10-batches-py/data_batch_1") imgX, imgY = load_CIFAR_batch("./cifar-100-python/train") print(imgX.shape) print("正在保存图片:") for i in range(imgX.shape[0]): imgs = imgX[i] if i &lt; 100:#只循环100张图片,这句注释掉可以便利出所有的图片,图片较多,可能要一定的时间 img0 = imgs[0] img1 = imgs[1] img2 = imgs[2] i0 = Image.fromarray(img0) i1 = Image.fromarray(img1) i2 = Image.fromarray(img2) img = Image.merge("RGB",(i0,i1,i2)) name = "img" + str(i)+".png" img.save("./pic1/"+name,"png")#文件夹下是RGB融合后的图像 for j in range(imgs.shape[0]): img = imgs[j] name = "img" + str(i) + str(j) + ".jpg" print("正在保存图片" + name) plimg.imsave("./pic2/" + name, img)#文件夹下是RGB分离的图像 print("保存完毕.") 注:在另一个文件夹还保存了三色的单通道图]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>图片识别</tag>
        <tag>CIFAR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MNIST 3.cnn实现]]></title>
    <url>%2F2019%2F06%2F02%2FAI%2Fmnist%2F3.mnist%2F</url>
    <content type="text"><![CDATA[该模型是tensorflow官方文档的第二个模型，使用了cnn卷积网络 该技术源于最早的lenet模型，细分计算过程，算上输入和输出，过程可分为卷积、池化、卷积、池化、全联接，总共七层。 卷积是用一个卷积核(比二维图像更小的一个二维数组)去扫一遍(就是矩阵积运算)图像，卷积计算可以提取带有卷积核的特征图像 池化是放大原图像局部特征，如3*3的像素值数组，突出最大像素值，清零其他像素值。达到放大特征，类似数据清洗，也可以减少计算量 全联接就是把图像值输出到结果值的万能公式y = wx+b得到输出的过程 该模型正确率约为99.2% 各层原理暂不详说，代码中有详细注释，先放两个传送门去多了解吧: https://www.jianshu.com/p/fabf52b35a08 https://blog.csdn.net/hwl19951007/article/details/81126699 以下是MNIST代码实现(注意最好当前文件夹下有MNIST_data这个本地包可以免去下载): 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("./MNIST_data/",one_hot=True)sess = tf.InteractiveSession()#交互式session，可以边构建运算图边执行sess，如果是普通session，需要构建完整的运算图后才可以运行sessx = tf.placeholder('float',[None,784])y_= tf.placeholder('float',[None,10])W = tf.Variable(tf.zeros([784,10]))b = tf.Variable(tf.zeros([10]))sess.run(tf.initialize_all_variables())y = tf.nn.softmax(tf.matmul(x,W)+b)cross_entropy = -tf.reduce_sum(y_*tf.log(y))##1.参数初始化def weight_variable(shape): initial = tf.truncated_normal(shape,stddev=0.1) return tf.Variable(initial) def bias_variable(shape): initial = tf.constant(0.1,shape=shape) #第二个参数为该常量的维度 return tf.Variable(initial)##2.卷积层和池化层def conv2d(x,W): return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME') def max_pool_2_2(x): return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME') ##3.第一层W_conv1 = weight_variable([5,5,1,32])#[5，5，1，32]表示为卷积核为5*5，卷积输入为1，输出为32(32个卷积核)b_conv1 = bias_variable([32])x_image = tf.reshape(x,[-1,28,28,1])#最后一维是通道数，这里是灰度图所以为1h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1)#[-1,28,28,1]用[5,5,1,32]卷积,得到图片28*28*32(因为有32个卷积核所以有32个特征图),具体为[-1,28,28,32]h_pool1 = max_pool_2_2(h_conv1)#池化,池化步长x和y轴都是2，所以图片缩小一半得到14*14*32，即[-1,14,14,32]##4.第二层W_conv2 = weight_variable([5,5,32,64])#[5，5，1，32]表示为卷积核为5*5，卷积输入通道为32，输出通道为64b_conv2 = bias_variable([64])h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2)#[-1,14,14,32]被[5,5,32,64]卷积32个通道输出为64个通道(卷积核)，具体为[-1,14,14,64]h_pool2 = max_pool_2_2(h_conv2)#池化后图片数据量减一半，最终为1024个特征向量[-1,7,7,64]##5.全连接层W_conv3 = weight_variable([7*7*64,1024])#[4096,1024]b_conv3 = bias_variable([1024])h_conv3_flat = tf.reshape(h_pool2,[-1,7*7*64])#[-1,7,7,64]reshape为[-1,7*7*64]h_conv3_fc1 = tf.nn.relu(tf.matmul(h_conv3_flat,W_conv3)+b_conv3)#[-1,7*7*64]*[7*7*64,1024]+[1014]##6.dropout防止过拟合keep_prob = tf.placeholder('float')h_conv3_drop = tf.nn.dropout(h_conv3_fc1,keep_prob)##7.输出W_output = weight_variable([1024,10])b_output = bias_variable([10])y_conv = tf.nn.softmax(tf.matmul(h_conv3_drop,W_output)+b_output)#[-1,1024]*[1024,10]+[10]##8.评估模型cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))sess.run(tf.initialize_all_variables())for i in range(20000): batch = mnist.train.next_batch(50) if i%1000 == 0: train_accuracy = accuracy.eval(feed_dict=&#123; x:batch[0], y_: batch[1], keep_prob: 1.0&#125;) print("step %d, training accuracy %g"%(i, train_accuracy)) train_step.run(feed_dict=&#123;x: batch[0], y_: batch[1], keep_prob: 0.5&#125;)print("test accuracy %g"%accuracy.eval(feed_dict=&#123; x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0&#125;)) 最终准确率：]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>MNIST</tag>
        <tag>图片识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MNIST 1.简介&可视化]]></title>
    <url>%2F2019%2F06%2F02%2FAI%2Fmnist%2F1.mnist%2F</url>
    <content type="text"><![CDATA[1.简介MNIST 数据集来自美国国家标准与技术研究所, 是NIST(National Institute of Standards and Technology)的缩小版，训练集 (training set) 由来自 250 个不同人手写的数字构成, 其中 50% 是高中学生, 50% 来自人口普查局 (the Census Bureau) 的工作人员，测试集(test set) 也是同样比例的手写数字数据. MNIST 数据集可在 http://yann.lecun.com/exdb/mnist/ 获取, 图片是以字节的形式进行存储，它包含了四个部分: Training set images: train-images-idx3-ubyte.gz (9.9 MB, 解压后 47 MB, 包含 60,000 个样本) Training set labels: train-labels-idx1-ubyte.gz (29 KB, 解压后 60 KB, 包含 60,000 个标签) Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 解压后 7.8 MB, 包含 10,000 个样本) Test set labels: t10k-labels-idx1-ubyte.gz (5KB, 解压后 10 KB, 包含 10,000 个标签) 此数据集中，训练样本：共60000个，其中55000个用于训练，另外5000个用于验证。测试样本：共10000个，验证数据比例相同。 数据集中像素值a）使用python读取二进制文件方法读取mnist数据集，则读进来的图像像素值为0-255之间；标签是0-9的数值。b）采用TensorFlow的封装的函数读取mnist，则读进来的图像像素值为0-1之间；标签是0-1值组成的大小为1*10的行向量。 2.读取mnist到numpyload_mnist 函数返回两个数组, 第一个是一个 n x m 维的 NumPy array(images), 这里的 n 是样本数(行数), m 是特征数(列数). 训练数据集包含 60,000 个样本, 测试数据集包含 10,000 样本. 在 MNIST 数据集中的每张图片由 28 x 28 个像素点构成, 每个像素点用一个灰度值表示. 在这里, 我们将 28 x 28 的像素展开为一个一维的行向量, 这些行向量就是图片数组里的行(每行 784 个值, 或者说每行就是代表了一张图片). load_mnist 函数返回的第二个数组(labels) 包含了相应的目标变量, 也就是手写数字的类标签(整数 0-9). 1234567891011121314151617181920mport osimport structimport numpy as np def load_mnist(path, kind='train'): """Load MNIST data from `path`""" labels_path = os.path.join(path,'%s-labels-idx1-ubyte'% kind) images_path = os.path.join(path,'%s-images-idx3-ubyte'% kind) with open(labels_path, 'rb') as lbpath: magic, n = struct.unpack('&gt;II',lbpath.read(8)) labels = np.fromfile(lbpath,dtype=np.uint8) #读入magic是一个文件协议的描述,也是调用fromfile 方法将字节读入NumPy的array之前在文件缓冲中的item数(n). with open(images_path, 'rb') as imgpath: magic, num, rows, cols = struct.unpack('&gt;IIII',imgpath.read(16)) images = np.fromfile(imgpath,dtype=np.uint8).reshape(len(labels), 784) return images, labels 12341.&gt;这是指大端(用来定义字节是如何存储的，关于大小端, 更多内容可见&lt;&lt;深入理解计算机系统 – 2.1 节信息存储&gt;&gt;)2.I: 这是指一个无符号整数. 3.查看tensorflow集成的mnist12345678910111213141516171819202122232425from tensorflow.examples.tutorials.mnist import input_dataminit = input_data.read_data_sets("../MNIST_data")#如果该路径没有会自动下载print("Training data size",minit.train.num_examples)#训练数据print("Training data size",minit.validatation.num_examples)#验证数据print("Training data size",minit.test.num_examples)#测试数据print("Example training data size",minit.train.image[0])#样例训练数据print（“Example training data label”,minist.train.labels[0]）#样例训练数据标签 batch_size = 100x,y = mnist.train.next_batch(batch_size)print('x shape:',x.shape)print('y shape:',y.shape) 4.可视化4.1 plt的方法 从 feature matrix 中将 784-像素值 的向量 reshape 为之前的 28*28 的形状, 然后通过 matplotlib 的 imshow 函数进行绘制,不能进行one-hot编码: 读单个图片 1234567891011121314151617181920212223242526272829import matplotlib.pyplot as plt #from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets#mnist = read_data_sets('MNIST_data', one_hot=False)from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("./MNIST_data",one_hot=False)x, y = mnist.test.next_batch(1)x = x.reshape([28, 28]) fig = plt.figure()# Method1 ax1 = fig.add_subplot(221)ax1.imshow(x, cmap=plt.cm.gray) # Method2: 反转色ax2 = fig.add_subplot(222)ax2.imshow(x, cmap=plt.cm.gray_r) # r表示reverse # Method3（等价于Method1）ax3 = fig.add_subplot(223)ax3.imshow(x, cmap='gray') # Method4（等价于Method2）ax4 = fig.add_subplot(224)ax4.imshow(x, cmap='gray_r') plt.show() 读多个图片 1234567891011121314151617181920212223242526import matplotlib.pyplot as pltimport tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("./MNIST_data",one_hot=False) fig, ax_big = plt.subplots() for i in range(100): #读一百张 x,y = mnist.test.next_batch(1) x = x.reshape([28,28]) ax = fig.add_subplot(10,10,i+1) #10行10列 ax.imshow(x, cmap=plt.cm.gray) ax.set_xticks([]) ax.set_yticks([]) #隐藏子图坐标轴刻度ax_big.set_xticks([]) # 隐藏坐标轴刻度ax_big.set_yticks([])plt.show()#plt.savefig("路径.png", dpi=150) 4.2 torchvision&amp;scipy方法其实数据集里的图片就是一个带有像素值的二维数组，可以画出这个数组的库有很多。包括机器学习库torch，其中的torchvision也可以。具体方法如下: 123456789101112131415161718192021import torchvision import torch.utils.data as Data import scipy.miscimport osDOWNLOAD_MNIST = True train_data = torchvision.datasets.MNIST(root='./MNIST_data2/',train=True,transform=torchvision.transforms.ToTensor(),download=DOWNLOAD_MNIST)#把原始图片保存至MNIST_data/raw/下save_dir="mnist/raw/"if os.path.exists(save_dir) is False: os.makedirs(save_dir) for i in range(20): image_array,_=train_data[i]#打印第i个 image_array=image_array.resize(28,28) filename=save_dir + 'mnist_train_%d.jpg' % i#保存文件的格式 print(filename) print(train_data.train_labels[i])#打印出标签 scipy.misc.toimage(image_array,cmin=0.0,cmax=1.0).save(filename)#保存图像 结果输出如下：]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>MNIST</tag>
        <tag>图片识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MNIST 2.最简单的识别模型]]></title>
    <url>%2F2019%2F06%2F02%2FAI%2Fmnist%2F2.mnist%2F</url>
    <content type="text"><![CDATA[该模型是tensorflow官方文档首个模型,没有使用卷积网络 关键是构建一个公式 公式为y=wx+b，带有二维像素值的数组(图片)作为输入x，标签(图片结果)作为输出y 用正向传播把数据(x，y)带入训练，再反向传播提升梯度来不断调整参数(w,b)，使得公式的输出尽量准确。 正确率约为92% 一、模型构建(计算公式实现)为了得到一章图片(28*28=784个像素值)属于某个特定数字类的特征，我们对像素值进行加权求和。如果结果特征即加权值为负，就不属于该类，为正就属于该类。 1.特征值(需要学习参数W、b) 2.softmax转换特征值为概率(0-1之间): 其中xi是输入数据，evidencei是特征,y为通过特征softmax后得到的最终概率， 而参数W和b是我们要学习得到的数据，Wi是一个[784,10]的数据，bi是一个[10]的数据，就是模型(也是一个计算公式)的核心部分。 代码：y=tf.nn.softmax(tf.matmul(x,W)+b) 3.构建交叉熵可以将W和b初始化为全0向量(或随意设置)，通过迭代输入变量的计算结果反向传播(bp),从而使用梯度下降算法(gradient descent algorithm)完成最优化参数W和b，最优化的结果可以计算出最终的模型准球率 梯度下降需要设置学习率即学习的速率,还需要一个损失函数(最长见的是交叉熵cross-entropy),该函数得到一个loss值来刻画模型训练的结果(准确率) y是预测的分布，y`是实际的分布， 代码:crossentropy = -tf.reduce_sum(y*tf.log(y)) 4.训练(BP和反向传播,学习过程)训练是一系列计算，包括1.计算梯度 2.每个参数的步长变化 3.更新参数 train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy) train_step是一个对象，计算时会使用梯度下降来更新参数，通过反复运行该对象完成。 1234567for i in range(1000): batch = mnist.train.next_batch(50) train_step.run(feed_ditc=&#123;x:batch[0],y:batch[1]&#125;) #x,y为具体数据，替代占位符(placeholder) #等价于: #train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy) #sess.run(train_step,feed_ditc=&#123;x:batch[0],y:batch[1]&#125;) 二、实现代码:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("./MNIST_data/",one_hot=True)print(mnist.train.images)print(type(mnist.train.images))print(mnist.train.images.shape)print(mnist.train.labels)print(type(mnist.train.labels))print(mnist.train.labels.shape)x = tf.placeholder('float',[None,784]) #该占位符第一维可以是任意长度，表示图像数据可以是28*28=784的n张图W = tf.Variable(tf.zeros([784,10]))b = tf.Variable(tf.zeros([10]))#w和b是需要学习的值，初始化为0y = tf.nn.softmax(tf.matmul(x,W)+b)#模型即计算公式,y是预测值y_ = tf.placeholder('float',[None,10])#y_是真实值cross_entropy = -tf.reduce_sum(y_*tf.log(y))#计算交叉熵train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)#优化器，计算梯度，并将梯度作用于变量.#使用minimize()操作，该操作不仅可以优化更新训练的模型参数，也可以为全局步骤(global step)计数init = tf.initialize_all_variables()sess = tf.Session()sess.run(init)for i in range(1000): batch_xs,batch_ys = mnist.train.next_batch(100) sess.run(train_step,feed_dict=&#123;x:batch_xs,y_:batch_ys&#125;) correct_predict = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))#y是一个含有10个元素的标签#argmax(a,b)返回集合a中和数值b相同的索引值accuracy = tf.reduce_mean(tf.cast(correct_predict,"float"))#tf.cast将bool值转化为浮点数#tf.reduce_mean可以取平均值,如[1,0,1,1]为0.75sess.run(accuracy,feed_dict=&#123;x:mnist.test.images,y_:mnist.test.labels&#125;) sess.close()#准确率为0.9129 三、实现代码2增加了测试过程的准确率，以1000次为一步 12345678910111213141516171819202122232425262728293031323334353637383940import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("./MNIST_data/",one_hot=True)x = tf.placeholder('float',[None,784]) #该占位符第一维可以是任意长度，表示图像数据可以是28*28=784的n张图W = tf.Variable(tf.zeros([784,10]))b = tf.Variable(tf.zeros([10]))#w和b是需要学习的值，初始化为0y = tf.nn.softmax(tf.matmul(x,W)+b)#模型即计算公式,y是预测值y_ = tf.placeholder('float',[None,10])#y_是真实值cross_entropy = -tf.reduce_sum(y_*tf.log(y))train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)correct_predict = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))accuracy = tf.reduce_mean(tf.cast(correct_predict,"float"))init = tf.initialize_all_variables()sess = tf.Session()sess.run(init)for i in range(10000): batch_xs,batch_ys = mnist.train.next_batch(100) sess.run(train_step,feed_dict=&#123;x:batch_xs,y_:batch_ys&#125;) if i%1000 == 0: acc=sess.run(accuracy,feed_dict=&#123;x:mnist.validation.images,y_:mnist.validation.labels&#125;) #训练1000次后(更新的参数W,b)，对整体validation的测试 print('step %d is %g'%(i,acc)) #上两行代码等价于: #print(accuracy.eval(feed_dict=&#123;x:mnist.validation.images,y_:mnist.validation.labels&#125;)) accFinal=sess.run(accuracy,feed_dict=&#123;x:mnist.test.images,y_:mnist.test.labels&#125;) print(accFinal)sess.close()#准确率为0.9129]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>MNIST</tag>
        <tag>图片识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MNIST 4.改进的cnn模型]]></title>
    <url>%2F2019%2F06%2F02%2FAI%2Fmnist%2F4.mnist%2F</url>
    <content type="text"><![CDATA[该模型是TF书中97页的改进版，来源于CSDN,模型使用tf框架的范围管理scope技术来优化参数设定，最终准确率为0.984 这里主要引入较多参数来改进原有的cnn模型： 使用激活函数去线性化 使用隐藏层即加深层数以解决复杂问题 使用学习率调整更新参数的频度 使用滑动平均模型来调整模型结果 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157# 导入必要的库import tensorflow as tfimport osfrom tensorflow.examples.tutorials.mnist import input_data # 下载数据，打印数据信息mnist = input_data.read_data_sets('/MNIST_data/', one_hot=True)print("Training data size: ", mnist.train.num_examples)print("Validating data size: ", mnist.validation.num_examples)print("Testing data size: ", mnist.test.num_examples)print("Example training data: ", mnist.train.images[0] )print("Example training data label: ", mnist.train.labels[0]) # 声明全局变量INPUT_NODE = 784 # 输入层节点数，图片是28*28*1的格式，每个像素点对应一个节点就是784OUTPUT_NODE = 10 # 输出层节点数，0-9十个数字 LAYER1_NODE = 500 # 第一个隐藏层的节点数 BATCH_SIZE = 100 # batch的大小，越大训练过程越接近梯度下降，越小越接近随机梯度下降 LEARNING_RATE_BASE = 0.8 # 基础的学习率LEARNING_RATE_DECAY = 0.99 # 学习率的衰减值 REGULARIZATION_RATE = 0.0001 # 正则化的λ系数TRAINING_STEPS = 30000 # 训练的轮数MOVING_AVERAGE_DECAY = 0.99 # 滑动平均衰减率 def get_weight_variable(shape, regualrizer): # get_variable()获取这个参数的现有变量或创建一个新变量。获取的参数根据"name"指定 # 生成的值服从具有指定平均值和标准偏差的正态分布， # 如果生成的值大于平均值2个标准偏差的值则丢弃重新选择。 # stddev 要生成的随机值的标准偏差 weights = tf.get_variable("weights", shape, initializer=tf.random_normal_initializer(stddev=0.1)) if regualrizer != None: # 传入的参数regualrizer是一个函数 # 如果定义了正则化函数（L1或者L2），则计算weights的正则化参数，并加入 # 名为“losses”的集合 tf.add_to_collection("losses", regualrizer(weights)) return weights def inference(x, regularizer): """ 辅助函数，给定神经网络的输入和所有参数，计算向前传播的结果 定义了一个relu激活的三层全连接网络(输入层，隐藏层，输出层) """ # variable_scope()用于定义创建变量（层）的操作的上下文管理器。此上下文管理器验证（可选）的 # values来自同一图形，确保图形是默认图形，并推送名称范围和变量范围 with tf.variable_scope('layer1', reuse = False): weights = get_weight_variable([INPUT_NODE, LAYER1_NODE], regularizer) biases = tf.get_variable("biases", [LAYER1_NODE], initializer=tf.constant_initializer(0.0)) layer1 = tf.nn.relu(tf.matmul(x, weights) + biases) with tf.variable_scope('layer2', reuse = False): weights = get_weight_variable([LAYER1_NODE, OUTPUT_NODE], regularizer) biases = tf.get_variable("biases", [OUTPUT_NODE], initializer=tf.constant_initializer(0.0)) layer2 = tf.matmul(layer1, weights) + biases return layer2 def train(mnist): """训练模型""" x = tf.placeholder(tf.float32, shape=[None, INPUT_NODE], name="x-input") y_ = tf.placeholder(tf.float32, shape=[None, OUTPUT_NODE], name="y-input") # 定义正则化的函数 regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE) # 向前传播求出y y = inference(x, regularizer) # 定义训练的轮数，需要用trainable=False参数指定不训练这个变量， # 这样同时也可以避免这个变量被计算滑动平均值 global_step = tf.Variable(0, trainable=False) # 给定滑动平均衰减速率和训练轮数，初始化滑动平均类 variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step) # 用tf.trainable_variable()获取所有可以训练的变量列表，全部使用滑动平均 variables_averages_op = variable_averages.apply(tf.trainable_variables()) # 定义损失函数 # 因为标准答案是一个长度为10的一维数组，argmax可以从这个矩阵（y_）的轴为1的部分取最大值的序号 # 在sparse_softmax_cross_entropy_with_logits()中，要将原来为one-hot形式的labels # 转换为数字标签[1],[2],...的格式。 # tf.argmax(Y,asix)，axis = 0 或 1，分别表示按列或按行返回最大值的序号。 cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1)) # 获取总损失平均值 cross_entropy_mean = tf.reduce_mean(cross_entropy) # 给损失加上正则化的损失 # 使用get_collection获取losses集合的全部值的列表，然后用add_n求列表的所有值的和 loss = cross_entropy_mean + tf.add_n(tf.get_collection("losses")) # 求加上指数衰减的学习率 learning_rate = tf.train.exponential_decay( LEARNING_RATE_BASE, global_step, mnist.train.num_examples / BATCH_SIZE, LEARNING_RATE_DECAY, staircase = True ) # 优化损失函数 # global_step初始值为0，在loss更新后会+1，用来记录更新的次数 # 返回值是训练之后的梯度，会随着global_step递增 train_step = tf.train.GradientDescentOptimizer( learning_rate).minimize(loss, global_step=global_step) # 反向传播更新参数之后需要更新每一个参数的滑动平均值，用下面的代码可以一次完成这两个操作 # train_step计算所有参数的梯度，variables_averages_op对所有参数进行滑动平均（利用train_step） with tf.control_dependencies([train_step, variables_averages_op]): train_op = tf.no_op(name="train") # y是计算得出的预测答案，而y_是正确答案，用argmax获取答案的序号（也即是数字的值） # equal()判断两个答案是否相等，是就返回True，否就返回False correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1)) # cast()把一个布尔类型的数转换为实数，然后用reduce_mean计算平均值，获取准确率 accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) with tf.Session() as sess: # 初始化全局变量 tf.global_variables_initializer().run() validate_feed = &#123;x: mnist.validation.images, y_: mnist.validation.labels&#125; test_feed = &#123;x: mnist.test.images, y_: mnist.test.labels&#125; # 开始迭代 for i in range(TRAINING_STEPS): xs, ys = mnist.train.next_batch(BATCH_SIZE) sess.run(train_op, feed_dict=&#123;x:xs, y_:ys&#125;) # tensorflow的数据集特有的一种batch_size获取方法 if i % 1000 == 0: # 获取计算之后的loss和global_step validate_acc = sess.run(accuracy, feed_dict=validate_feed) print("After %d traing times, validate accuracy using average model is %g" % (i, validate_acc)) # 使用模型训练测试集，获取最终的准确率 test_acc = sess.run(accuracy, feed_dict=test_feed) print("After %d traing times, test accuracy using average model is %g" % (TRAINING_STEPS, test_acc)) # 主函数定义 def main(argv=None): tf.reset_default_graph() mnist = input_data.read_data_sets('/MNIST_data/', one_hot=True) train(mnist) if __name__ == "__main__": main() 参考文献：https://blog.csdn.net/lovefreewind/article/d]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>MNIST</tag>
        <tag>图片识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫教程2 框架爬虫]]></title>
    <url>%2F2018%2F09%2F26%2F%E7%88%AC%E8%99%AB%2F2.%E7%88%AC%E8%99%AB2%2F</url>
    <content type="text"><![CDATA[Python 简易爬虫 1 Scrapy框架1.1 框架介绍 通过ORM，把爬取的数据对应到python的对象中，完成数据的爬取。 1.2 基本操作123456789#可能安装的依赖包&gt;&gt;&gt;pip install wheel&gt;&gt;&gt;cd c:/&gt;&gt;&gt;pip install Twi+(tab)&gt;&gt;&gt;pip install scrapy#创建项目&gt;&gt;&gt;scrapy startproject aSpider 1.2.1 项目的目录结构1234567891011121314aSpider --- aSpider --- __init__.py __pycache__ middlewares.py settings.py spiders #用于实现爬虫的文件 __init__.pyc items.py #用于写类(class)实现ORM的文件 pipelines.py settings.pyc scrapy.cfg 1.3 XpathXPath 是一门在 XML 文档中查找信息的语言。XPath 可用来在 XML 文档中对元素和属性进行遍历。 XPath 是 W3C XSLT 标准的主要元素，并且 XQuery 和 XPointer 都构建于 XPath 表达之上。 12345678/html/head/title/text()#选择HTML文档&lt;head&gt;元素下面的&lt;title&gt;标签内的文本内容//td:#选择所有的td元素//div[@class="mine"]#选择所有包含class="mine"属性的div标签元素 xpath():返回selectors,每一个select表示一个xpath参数表达式选择的节点 css():返回selectors，每一个select表示一个css参数表达式选择的节点 extract():返回一个unicode字符串，内容为xpath选中的内容 re()：返回一个unicode字符串，内容为正则表达式的内容 1.4 spider存于项目的spiders文件夹下,itcast_spider.py中 123456789101112131415class aSpider(scrapy.spiders.Spider): name="itcast" allowd_domains = ["http://www.itcast.cn"] start_urls = ["http://www.itcast.cn/channel/teacher.shtml#ac"] def parse(self,response): for site in response.xpath('//div[@class="li_txt"]'): teacher_name = site.xpath('h3/text()').extract() teacher_level = site.xpath('h4/text()').extract() teacher_info = site.xpath('p/text()').extract() print teacher_name[0] print teacher_level[0] print teacher_info[0] print "=============" 1.5 items.py1234567891011import scrapy class aSpiderItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() passclass ItcastItem(scrapy.Item): name = scrapy.Field() level = scrapy.Field() info = scrapy.Field() 1.6 改写spider1234567891011121314151617181920212223242526272829303132import scrapyfrom aSpider.items import ItcastItemclass aSpider(scrapy.spiders.Spider): name="itcast" allowd_domains = ["http://www.itcast.cn"] start_urls = ["http://www.itcast.cn/channel/teacher.shtml#ac"] items = [] def parse(self,response): for site in response.xpath('//div[@class="li_txt"]') teacher_name = site.xpath('h3/text()').extract() teacher_level = site.xpath('h4/text()').extract() teacher_info = site.xpath('p/text()').extract() print teacher_name[0] print teacher_level[0] print teacher_info[0] print "=============" item = ItcastItem() #一个对象数据 item['name']=teacher_name[0] item['level']=teacher_level[0] item['info']=teacher_info[0] items.append(item) return items 1.7 爬取内容12345#爬取内容&gt;&gt;&gt;python3 -m scrapy crawl itcast#爬取内容至json中&gt;&gt;&gt;scrapy crawl itcast -o itcast_teacher.json -t json]]></content>
      <categories>
        <category>Python爬虫</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫教程1 爬虫基础]]></title>
    <url>%2F2018%2F09%2F26%2F%E7%88%AC%E8%99%AB%2F1.%20%E7%88%AC%E8%99%AB%201%2F</url>
    <content type="text"><![CDATA[Python 简易爬虫 1.爬整个网页 一个网址字符串，ex：’http://www.baidu.com‘ 向网站发出请求：把字符串传入request对象() 把请求返回的信息赋值到变量response 写入txt文件 1234567891011121314151617181920212223# python3import urllib.requestheader= &#123; 'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko ) Chrome/58.0.3029.96 Safari/537.36'&#125; #一个请求的头部，其中User-Agent用于描述浏览器类型request = urllib.request.Request('http://www.sina.com',headers=header)#请求对象，请求某一网站的内容response1 = urllib.request.urlopen('http://www.sina.com')#某一网站的响应response2 = urllib.request.urlopen(request) html=response1.read()#读取响应信息的字节流f = open('./4.txt','wb')f.write(html)f.close()#将字节流写入到文件中 2.爬取豆瓣短评 load(url)函数,通过url传递网页爬取网页内容123456789import urllib.requestdef load(url): req = urllib.request.Request(url) #豆瓣评论的网址 res = urllib.request.urlopen(req) html = res.read() return html``` &gt;write(html,txt)函数，将html内容存至txt文件中 def write(html,t): f = open(t,’wb’) f.write(html) f.close()1234&gt;spider(url,begin,end)函数，爬取指定页数的评论其中https://movie.douban.com/subject/24773958/comments?start=0&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=为短评首页 def spider(url,begin,end): for i in range(begin,end+1): 20*(i-1) the_url=’https://movie.douban.com/subject/24773958/comments?start=&#39;+str(i)+&#39;&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=‘ html = load(the_url) t = str(i)+’.html’ write(html,t) print(‘已保存第%d页’%i) 1&gt;正则表达式爬取评论内容 结局简直丧出天际！灭霸竟然有内心戏！ 全程下来美队和钢铁侠也没见上一面， 我还以为在世界末日前必然要重修旧好了！ 正则表达式为‘(.*?)‘ 改写load()import urllib.requestimport redef load(url): req = urllib.request.Request(url) #豆瓣评论的网址 res = urllib.request.urlopen(req) html = res.read() #二进制文件 html = html.decode(&#39;utf-8&#39;) #解码,该方法返回解码后的字符串。 pattern = re.compile(&#39;&lt;p class=&quot;&quot;&gt;(.*?)&lt;/div&gt;&#39;) list = pattern.findall(html) return list 123&gt;命令行操作 有中文输出输入时需加下行的编码-- coding: utf-8 --if name == ‘main‘: url = input(‘请输入网址:’) begin = int(input(‘请输入起始页:’)) end = int(input(‘请输入终止页:’)) spider(url,begin,end)```]]></content>
      <categories>
        <category>Python爬虫</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4. 类与对象]]></title>
    <url>%2F2018%2F09%2F21%2FPython%2F4.%20%E7%B1%BB-1%2F</url>
    <content type="text"><![CDATA[Python 原创基础教程 第四章 类与对象4.1 类简述 类是一个“模版”，可以包含变量和函数(即类是属性和方法的集合) 对象是类创建的实例，通过实例可以调用变量和函数 类中普通函数的必须有第一个参数，来代表该类调用函数的具体对象(一般取名为self) 1234567891011121314#类的基本语法class A: x = 'x' #静态变量 def __init__(self): #构造函数 self.y = 'y' #普通变量 def f1(self): #普通函数，无参数 print("aaa") def f2(self,name): #普通函数，有参数 print('my name is %s'%name) obj1 = A() #实例化对象，对象变量为obj1obj1.f1() #对象调用函数f1() 4.2 类成员 类的结构图，其中变量也称属性，函数也称方法123456789graph LRA(类成员)--&gt;B(变量)A--&gt;C(函数)A--&gt;D(方法属性)B--&gt;普通变量B--&gt;静态变量C--&gt;普通函数C--&gt;类函数C--&gt;静态函数 4.3 变量(属性) 类中的变量也叫属性，亦可叫字段，是类这种数据结构中保存多样数据的方式 普通字段属于对象(每个对象都存一份) 静态字段属于类(就类存有一份) 123456789101112131415class Province: #静态字段 country = '中国' def __init__(self,name): #普通字段 self.name=nameobj = Province('河北省')访问普通字段print obj.name访问静态字段Province.country 4.4 函数(方法) 函数在类中也叫方法。通过方法，让类这种数据结构具有“运动”的特征，即类不仅可以保存数据，以可以操作处理数据，其中操作处理数据就是通过类方法实现。 普通方法:对象调用，至少一个self参数，执行方法自动调用具体对象给该方法 类方法:由类调用，至少一个cls参数，执行时自动调用cls给该方法 静态方法:由类调用，无默认参数 三种方法都存于类 123456789101112131415161718192021222324252627class Foo: def __init__(self,name): self.name = name #普通方法 def ord_func(self): print(普通方法) #类方法 @classemethod def class_func(cls): print(类方法) #定义静态方法 @staticmethod def static_func(): print(静态方法)#调用普通方法f = Foo()f.ord_func()#调用类方法Foo.class_func()#调用静态方法Foo.static_func() 4.4.1 函数属性化 通过装饰器，函数可以像属性一样调用 用@property装饰器定义 仅有一个self参数 调用时无需括号 经典类(python2中常用)123456789101112131415################ 定义 ###############class Foo: def func(self): pass # 定义属性 @property def prop(self): print('abc')################ 调用 ###############foo_obj = Foo() foo_obj.func()foo_obj.prop #调用属性 新式类 由于新式类中具有三种访问方式，我们可以根据他们几个属性的访问特点，分别将三个方法定义为对同一个属性： 获取 修改 删除 1234567891011121314151617181920212223# ############### 定义 ###############class Goods(object): @property def price(self): print '@property' @price.setter def price(self, value): print '@price.setter' @price.deleter def price(self): print '@price.deleter' # ############### 调用 ###############obj = Goods() obj.price # 自动执行 @property 修饰的 price 方法，并获取方法的返回值 obj.price = 123 # 自动执行 @price.setter 修饰的 price 方法，并将 123 赋值给方法的参数 del obj.price # 自动执行 @price.deleter 修饰的 price 方法 以下是property的构造方法(静态变量的方式)中有个四个参数 第一个参数是方法名，调用 对象.属性 时自动触发执行方法 第二个参数是方法名，调用 对象.属性 ＝ XXX 时自动触发执行方法 第三个参数是方法名，调用 del 对象.属性 时自动触发执行方法 第四个参数是字符串，调用 对象.属性.doc ，此参数是该属性的描述信息 1234567891011121314151617181920class Foo： def get_bar(self): return 'wupeiqi' # *必须两个参数 def set_bar(self, value): return return 'set value' + value def del_bar(self): return 'wupeiqi' BAR ＝ property(get_bar, set_bar, del_bar, 'description...') obj = Foo() obj.BAR # 自动调用第一个参数中定义的方法：get_barobj.BAR = "alex" # 自动调用第二个参数中定义的方法：set_bar方法，并将“alex”当作参数传入del Foo.BAR # 自动调用第三个参数中定义的方法：del_bar方法obj.BAE.__doc__ # 自动获取第四个参数中设置的值：description... 4.5 类变量(属性)扩展 静态变量(保存在类中)：在任何对方都能访问 私有静态变量(变量前加__)：只有在类的内部能访问 普通变量(在函数里的变量):对象可以访问、类内部可以访问、派生类中可以访问 普通私有变量(变量前加__):仅类内部能访问 静态变量：类可以访问、类内部可以访问、派生类中可以访问 12345678910111213141516171819class C: name = "全局变量" def func(self): print C.name class D(C): def show(self): print C.name C.name # 类访问 obj = C()obj.func() # 类内部可以访问 obj_son = D()obj_son.show() # 派生类中可以访问 2.私有静态变量：仅类内部可以访问12345678910111213141516171819class C: __name = "私有静态变量" def func(self): print C.__name class D(C): def show(self): print C.__name C.__name # 类访问 错误 obj = C()obj.func() # 类内部可以访问 正确 obj_son = D()obj_son.show() # 派生类中可以访问 错误 3.普通变量 1234567891011121314151617181920class C: def __init__(self): self.foo = "普通变量" def func(self): print self.foo # 类内部访问 class D(C): def show(self): print self.foo ＃ 派生类中访问 obj = C() obj.foo # 通过对象访问obj.func() # 类内部访问 obj_son = D();obj_son.show() # 派生类中访问 4.私有字段 1234567891011121314151617181920class C: def __init__(self): self.__foo = "私有字段" def func(self): print self.foo # 类内部访问 class D(C): def show(self): print self.foo ＃ 派生类中访问 obj = C() obj.__foo # 通过对象访问 错误obj.func() # 类内部访问 正确 obj_son = D();obj_son.show() # 派生类中访问 错误 如果想要强制访问私有字段，可以通过 【对象.类名_私有字段明 】访问（如：obj._C__foo），不建议强制访问私有成员。 4.6 类的特殊成员 类的特殊成员包括特殊变量和特殊方法，其是系统定义的，不需要用户定义，一般具有普通变量和方法所不具有的特殊功能 1. doc:表示类的描述 12345678class Foo: """ 描述类信息，这是用于看片的神奇 """ def func(self): pass print(Foo.__doc__)#输出：类的描述信息 2. module:表示当前操作对象在哪个模块 模块:组织函数和类的单位(类似java的一类一文件，有时不同模块可能有同名函数),例如Django 1print(obj.__module__) #输出对象所在模块 3. class：表示当前操作对象的是什么 类 1print(obj.__class__) #输出对象所在类 4. init(self,..):构造方法、类创建对象时自动执行 5. del(self,..):析构方法、当对象在内存释放时、自动触发执行。 此方法一般无须定义，因为Python是一门高级语言，程序员在使用时无需关心内存的分配和释放，因为此工作都是交给Python解释器来执行，所以，析构函数的调用是由解释器在进行垃圾回收时自动触发执行的。 6. call(self,..):除析构方法外，执行对象的另一种特殊方法,对象加括号执行 1234567891011class Foo: def __init__(self): pass def __call__(self, *args, **kwargs): print '__call__' obj = Foo() # 执行 __init__obj() # 执行 __call__ 7. dict:显示类(静态变量、方法)和对象(普通字段)的所以成员 123456789101112131415161718192021222324class Province: country = 'China' def __init__(self, name, count): self.name = name self.count = count def func(self, *args, **kwargs): print 'func' # 获取类的成员，即：静态字段、方法、print Province.__dict__# 输出：&#123;'country': 'China', '__module__': '__main__', 'func': , '__init__': , '__doc__': None&#125; obj1 = Province('HeBei',10000)print obj1.__dict__# 获取 对象obj1 的成员# 输出：&#123;'count': 10000, 'name': 'HeBei'&#125; obj2 = Province('HeNan', 3888)print obj2.__dict__# 获取 对象obj1 的成员# 输出：&#123;'count': 3888, 'name': 'HeNan'&#125; str:如果一个类中定义了str方法，那么在打印(print)对象时，默认输出该方法的返回值。 9. getitem、 setitem、 delitem 用于对象的索引操作，如字典。以上分别表示获取、设置、删除数据 12345678910111213141516171819#!/usr/bin/env python# -*- coding:utf-8 -*- class Foo(object): def __getitem__(self, key): print '__getitem__',key def __setitem__(self, key, value): print '__setitem__',key,value def __delitem__(self, key): print '__delitem__',key obj = Foo() result = obj['k1'] # 自动触发执行 __getitem__obj['k2'] = 'wupeiqi' # 自动触发执行 __setitem__del obj['k1'] # 自动触发执行 __delitem__ 10.getslice、setslice、delslice 用于对象的分片操作(如列表) 1234567891011121314151617class Foo(object): def __getslice__(self, i, j): print '__getslice__',i,j def __setslice__(self, i, j, sequence): print '__setslice__',i,j def __delslice__(self, i, j): print '__delslice__',i,j obj = Foo() obj[-1:1] # 自动触发执行 __getslice__obj[0:1] = [11,22,33,44] # 自动触发执行 __setslice__del obj[0:2] # 自动触发执行 __delslice__ 11. iter:迭代器 12345678910111213141516171819202122232425262728293031323334353637383940##case 1:class Foo(object): pass obj = Foo() for i in obj: print i # 报错：TypeError: 'Foo' object is not iterable## case 2:class Foo(object): def __iter__(self): pass obj = Foo() for i in obj: print i # 报错：TypeError: iter() returned non-iterator of type 'NoneType'## case 3:class Foo(object): def __init__(self, sq): self.sq = sq def __iter__(self): return iter(self.sq) obj = Foo([11,22,33,44]) for i in obj: print i 迭代的变种 1234567891011obj = iter([11,22,33,44]) for i in obj: print i############################obj = iter([11,22,33,44]) while True: val = obj.next() print val 4.7 旧式类和新式类 从Python2.2开始，Python 引入了 new style class（新式类） 新式类类似Java，有一个根类object，所有类都继承自根类object 新式类跟经典类的差别主要是以下几点: a.新式类对象可以直接通过class属性获取自身类型:type b.继承搜索的顺序发生了改变,经典类多继承属性搜索顺序: 先深入继承树左侧，再返回，开始找右侧;新式类多继承属性搜索顺序: 先水平搜索，然后再向上移动123456789101112131415161718192021222324252627282930313233343536373839404142434445# -*- coding:utf-8 -*- class A(object): """ 新式类 作为所有类的基类 """ def foo(self): print "class A" class A1(): """ 经典类 作为所有类的基类 """ def foo(self): print "class A1" class C(A): pass class C1(A1): pass class D(A): def foo(self): print "class D" class D1(A1): def foo(self): print "class D1" class E(C, D): pass class E1(C1, D1): pass e = E()e.foo() e1 = E1()e1.foo() c.新式类增加了slots内置属性，可以把实例属性的种类锁定到slots规定的范围之中。123456789101112131415161718#比如只允许对A实例添加name和age属性# -*- coding:utf-8 -*- class A(object): __slots__ = ('name', 'age') class A1(): __slots__ = ('name', 'age') a1 = A1()a = A() a1.name1 = "a1"a.name1 = "a"#A是新式类添加了__slots__ 属性,所以只允许添加 name age#A1经典类__slots__ 属性没用 d.新式类增加了getattribute方法1234567891011121314151617181920class A(object): def __getattribute__(self, *args, **kwargs): print "A.__getattribute__" class A1(): def __getattribute__(self, *args, **kwargs): print "A1.__getattribute__" a1 = A1()a = A() a.testprint "========="a1.test#A是新式类，每次通过实例访问属性，都会经过__getattribute__函数,#A1不会调用__getattribute__所以出错了 4.8 类的实例化 call方法 类的实例化主要通过init()函数和call()函数实现，其中init()较为常用，call()函数是一种让类像函数一样使用的特殊方法。 1234567891011121314151617181920212223class MyType(type): def __init__(self, what, bases=None, dict=None): super(MyType, self).__init__(what, bases, dict) def __call__(self, *args, **kwargs): obj = self.__new__(self, *args, **kwargs) self.__init__(obj) class Foo(object): __metaclass__ = MyType def __init__(self, name): self.name = name def __new__(cls, *args, **kwargs): return object.__new__(cls, *args, **kwargs) # 第一阶段：解释器从上到下执行代码创建Foo类# 第二阶段：通过Foo类创建obj对象obj = Foo() new方法 继承自object的新式类才有new new方法接受的参数虽然也是和init一样，但init是在类实例创建之后调用，而 new方法正是创建这个类实例的方法。 依照Python官方文档的说法，new方法主要是当你继承一些不可变的class时(比如int, str, tuple)， 提供给你一个自定义这些类的实例化过程的途径。还有就是实现自定义的metaclass。 12345678910111213141516# 创建一个类，继承int，并返回绝对值class PositiveInteger(int): def __init__(self, value): super(PositiveInteger, self).__init__(self, abs(value)) i = PositiveInteger(-3)print i#结果还是-3class PositiveInteger(int): def __new__(cls, value): return super(PositiveInteger, cls).__new__(cls, abs(value)) i = PositiveInteger(-3)print i#结果是 3 因为类的每一次实例化都是通过new实现的,通过重载类来实现单例 12345678910111213class Singleton(object): def __new__(cls): # 关键在于这，每一次实例化的时候，我们都只会返回这同一个instance对象 if not hasattr(cls, 'instance'): cls.instance = super(Singleton, cls).__new__(cls) return cls.instance obj1 = Singleton()obj2 = Singleton() obj1.attr1 = 'value1'print obj1.attr1, obj2.attr1print obj1 is obj2]]></content>
      <categories>
        <category>Python教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9.常用函数]]></title>
    <url>%2F2018%2F09%2F21%2FPython%2F9.%20%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Python 原创基础教程 第九章 常用函数 iter()&amp;next() 迭代器和生成器 123a=iter(x) //生成一个迭代器next(a） range() 12345678#从0到10range(10)#从1到11range(1,11)#从1到11，步长为3range(1,11,3) list() 把变量转换为list map() map(fuciton,iterable,…),第一个参数是一个函数，以后的参数的列表，map把列表中的值带入到函数(第一个参数)并输出值 map()的值在python2中是一个列表，在python3中是一个迭代器 1234567891011&gt;&gt;&gt;def square(x) : # 计算平方数... return x ** 2... &gt;&gt;&gt; map(square, [1,2,3,4,5]) # 计算列表各个元素的平方[1, 4, 9, 16, 25]&gt;&gt;&gt; map(lambda x: x ** 2, [1, 2, 3, 4, 5]) # 使用 lambda 匿名函数[1, 4, 9, 16, 25] # 提供了两个列表，对相同位置的列表数据进行相加&gt;&gt;&gt; map(lambda x, y: x + y, [1, 3, 5, 7, 9], [2, 4, 6, 8, 10])[3, 7, 11, 15, 19] filter() filter(function, iterable)函数用于过滤序列，过滤掉不符合条件的元素，返回由符合条件元素组成的新列表。function是过滤条件，iterable是可迭代对象。 12345678910111213141516def is_odd(n): return n % 2 == 1 newlist = filter(is_odd, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])print(newlist)#过滤奇数import mathdef is_sqr(x): return math.sqrt(x) % 1 == 0 newlist = filter(is_sqr, range(1, 101))print(newlist) #python2使用，返回列表list(newlist)newlist.__next__()#python3使用，返回迭代器#过滤平方根是整数的数]]></content>
      <categories>
        <category>Python教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.面向对象]]></title>
    <url>%2F2018%2F09%2F21%2FPython%2F5.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1-2%2F</url>
    <content type="text"><![CDATA[Python 原创基础教程 第五章 面向对象5.1 继承 继承实现子类继承父类的方法和属性 1234567class Animal: def eat(self): print("%s 吃 "%self.name） def drink(self): print("%s 喝 " %self.name) 12345678910111213141516171819class Cat(Animal): def __init__(self, name): self.name = name self.breed ＝ '猫' #属性不必再单独定义 def cry(self): print '喵喵叫' class Dog(Animal): def __init__(self, name): self.name = name self.breed ＝ '狗' def cry(self): print '汪汪叫' 5.5.1 多继承 可以继承多个类 继承类分为经典类和新式类 当前类或者父类继承了object类，那么该类便是新式类，否则便是经典类。 经典类时，多继承会按照深度优先查找覆盖方法 新式类时，多继承会按照广度优先查找覆盖方法 子类中，super()可以调用父类的属性和方法 调用super()的实例1234567891011121314151617181920212223242526272829class Parent(object): def __init__(self): self.parent = 'I\'m the parent.' print ('Parent') def bar(self,message): print ("%s from Parent" %message) class Child(Parent): def __init__(self): #super(FooChild,self).__init__() //python2语法 super().__init__() print ('Child') def bar(self,message): #super(FooChild, self).bar(message)//这里是python2的语法 super().bar(message) print ('Child bar fuction') print (self.parent) #继承父类属性 C = Child()C.bar('HelloWorld')#执行结果:#Parent#Child#HelloWorld from Parent#Child bar function#I'm the parent 多继承顺序实例12345678910111213141516171819202122232425262728class A: def say(self): print("A Hello:", self) class B(A): def eat(self): print("B Eating:", self) class C(A): def eat(self): print("C Eating:", self) class D(B, C): def say(self): super().say() print("D Hello:", self) def dinner(self): self.say() super().say() self.eat() super().eat() C.eat(self) d = D() d.eat() C.eat(d) D.__mro__ #类的一个继承顺序d.dinner() 5.2 封装 封装，即隐藏对象的属性和实现细节，仅对外公开接口，控制在程序中属性的读和修改的访问级别。 将内容封装到类 从某处调用被封装的内容(通过对象或者self) 1234567891011121314class B: #构造方法，根据类创建对象时自动执行 def __init__(self,name,age): self.name = name self.age = age def f1(self)： print(self.name,self.name) #自动执行__init__方法obj1 = B('anda',28)print(obj1.name) #直接调用对象属性obj1.f1() #obj1将self作为参数传递给f1(),因此self就是obj1，实现self的间接调用 5.3 多态 多态是同一个行为具有多个不同表现形式或形态的能力。 多态就是同一个接口，使用不同的实例而执行不同操作 实现多态的三要素(继承、重写、父类引用指向子类对象) 123456789101112131415161718192021222324252627class F1: pass class S1(F1): def show(self): print 'S1.show' class S2(F1): def show(self): print 'S2.show' # 由于在Java或C#中定义函数参数时，必须指定参数的类型# 为了让Func函数既可以执行S1对象的show方法，又可以执行S2对象的show方法，所以，定义了一个S1和S2类的父类# 而实际传入的参数是：S1对象和S2对象 def Func(F1 obj): """Func函数需要接收一个F1类型或者F1子类的类型""" print obj.show() s1_obj = S1()Func(s1_obj) # 在Func函数中传入S1类的对象 s1_obj，执行 S1 的show方法，结果：S1.show s2_obj = S2()Func(s2_obj) # 在Func函数中传入Ss类的对象 ss_obj，执行 Ss 的show方法，结果：S2.show 5.4 type()产生对象 Python中一切事物都是对象,类也是 类可由type类实力化产生 type() 函数如果你只有第一个参数则返回对象的类型，三个参数返回新的类型对象 创建类的两种方式: 12345678910111213141516# case 1:普通方式class Foo(object): def func(self): print 'hello wupeiqi' # case 2:特殊方式def func(self): print 'hello wupeiqi' Foo = type('Foo',(object,), &#123;'func': func&#125;)#type第一个参数：类名#type第二个参数：当前类的基类#type第三个参数：类的成员 5.5 类的特殊成员1. doc:表示类的描述 12345678class Foo: """ 描述类信息，这是用于看片的神奇 """ def func(self): pass print(Foo.__doc__)#输出：类的描述信息 2. module:表示当前操作对象在哪个模块 模块:组织函数和类的单位(类似java的一类一文件，有时不同模块可能有同名函数),例如Django 1print(obj.__module__) #输出对象所在模块 3. class：表示当前操作对象的是什么 类 1print(obj.__class__) #输出对象所在类 4. init(self,..):构造方法、类创建对象时自动执行 5. del(self,..):析构方法、当对象在内存释放时、自动触发执行。 此方法一般无须定义，因为Python是一门高级语言，程序员在使用时无需关心内存的分配和释放，因为此工作都是交给Python解释器来执行，所以，析构函数的调用是由解释器在进行垃圾回收时自动触发执行的。 6. call(self,..):除析构方法外，执行对象的另一种特殊方法,对象加括号执行 1234567891011class Foo: def __init__(self): pass def __call__(self, *args, **kwargs): print '__call__' obj = Foo() # 执行 __init__obj() # 执行 __call__ 7. dict:显示类(静态变量、方法)和对象(普通字段)的所以成员 123456789101112131415161718192021222324class Province: country = 'China' def __init__(self, name, count): self.name = name self.count = count def func(self, *args, **kwargs): print 'func' # 获取类的成员，即：静态字段、方法、print Province.__dict__# 输出：&#123;'country': 'China', '__module__': '__main__', 'func': , '__init__': , '__doc__': None&#125; obj1 = Province('HeBei',10000)print obj1.__dict__# 获取 对象obj1 的成员# 输出：&#123;'count': 10000, 'name': 'HeBei'&#125; obj2 = Province('HeNan', 3888)print obj2.__dict__# 获取 对象obj1 的成员# 输出：&#123;'count': 3888, 'name': 'HeNan'&#125; str:如果一个类中定义了str方法，那么在打印(print)对象时，默认输出该方法的返回值。 9. getitem、 setitem、 delitem 用于对象的索引操作，如字典。以上分别表示获取、设置、删除数据 12345678910111213141516171819#!/usr/bin/env python# -*- coding:utf-8 -*- class Foo(object): def __getitem__(self, key): print '__getitem__',key def __setitem__(self, key, value): print '__setitem__',key,value def __delitem__(self, key): print '__delitem__',key obj = Foo() result = obj['k1'] # 自动触发执行 __getitem__obj['k2'] = 'wupeiqi' # 自动触发执行 __setitem__del obj['k1'] # 自动触发执行 __delitem__ 10.getslice、setslice、delslice 用于对象的分片操作(如列表) 1234567891011121314151617class Foo(object): def __getslice__(self, i, j): print '__getslice__',i,j def __setslice__(self, i, j, sequence): print '__setslice__',i,j def __delslice__(self, i, j): print '__delslice__',i,j obj = Foo() obj[-1:1] # 自动触发执行 __getslice__obj[0:1] = [11,22,33,44] # 自动触发执行 __setslice__del obj[0:2] # 自动触发执行 __delslice__ 11. iter:迭代器 12345678910111213141516171819202122232425262728293031323334353637383940##case 1:class Foo(object): pass obj = Foo() for i in obj: print i # 报错：TypeError: 'Foo' object is not iterable## case 2:class Foo(object): def __iter__(self): pass obj = Foo() for i in obj: print i # 报错：TypeError: iter() returned non-iterator of type 'NoneType'## case 3:class Foo(object): def __init__(self, sq): self.sq = sq def __iter__(self): return iter(self.sq) obj = Foo([11,22,33,44]) for i in obj: print i 迭代的变种 1234567891011obj = iter([11,22,33,44]) for i in obj: print i############################obj = iter([11,22,33,44]) while True: val = obj.next() print val 12.new方法 继承自object的新式类才有new new方法接受的参数虽然也是和init一样，但init是在类实例创建之后调用，而 new方法正是创建这个类实例的方法。 依照Python官方文档，new方法主要是当你继承一些不可变的class时(比如int, str, tuple)， 提供给你一个自定义这些类的实例化过程的途径。还有就是实现自定义的metaclass。 12345678910111213141516# 创建一个类，继承int，并返回绝对值class PositiveInteger(int): def __init__(self, value): super(PositiveInteger, self).__init__(self, abs(value)) i = PositiveInteger(-3)print i#结果还是-3class PositiveInteger(int): def __new__(cls, value): return super(PositiveInteger, cls).__new__(cls, abs(value)) i = PositiveInteger(-3)print i#结果是 3 因为类的每一次实例化都是通过new实现的,通过重载类来实现单例 12345678910111213class Singleton(object): def __new__(cls): # 关键在于这，每一次实例化的时候，我们都只会返回这同一个instance对象 if not hasattr(cls, 'instance'): cls.instance = super(Singleton, cls).__new__(cls) return cls.instance obj1 = Singleton()obj2 = Singleton() obj1.attr1 = 'value1'print obj1.attr1, obj2.attr1print obj1 is obj2]]></content>
      <categories>
        <category>Python教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7. 字符串]]></title>
    <url>%2F2018%2F09%2F21%2FPython%2F7.%20%E7%89%B9%E6%AE%8A%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Python 原创基础教程 第七章 类方法中的特殊参数类参数self&amp;cls staticmethod(静态方法):可以没有self，当普通函数使用 classmethod(类方法):第一个参数是cls，代表类本身 123456789101112131415161718192021 class A(object): def foo1(self): print("Hello",self) @staticmethod def foo2(): print("hello") @classmethod def foo3(cls): print("hello",cls) &gt;&gt;&gt; a = A()&gt;&gt;&gt; a.foo1() #最常见的调用方式，但与下面的方式相同Hello &lt;__main__.A object at 0x9f6abec&gt;&gt;&gt;&gt; A.foo1(a) #这里传入实例a，相当于普通方法的selfHello &lt;__main__.A object at 0x9f6abec&gt;&gt;&gt;&gt; A.foo2() #这里，由于静态方法没有参数，故可以不传东西hello&gt;&gt;&gt; A.foo3() #这里，由于是类方法，因此，它的第一个参数为类本身。hello &lt;class '__main__.A'&gt;&gt;&gt;&gt; A #可以看到，直接输入A，与上面那种调用返回同样的信息。&lt;class '__main__.A'&gt; 函数参数（args &amp; *kwargs） *args 其中args只是个名字，可以是其他字母 1*args表示函数可以接受多个参数 实例1 123456def test_args(normal_arg, *args): print("first normal arg:" + normal_arg) for arg in args: print("another arg through *args :" + arg)test_args("normal", "python", "java", "C#") **kwargs意思相同，但参数形式是字典形式 实例212345678910def fun_kwargs(farg, **kwargs): print "arg:", farg for key in kwargs: print "another key and arg: %s: %s" % (key, kwargs[key]) fun_kwargs(farg=1, myarg2="two", myarg3=3) dic = &#123;"args2":"two", "args3":3&#125; fun_kwargs(fargs=1, **dic) #调用方式1 实例3 12345678def fun_kwargs1(arg1, arg2, arg3): print "arg1:", arg1 print "arg2:", arg2 print "arg3:", arg3 kwargs = &#123;"arg2":"two", "arg3":3&#125; fun_kwargs1(1, **kwargs)]]></content>
      <categories>
        <category>Python教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.类的系统成员]]></title>
    <url>%2F2018%2F09%2F21%2FPython%2F6.%20%E7%B1%BB%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%88%90%E5%91%98(%E5%86%85%E7%BD%AE%E5%B1%9E%E6%80%A7)%2F</url>
    <content type="text"><![CDATA[Python 原创基础教程 第六章 类的系统成员(内置属性) name和 main Python使用缩进对齐组织代码的执行，所有没有缩进的代码，都会在载入时自动执行。每个文件（模块）都可以任意写一些没有缩进的代码，并在载入时自动执行。为了区分 主执行代码和被调用文件，Python引入了变量： name。 当文件是被调用时， name的值为模块名 当文件被执行时， name的值为 ‘ main’ init和 new和 call new： 对象的创建，是一个静态方法，第一个参数是cls。(想想也是，不可能是self，对象还没创建，哪来的self) init ： 对象的初始化， 是一个实例方法，第一个参数是self。 123456class Foo(object): def __new__(cls, *args, **kwargs): print('a') Foo()#输出a call ： python中函数是一个对象，类也是一个对象，可以通过 call方法调用对象(如调用函数一样) 例1123456class Foo(object): def __call__(self): print('b') f = Foo()#类Foo可call f()#对象f可call 例2 123456789101112class Person(object): def __init__(self, name, gender): self.name = name self.gender = gender def __call__(self, friend): print（'My name is %s...'%self.name） print（'My gender is %s...'%self.gender print（'My friend is %s...'%friend）p = Person('anda','male')p('Tim') #call方法调用对象(函数的方法) 在python中，类的行为就是这样，new、init、call等方法不是必须写的，会默认调用，如果自己定义了，就是override,可以custom。既然override了，通常也会显式调用进行补偿以达到extend的目的。 str &amp; rept &amp; repr str让对象返回字符串的形式 12345678class Person(object): def __init__(self, name, gender): self.name = name self.gender = gender def __str__(self): return '(Person: %s, %s)'%(self.name, self.gender)p = Person('anda','male')print(p) # __str__() repr 返回一个可以用来表示对象的可打印字符串： 123456789class Person(object): def __init__(self, name, gender): self.name = name self.gender = gender def __str__(self): return '(Person: %s, %s)'%(self.name, self.gender) __repr__=__str__p = Person('anda','male')p #__repr__() 1234567891011121314151617class Fib(object): def __init__(self): pass def __call__(self,num): a,b = 0,1; self.l=[] for i in range (num): self.l.append(a) a,b= b,a+b return self.l def __str__(self): return str(self.l) __repr__=__str__ f = Fib()f(10) setitem&amp; getitem&amp;__ delitem() 使得对象和字典功能对应 setitem:每当属性被赋值的时候都会调用该方法，因此不能再该方法内赋值 self.name = value 会死循环 getitem:当访问不存在的属性时会调用该方法 delitem:当删除属性时调用该方法 dict:对象的字典值 123456789101112131415161718192021222324252627282930313233class A(object): def __init__(self): self['B'] = "BB" self['D'] = "DD" del self['D'] def __setitem__(self,name,value): ''''' @summary: 每当属性被赋值的时候都会调用该方法，因此不能再该方法内赋值 self.name = value 会死循环 ''' print "__setitem__:Set %s Value %s"%(name,value) self.__dict__[name] = value def __getitem__(self,name): ''''' @summary: 当访问不存在的属性时会调用该方法 ''' print "__getitem__:No attribute named '%s'"%name return None def __delitem__(self,name): ''''' @summary: 当删除属性时调用该方法 ''' print "__delitem__:Delect attribute '%s'"%name del self.__dict__[name] print self.__dict__ X = A()X['a']='aa'X['b']='bb'X.__dict__]]></content>
      <categories>
        <category>Python教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10. 字符串]]></title>
    <url>%2F2018%2F09%2F21%2FPython%2F10.%20%E6%96%87%E4%BB%B6%E5%92%8C%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[Python 原创基础教程 第十章 文件与异常1.文件操作12345# 1.txt 文件内容a: aaab: bbbc: cccd: ddd :d222 123456789data1 = open('1.txt') #open函数生成一个文件对象data2 = open('2.txt','w') #w是从头开始写，a是从文件尾开始写 参数‘w’，代表可写，无该文件时会创建该文件，默认为rdata2.write('hello /n world /n') #将字符串写入文件中data1.close() #关闭文件data2.close() 123data = open('1.txt')for i in data print(i) 2.异常处理 1 1234try: code1except: code2 #如果code1出现错误，执行code2部分 2 123456try: code1except ValueError: code2 #如果code1出现ValueError错误，执行code2部分 # 错误类型有很多，例如IOError() 3 123456try: code1except: code2finally: code3 #code3是无论是否出错，都会执行的代码块,例如文件关闭 4 1234567try: with open('1.txt','w') as data: print('It;s...',file=data)exceot IOError as err: print('File error'+str(err))#省去finnaly，with可以妥善关闭一个文件]]></content>
      <categories>
        <category>Python教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对当下高职教育的个人感想]]></title>
    <url>%2F2018%2F07%2F20%2F%E6%97%A5%E8%AE%B0%2F%E5%AF%B9%E5%BD%93%E4%B8%8B%E9%AB%98%E8%81%8C%E6%95%99%E8%82%B2%E7%9A%84%E4%B8%AA%E4%BA%BA%E6%84%9F%E6%83%B3%2F</url>
    <content type="text"><![CDATA[对当下高职教育，学历提升和上升通道的思考 说到教育，先谈一谈我们教育一件最重要的事 高考 不可否认，高考是当下我国最重要的考试，没有之一，无数人因此踏实不同的人生道路，去不同的城市，不同的大学，不同的专业，迎接不同的人生。 高考也是人生的第一次分水岭，十年磨一剑，去了一流大学的人，相对得到更好的资源和平台，也就是更好的发展，事实证明，这是大概率的情况。 对于一般本科的学生而言，相对前者有一个质的差距，无论就业的机会，还是学校四年的机会和经历，举例。外交部等部委到学校的直接招聘，海外和国内名校的保送名额，还有跨国企业的招聘，无论就业岗位和层次，都会有差距。 当然，从高考的选拔角度来说，应试能力和个人实力造成了这样的差距，公平竞争，通过高考选拔人才，这无可厚非。但我们不能忽略个人努力的在不同时期的差异。 无论高考结果与否，我认为，只要一个人在任何时刻省悟，并投入努力去拼搏，就应该有改变命运的机会。 出国&amp;考研 考研总的来说给了当下普通本科生一次“再高考”的机会，当今很多人，都是这个机会的受益者。通过考研，相对公平的考试和选拔制度，让大量人以“追求学术的名义”从新选择高校，从而进入名校，得到较好学校的就业和发展机会。 我无意笃定高考和考研对人生的决定性，只是它的重要性在当下中国具有普片意义。必须承认，高考不理想或未考研的学生中不乏优秀成功的人，但按比例和趋势看，这不具有普片意义，对大部分人来说，还是高考和考研提高了他们就业和发展的可能性，完成了一次质变。 以上说的，是客观问题。机会有了，成功与否很大程度上是个人努力决定的。高考成功，考研成功等等成功，机会只是一方面。但对于高职学生来说，这样的机会现在显的有点少。 高职教育 高职学生和大部分本科学生一样，同样的年龄，同样的体制和教育后开始新的旅程。 在这样一个大好年纪，无论处于任何一个环境和学历，人都有提高自己，追求更好生活的权力，更何况相对本科处于劣势的高职学生，特别那些优秀的高职学生。 然而现在的情况并没有这样的机会，一方面，专升本的考试升学率一直在降低，专生本并没有太多的学校可以选择，且不能跨省，这意味着专科教育就是针对本地为本地中小企业服务的教育，虽然专科教育按学生能力和社会需求，这样的定位并没有什么问题，但就个人通道而言，缺少上升路径。 人生而平等，广大专科生是否能有类似考研的机会呢？ 这机会意味着什么？ 我想一个优秀的高职学生，也可能会有改变努力命运的想法，如通过努力学习，去更好的大学，感受一下大学的生活和教育，有更好的平台和人生，去其他城市，从南到北，离开家乡去看看，闯一闯，趁年轻，看看外面的世界。 我的感想和建议 给高职学生一个这样的机会，在物质生活日益丰盛的今天，文化和精神的需求变得更为强烈，国家发展也处于由劳动密集型向科研创新型转变，需要这样的机会，提高全民整体的高等教育水平。 就我一线的从教感受而言，当下的高职学生，也对专升本考试日益重视，他们知道这个的意义和重要性，有一份少年本该有的渴望和梦想。]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>高职教育</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[0.算法分类]]></title>
    <url>%2F2018%2F06%2F06%2F%E7%AE%97%E6%B3%95%2Fp%20np%20npc%2F</url>
    <content type="text"><![CDATA[原创 进阶算法概述 算法分类(多项式分类) P问题 如果一个问题可以找到一个能在多项式的时间里解决它的算法，那么这个问题就属于P问题。 P是英文单词多项式的第一个字母。 NP问题 NP问题不是非P类问题。NP问题是指可以在多项式的时间里验证一个解的问题。 NP问题的另一个定义是，可以在多项式的时间里猜出一个解的问题。 NP问题一直都是信息学的巅峰。巅峰，意即很引人注目但难以解决。在信息学研究中，这是一个耗费了很多时间和精力也没有解决的终极问题，好比物理学中的大统一和数学中的歌德巴赫猜想等。 目前为止这个问题还“啃不动”。但是，一个总的趋势、一个大方向是有的。人们普遍认为，P=NP不成立，也就是说，多数人相信，存在至少一个不可能有多项式级复杂度的算法的NP问题。人们如此坚信P≠NP是有原因的，就是在研究NP问题的过程中找出了一类非常特殊的NP问题叫做NP-完全问题，也即所谓的 NPC问题。C是英文单词“完全”的第一个字母。正是NPC问题的存在，使人们相信P≠NP。 NP-hard P!=NP时，NP-hard属于比NP难的问题,只可以用一定运算（时间大于等于多项式运算时间）解决该问题，无法找到多项式的算法。 P=NP时，NP=NP-hard NPC问题 约化(Reducibility，有的资料上叫“归约”) : 一个问题A可以约化为问题B的含义即是，可以用问题B的解法解决问题A 参见《算法导论》：一元二次方程解一元一次方程的例子 一个问题约化为另一个问题，时间复杂度增加了，问题的应用范围也增大了。 通过对某些问题的不断约化，我们能够不断寻找复杂度更高，但应用范围更广的算法来代替复杂度虽然低，但只能用于很小的一类问题的算法。 再回想前面讲的P和NP问题，根据约化的传递性，如果不断地约化上去，不断找到能“通吃”若干小NP问题的一个稍复杂的大NP问题，那么最后能找到一个时间复杂度最高，并且能“通吃”所有的NP问题的这样一个超级NP问题，就是NPC问题。 只要解决了这个NPC问题，那么所有的NP问题都解决了。这种问题不只一个，它有很多个，它是一类问题。这一类问题就是传说中的NPC问题，也就是NP-完全问题。 NPC问题：a.它得是一个NP问题；b.所有的NP问题都可以约化到它。 （证明一个问题是 NPC问题也很简单。先证明它至少是一个NP问题，再证明其中一个已知的NPC问题能约化到它 常见NPC问题SAT问题0-1整数规划最大团ClIQUE顶点覆盖问题子集合问题哈密顿回路问题TSP问题http://www.matrix67.com/blog/archives/105]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三.贪心算法]]></title>
    <url>%2F2018%2F06%2F06%2F%E7%AE%97%E6%B3%95%2F3%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[原创 进阶算法概述 1.算法本质 在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的是在某种意义上的局部最优解。 贪心算法不是对所有问题都能得到整体最优解，关键是贪心策略的选择，选择的贪心策略必须具备无后效性，即某个状态以前的过程不会影响以后的状态，只与当前状态有关。 2.解题步骤类似一个一维数组遍历，每一步遍历都能获得局部最优解，每一次只考虑选取一个数据，它满足当时局部最优解。 伪代码 一般是一个双重循环，第一重循环是总循环，第二重循环是每次循环求局部最优解 3.例题 其他 贪心算法 贪心算法的本质：从问题的某一个初始解出发，向给定的目标推进。推进的每一步做一个当时看似最佳的贪心选择。不断的将问题规模缩小。并由所有的局部最优选择产生一个全局最优解 删数问题 从键盘输入一个高精度正整数N(N不超过200位），任意去掉S个数字，把剩下的数字组合成一个新的正整数，次序不变且剩下的数字组成的新数最小。输入：N（≤200位），S（1≤S≤10）例如： 输入 51428397 5 输出 123 代码(python) 123456789101112131415161718192021# 命令行输入输出# 删数问题print("输入一个整数")a = input()print("输入删除的位数")b = input()b = int(b)n = len(a) for i in range(b): x=len(a) for j in range(x): if (j+1)&lt;x: if a[j] &gt; a[j+1]: a = a[:j]+a[j+1:] break else: a = a[:j] breakprint(a) 首先：N超过200位，肯定要用字符串数组来进行存储。我们知道字符串数组隐含的’\0’作为结束符。当然，我们也可以用strlen()函数来直接计算字符串长度。 第二步，如何删除数字。假定只删除一个数字。如果数字从左到右为顺序增大，显然删除最后一个可以。如果不是顺序增加的。删除递减区间的第一个就行了。这样循环删除s个数字即可完成。 还要注意一点的是，每删除一个数字，就要从这个数组的第一个单元开始重新判断。所以，用当型循环比较合适。每判断到一个可以删除的数，就结束判断。 https://www.cnblogs.com/steven_oyj/archive/2010/05/22/1741375.html]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二.动态规划]]></title>
    <url>%2F2018%2F06%2F06%2F%E7%AE%97%E6%B3%95%2F2%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[原创 进阶算法概述 二.动态规划1.算法本质 状态 一个方程，用于表述问题的(1-n)通向公式，可以是求解过程中一个开始或一个结果 状态转移方程 状态与状态的关系公式，就是转移方程,比如状态k和状态k-1 2.解题步骤 二维数组填表 状态与状态的转移用一张二维表来表述，通过双重循环来逐渐把二维表填满，表每一行是一个状态，下一行是转移到另一个状态，最终填满二维表 3.例题3.1 0-1背包问题 问题描述 有N件物品和一个容量为==v==的背包。第i件物品的重量是==c[i]==(每一件物品只有一件，可以选择装或者不装，也就是问题0-1的意思)，价值是==w[i]==。求解将哪些物品装入背包可使价值总和最大。 状态 即f[i][v]表示前i件物品恰放入一个容量为v的背包可以获得的最大价值。 转移方程 1f[i][v]=max&#123;f[i-1][v],f[i-1][v-c[i]]+w[i]&#125; 伪代码 123456#c[i]=cost[i],w[i]=weight[i]for i=1..N for v=V..0 f[v]=max&#123;f[v],f[v-c[i]]+w[i]&#125;; 3.2 TSP问题 问题描述 Travelling Salesman Problem (TSP) 是最基本的路线问题。它寻求的是旅行者由起点出发，通过所有给定的需求点后，再次返回起点所花费的最小路径成本 状态 d(i,v)表示从顶点i出发，经过v中所有结点一次后的最小花费 转移方程 d(i,v)=min_{i\epsilon{v}}\{d(k,v)+c_{ki}\} 代码 123456789101112131415161718for(int j=1;j&lt;1&lt;&lt;(n-1);j++)&#123; for(int i=1;i&lt;n;i++)&#123; //j用二进制表示的城市集合 if(((1&lt;&lt;(i-1))&amp;j)==0)&#123; //i不在j表示的城市集合中 minDis=60000; for(int k=1;k&lt;n;k++)&#123; if(((1&lt;&lt;(k-1))&amp;j)!=0) &#123;//k表示的城市在j表示的城市集合中 temp=dis[i][k]+d[k][j-(1&lt;&lt;(k-1))]; if(temp&lt;minDis)&#123; minDis=temp; //所有k中最小的距离 &#125; &#125; &#125; &#125; d[i][j]=minDis; &#125; &#125; 其他动态规划算法通常用于求解具有某种最优性质的问题。在这类问题中，可能会有许多可行解。每一个解都对应于一个值，我们希望找到具有最优值的解。 动态规划算法与分治法类似，其基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解。 与分治法不同的是，适合于用动态规划求解的问题，经分解得到子问题往往不是互相独立的。若用分治法来解这类问题，则分解得到的子问题数目太多，有些子问题被重复计算了很多次。 如果我们能够保存已解决的子问题的答案，而在需要时再找出已求得的答案，这样就可以避免大量的重复计算，节省时间。我们可以用一个表来记录所有已解的子问题的答案。不管该子问题以后是否被用到，只要它被计算过，就将其结果填入表中。这就是动态规划法的基本思路。具体的动态规划算法多种多样，但它们具有相同的填表格式。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五.分支限界]]></title>
    <url>%2F2018%2F06%2F06%2F%E7%AE%97%E6%B3%95%2F5%E5%88%86%E6%94%AF%E9%99%90%E7%95%8C%2F</url>
    <content type="text"><![CDATA[原创 进阶算法概述 五.回溯算法1.算法本质 求解目标：回溯法的求解目标是找出解空间树中满足约束条件的所有解，而分支限界法的求解目标则是找出满足约束条件的一个解，或是在满足约束条件的解中找出在某种意义下的最优解。 求解思路:在分支限界法中，每一个活结点只有一次机会成为扩展结点。活结点一旦成为扩展结点，就一次性产生其所有儿子结点。在这些儿子结点中，导致不可行解或导致非最优解的儿子结点被舍弃，其余儿子结点被加入活结点表中。此后，从活结点表中取下一结点成为当前扩展结点，并重复上述结点扩展过程。这个过程一直持续到找到所需的解或活结点表为空时为止 2.算法步骤 利用一个队列，进行对树或图的广度优先遍历 伪代码 12345678910111213141516q = queue()q.put(s) # 插入原点v[s][s] = 0def f(x): while true: i=q.get() if !q.empty() : j=q.pull() #出队 v[s][j]=v[s][j-1]+s.value() if i != x: while s.next(): q.put(s.next()) #入队 else: break;f(x)print(min(v[s][x])) 3.典型应用3.1 单源最短路径3.2 TSP问题]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四.回溯算法]]></title>
    <url>%2F2018%2F06%2F06%2F%E7%AE%97%E6%B3%95%2F4%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[原创 进阶算法概述 四.回溯算法1.算法本质 解决多选择问题 选择时判断，符合条件继续，不符合条件返回 把问题的解空间转化成了图(深度优先)或者树(左右根)的结构表示。 2.算法步骤2.1 算法基本的步骤思想为： 在搜索过程中动态产生问题的解空间 只保存从根结点到当前扩张结点的路径 深度优先方式搜索解空间，能找出满足约束条件的所有解 2.2 伪代码:12345678def Backtrack(t) if t&gt;n : output(x) #记录可行解 else: for i in ResultTree X[t] = h(i) # h(i)表示当前结点处的第i个可选值 if constraint(t)&amp;&amp;bount(t) #解空间的约束函数和限界函数 Backtrack(t+1) 3.回溯算法应用3.1 八皇后问题 八皇后问题是一个以国际象棋为背景的问题：如何能够在 8×8 的国际象棋棋盘上放置八个皇后，使得任何一个皇后都无法直接吃掉其他的皇后？ 为了达到此目的，任两个皇后都不能处于同一条横行、纵行或斜线上。八皇后问题可以推广为更一般的n皇后摆放问题：这时棋盘的大小变为n×n，而皇后个数也变成n。当且仅当 n = 1 或 n ≥ 4 时问题有解 Input 无输入 Output 多种 123456789101112131415161718192021222324252627No. 11 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 No. 21 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 No. 31 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 求解思路 观察棋盘坐标 同一斜线上的“/”上的坐标点，横纵坐标之和相同 同一斜线上的“\”上的坐标点，横纵坐标之差相同 基本步骤 判断皇后冲突 递归得到结果 输出所有结果 代码 1234567891011121314151617181920212223242526272829# state是一个元组，存放每行的坐标,从首行开始# pos是当前行不与之前皇后冲突的位置&gt;&gt;&gt; def confict(state, pos): nextY = len(state) if pos in state: return True '''判断斜线''' for i in range(nextY): if nextY-pos == i-state[i]: return True if nextY+pos == i+state[i]: return True return False&gt;&gt;&gt; def queens(num, state=()): if num-1 == len(state): #若当前是最后一次选择 for i in range(num): #遍历选择的所有值，此次选择不与前值冲突，以元祖形式返回该值 if not confict(state, i): yield (i,) else: for pos in range(num): #当前不是最后一次选择： #遍历所有取值，若不与之前的选择序列冲突， #“返回”当前选择取该值的基础上，接来的选择结果。 if not confict(state, pos): for result in queens(num, state+(pos,)): yield (pos,) + result &gt;&gt;&gt; for i in list(queens(8)): print(i) 3.2 数独问题3.3 集合问题3.4 图着色问题]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一.分冶算法]]></title>
    <url>%2F2018%2F06%2F06%2F%E7%AE%97%E6%B3%95%2F1%E5%88%86%E5%86%B6%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[原创 进阶算法概述 一.分冶算法1.算法本质 一个问题规模为N的问题可以分解为k个规模较小的问题，这些子问题相互独立且与原问题性质相同，求出子问题的解可以得到原问题的解。 2.算法步骤 分解 求解（子问题比原问题易求） 合并 2.1 伪代码 伪代码 1234567891011121314151617181920212223242526分治法的伪代码： v divide_and_conquer(proplem p) &#123;//n为问题规模 if(|p|&lt;n0)//n0为一阈值 solve(p); else &#123; divide p into smaller subproblem P1,P2,...Pk; for(i=1;i&lt;=k;i++) &#123; yi=divide_and_conquer(Pi); #可能用到递归 return merge(y1,y2,...,yk); &#125; &#125; &#125; 3.例题(python)3.1求众数(一个数组中重复最多的数) 思想 （1）快速排序 （2）求中位数,及其重数(重复数) （3）计算出中位数的最左端和最右端的位置(如果有重复)，然后分割成2段数组 （4）中位数个数与左端数组个数比较，中&lt;左 即最大众数可能存在左端，将左端再进行2段分割（递归）直到 中 &gt; 左为止 代码 12345678910def mode(l,r) #l,r两个参数分别代表数组两端，a是数组 med = median(a,l,r) //寻找中位数 split = (a,med,l,r,l1,r1)//分割数组 if largest&lt;(r1-l1+1): largest=r1-l1+1 element=med;//element是众数 if(l1-1&gt;largest): mode(1,l1-1) if(r-r1&gt;largest): mode(r1+1,r) 3.2 合并排序 基本思想:将一组数分为两组数，分别对两组数进行排序，将合并好的子集合合并到排好序的集合中 1234567891011void MergeSort(Type a[],int left,int right)&#123; if(left &lt; right) &#123; int i = (left + right)/2 &#125; MergeSort(a,left,i) MergeSort(a,i+1,right) Merge(a,b,left,i,right)//合并数组到b Copy(a,b,left,right)//复制回数组a&#125; 3.3 快速排序12345678910111213141516def Qsort(a,left,right): l = left r = right key = a[0] while(l&lt;r): while(l&lt;r &amp;&amp; a[r]&gt;=key): r = r-1 a[l] = a[r] while(l&lt;r &amp;&amp; a[l]&lt;=key): l = l+1 a[r] = a[l] a[0]= key Qsort(a,left,l-1) Qsort(a,l+1,right)Qsort(a,0,len(a-1)) 3.4 重复元素排列问题 思想 n个元素的全排列减小的n-1个元素的全排列，直至减小的1个元素的排列，就不需要排列 其他分治法所能解决的问题一般具有以下几个特征： 1) 该问题的规模缩小到一定的程度就可以容易地解决 2) 该问题可以分解为若干个规模较小的相同问题，即该问题具有最优子结构性质。 3) 利用该问题分解出的子问题的解可以合并为该问题的解； 4) 该问题所分解出的各个子问题是相互独立的，即子问题之间不包含公共的子子问题。 第一条特征是绝大多数问题都可以满足的，因为问题的计算复杂性一般是随着问题规模的增加而增加； 第二条特征是应用分治法的前提它也是大多数问题可以满足的，此特征反映了递归思想的应用； 第三条特征是关键，能否利用分治法完全取决于问题是否具有第三条特征，如果具备了第一条和第二条特征，而不具备第三条特征，则可以考虑用贪心法或动态规划法。 第四条特征涉及到分治法的效率，如果各子问题是不独立的则分治法要做许多不必要的工作，重复地解公共的子问题，此时虽然可用分治法，但一般用动态规划法较好。 http://blog.jobbole.com/83944/]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.正则表达式]]></title>
    <url>%2F2018%2F05%2F30%2FPython%2F8.%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Python 原创基础教程 第八章 正则表达式基础 对字符串匹配的一套规则 123456789import re #正则表达式的包#1pattern = re.compile('\d+\.\d+') #创建一个正则表达式对象str = "1.12321, 432423.32 abc 123.123 342"result = pattern.findall(str)#2result = re.findall('\d+\.\d+',str) compile() 编译正则表达式,返回一个正则表达式对象 findall() 找到字符串中所有的匹配(以空格为间隔) search() 匹配整个字符串，直到找到一个匹配 match() 从开始匹配字符串是否符合正则表达式 split() 将匹配到的字符串当做分割点,对字符串进行分割，最终分割成列表 sub() 替换 字符串前缀 u/U: 表示unicode字符串 1.不是仅仅是针对中文, 可以针对任何的字符串，代表是对字符串进行unicode编码。 2.一般英文字符在使用各种编码下, 基本都可以正常解析, 所以一般不带u；但是中文, 必须表明所需编码, 否则一旦编码转换就会出现乱码。 3.建议所有编码方式采用utf8 r/R: 非转义的原始字符串 1.与普通字符相比，其他相对特殊的字符，其中可能包含转义字符，即那些，\反斜杠加上对应字母，表示对应的特殊含义的，比如最常见的”\n”表示换行，”\t”表示Tab等。 2.而如果是以r开头，那么说明后面的字符，都是普通的字符了，即如果是“\n”那么表示一个反斜杠字符，一个字母n，而不是表示换行了。 3.以r开头的字符，常用于正则表达式，对应着re模块。 b: bytes 1.python3.x里默认的str是(py2.x里的)unicode, 2.bytes是(py2.x)的str, b”“前缀代表的就是bytes 3.python2.x里,b前缀没什么具体意义，只是为了兼容python3.x的这种写法 正则表达式表 字符 header 1 header 2 . 任意字符 row 1 col 1 row 1 col 2 row 2 col 1 row 2 col 2 位置 位置 - ^ 匹配字符串的开头 $ 匹配字符串的结尾 预定义字符集 预定义字符 - \d 数字:[0-9] \D 非数字:\d \w 字母数字 \W 非字母数字 数量词 数量词 - * 匹配前一个字符0次或无限次 + 匹配前一个字符1次或无限次 ？ 匹配前一个字符0次或1次 {m} 匹配前一个字符m次 {m,n} 匹配前一个字符m至n次，m和n可以省略，上下界默认为0和无穷 括号 括号 header 2 （） 表示一个组，匹配结果缩小为()里面的组(不能匹配换行符) ex: gr(a\ e)y,匹配a或e […] 表示一个字符，ex:[akj]表示a或k或j ... 表示不在里面的一个字符 {m} 匹配前一个字符m次 {m,n} 匹配前一个字符m至n次，m和n可以省略，上下界默认为0和无穷 特例 . 和 .? 前者匹配结果重复最大的字符串，后者匹配结果重复 的最小字符串 123s = 'aabab'r1 = re.search('a.*b',s) #结果为aababr2 = re.search('a.*?b',s) #结果为aab 匹配反斜杆 需要4个反斜杆才能匹配1个反斜杆 匹配换行符 compile函数加参数re.DOTALL ((?:.|\n)*?)其中(?:.)是非捕获组]]></content>
      <categories>
        <category>Python教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.2 重要关键字]]></title>
    <url>%2F2018%2F05%2F30%2FPython%2F3.1%20%E9%87%8D%E8%A6%81%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[Python 原创基础教程 3.2 与函数有关的重要关键字3.2.1 lambda表达式 一种函数的简写形式,类似匿名函数 123456789101112func = lambda x:x+1func(1)#func为函数名，x为参数， :后是表达式func2 = lambda x,y,z:x+y+zfunc2(1,2,3)#匿名函数的形式def f(x): return lambda y:x+ya = f(2) # a是一个函数对象a(22) 3.2.2 global关键字在编写程序的时候，如果想为一个在函数外的变量重新赋值，并且这个变量会作用于许多函数中时，就需要告诉python这个变量的作用域是全局变量。此时用global语句就可以变成这个任务，也就是说没有用global语句的情况下，是不能修改全局变量的。 12345678910# coding:utf-8var = 0def fun(): global var # 此处是global对var的声明，只有声明后，才可以在这个函数中改变var的值 var = 5print var # 0fun()print var # 5#如果不加global声明， 第二次打印var还是0 3.2.3 yield关键字(生成器) 迭代器和生成器的概念 1.迭代器协议 对象需要提供next方法，它要么返回迭代中的下一项，要么就引起一个StopIteration异常，以终止迭代 可迭代对象就是：实现了迭代器协议的对象 协议是一种约定，可迭代对象实现迭代器协议，Python的内置工具(如for循环，sum，min，max函数等)使用迭代器协议访问对象 通过dir()查看是否实现iter即迭代器协议 2.生成器协议 生成器可以不立即返回全部结果，而是需要的适合逐个返回结果，因此生成器自动实现迭代器协议 生成器函数，通过在函数里添加yield代替return，yield一次返回一个结果 示例1234567891011def g(N): res=[] for i in range(N): res.append(i*i) rerurn res for item in g(5) def g(N) 生成器表达式，类似列表推导，返回一个迭代器，而不是全部结果123squares1 = [x**2 for x in range(5)]#结果，一个列表squares2 = (x**2 for x in range(5))#生成器next(squares2) 用yield改写函数 123456def fab(max): n, a, b = 0, 0, 1 while n &lt; max: print b a, b = b, a + b n = n + 1 1234567def fab(max): n, a, b = 0, 0, 1 while n &lt; max: yield b # print b a, b = b, a + b n = n + 1 a.yield 的作用就是把一个函数变成一个generator，带有yield的函数不再是一个普通函数，Python解释器会将其视为一个generator，调用fab(5)不会执行 fab 函数，而是返回一个 iterable 对象！ b.在 for 循环执行时，每次循环都会执行 fab 函数内部的代码，执行到 yield b 时，fab 函数就返回一个迭代值，下次迭代时，代码从 yield b 的下一条语句继续执行，而函数的本地变量看起来和上次中断执行前是完全一样的，于是函数继续执行，直到再次遇到 yield。 c.改写fab函数如果通过返回List能满足复用性的要求，但是更有经验的开发者会指出，该函数在运行中占用的内存会随着参数max的增大而增大，如果要控制内存占用，最好不要用List来保存中间结果，而是通过 iterable 对象来迭代。]]></content>
      <categories>
        <category>Python教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[教程2 Django 操作Mysql(增加数据)]]></title>
    <url>%2F2018%2F05%2F03%2Fdjango%2FA%20mysql%E6%93%8D%E4%BD%9C%E4%B8%80%2F</url>
    <content type="text"><![CDATA[Django框架,以MVT(mvc+T)模式高效开发web,超越spring系列的存在 Django 操作Mysql(增加数据)版本 Django:2.0.5 Python:3 Mysql:5.7.20 PyMySQL:0.8.0 一、配置数据库(包括model层) settings.py文件 1.配置mysql连接123456789101112DATABASES = &#123; 'default': &#123; #'ENGINE': 'django.db.backends.sqlite3', #'NAME': os.path.join(BASE_DIR, 'db.sqlite3'), 'ENGINE': 'django.db.backends.mysql', 'NAME': 'testdata', 'USER': 'root', 'PASSWORD': 'xxxxx', #数据库密码 'HOST': '127.0.0.1', 'PORT': '3306' &#125;&#125; 2.注册app 命令行生成app 需要先在init.py文件中导入pymysql,参见后面数据库操作1 1&gt;python manage.py startapp appname 再在配置文件中配置123456789INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'appname' #最后一行加上app名] models.py 定义models.py中的类 12345678910 # -*- coding: utf-8 -*-from __future__ import unicode_literalsfrom django.db import models# Create your models here.class message(models.Model): username = models.CharField(max_length=20) password = models.CharField(max_length=15) 二、数据库操作(models-&gt;mysql)1.pymysql 区别于python2，python3中没有MysqlDB,所以python3不能连接到数据库，会报错”no modul MysqlDB”,替代包有pyMySQL,Mysqlclient. 在站点文件中的init.py中导入12import pymysqlpymysql.install_as_MySQLdb() 2.命令行操作 生成数据库迁移类1python manage.py makemigrations appname 把迁移类迁移到数据库1python manage.py migrate 数据库操作 迁移前123&gt;mysql -u root -p;&gt;password;&gt;create database testdata; 迁移后 12345&gt;show databases;&gt;use testdata;&gt;show tables;&gt;desc appname_message #查看同步的数据表结构&gt;select * from appname_message #查看数据表结构 三、view层 views.py文件 导入包 123from __future__ import unicode_literalsfrom appname import modelsfrom django.shortcuts import render_to_response 定义insert函数，用于将网页数据插入到数据库123456def insert(request): if request.method == "POST": username = request.POST.get("username", None) password = request.POST.get("password", None) models.message.objects.create(username=username, password=password) return render_to_response('insert.html') 定义list函数,用于将数据库数据显示到网页 123def list(request): people_list = models.message.objects.all() return render_to_response("showuser.html",&#123;"people_list":people_list&#125;) 四、control层(urls.py) 控制访问路径123456789from django.conf.urls import urlfrom django.contrib import adminfrom appname import viewsurlpatterns = [ url(r'^insert/',views.insert), url(r'^show/',views.list), url(r'^admin/', admin.site.urls),] 五、网页部分(templates) 在根文件夹下创建templates文件夹,并在setting.py中配置TEMPLATES的’DIRS’ 12345678910111213141516TEMPLATES = [ &#123; 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [os.path.join(BASE_DIR,'templates')], #配置templates的路径 'APP_DIRS': True, 'OPTIONS': &#123; 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], &#125;, &#125;,] 插入数据页面insert.html1234567891011121314&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;用户登录&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action="/insert/" method="post"&gt; &lt;input type="text" name="username"/&gt; &lt;input type="password" name="password"/&gt; &lt;input type="submit" value="提交"&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 显示数据页面showuser.html 12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;信息展示&lt;/h1&gt; &lt;table &lt;tr&gt; &lt;th&gt;用户名&lt;/th&gt; &lt;th&gt;密码&lt;/th&gt; &lt;/tr&gt; &#123;% for line in people_list %&#125; &lt;tr&gt; &lt;td&gt;&#123;&#123;line.username&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;line.password&#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;% endfor %&#125; &lt;/table&gt;&lt;/body&gt;&lt;/html&gt; 六、csrf报错 页面提交数据报错(403)，在setting.py中关闭CSRF 123456789MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', #'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware',] -参考: https://blog.csdn.net/yf999573/article/details/53081196 https://blog.csdn.net/it_dream_er/article/details/52093362]]></content>
      <categories>
        <category>Django框架</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[教程1 Django初学实践，创建简易blog]]></title>
    <url>%2F2018%2F05%2F03%2Fdjango%2FA%E5%AE%9E%E6%88%98%E6%95%99%E7%A8%8B(%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2)%2F</url>
    <content type="text"><![CDATA[Django框架,以MVT(mvc+T)模式高效开发web,超越spring系列的存在 1.前期工作以下命令在命令行下完成 创建项目 该命令生成manage.py文件和4个基本配置文件，如果项目已有相关文件，就无需再使用该命令 1django-admin.py startproject mysite 生成文件如下： mysite - - init.py - settings.py - urls.py - wsgi.py manage.py - 运行服务器 12python manage.py runserver#可更改端口:python manage.py runserver 8003 创建应用(app) 1python manage.py startapp blog 2.mvc设计 models(models.py)用于定义数据结构 12345678910111213141516#from __future__ import unicode_literals#该命令负责转码，非必须使用from django.contrib import adminfrom django.db import modelsclass BlogPost(models.Model): title = models.CharField(max_length =150) body = models.TextField() timestamp = models.DateTimeField()# BlogPost类是django.db.models.Model的一个子类 。#它有变量title(blog的标题)，body(blog的内容部分)，#timestamp(blog的发表时间)。 class BlogPostAdmin(admin.ModelAdmin): list_display = ('title','timestamp') views(views.py) 该层用于定义request和response，就是用户请求后获得什么样的页面 123456789from blog.models import BlogPostfrom django.shortcuts import render_to_responsedef myBlogs(request): blog_list = BlogPost.objects.all() return render_to_response('BlogTemplate.html',&#123;'blog_list':blog_list&#125;)def Hello(request): return HttpResponse('&lt;h1&gt;hello disanda&lt;h1&gt;') controller(urls.py) 123456789from django.conf.urls import urlfrom django.contrib import adminfrom blog.views import *urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^myBlogs/$',myBlogs), url('',Hello) ] 3.templates模版网站(MTV模式)在根项目文件下创建templates文件夹(用于存放前端网页)，并在根配置文件(settings.py)配置templates路径。 ‘DIRS’: [os.path.join(BASE_DIR,’templates’)], 12345678910111213141516TEMPLATES = [ &#123; 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [os.path.join(BASE_DIR,'templates')], 'APP_DIRS': True, 'OPTIONS': &#123; 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], &#125;, &#125;,] 基模版页1234567891011121314151617181920212223242526272829303132333435#名为base.html&lt;!DOCTYPE html&gt;&lt;html lang="zh"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;标题&lt;/title&gt;&lt;/head&gt;&lt;style type="text/css"&gt; body&#123; color: #efd; background: #BBBBBB; padding: 12px 5em; margin:7px; &#125; h1&#123; padding: 2em; background: #675; &#125; h2&#123; color: #85F2F2; border-top: 1px dotted #fff; margin-top:2em; &#125; p&#123; margin:1em 0; &#125;&lt;/style&gt;&lt;body&gt;&lt;h1&gt;XX博文&lt;/h1&gt;&lt;h3&gt;小生不才，但求简约！&lt;/h3&gt;&#123;% block content %&#125;&#123;% endblock %&#125;&lt;/body&gt;&lt;/html&gt; 具体网页(和views.py中的网页对应)12345678910#名为BlogTemplate.html&#123;% extends "base.html" %&#125; &#123;% block content %&#125; &#123;% for post in blog_list %&#125; &lt;h2&gt;&#123;&#123; post.title &#125;&#125;&lt;/h2&gt; &lt;p&gt;&#123;&#123; post.timestamp &#125;&#125;&lt;/p&gt; &lt;p&gt;&#123;&#123; post.body &#125;&#125;&lt;/p&gt; &#123;% endfor %&#125; &#123;% endblock %&#125; 4.配置工作2.1前期配置 在setting.py的INSTALLED_APP列表中配置app 123456789INSTALLED_APPS = ( 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'blog',) 在setting.py中配置数据库连接 2.2 model相关(写完model之后) 记录model变动 完成后会生成model中对应类的文件 1python manage.py makemigrations 同步数据库 1python manage.py migrate 创建超级管理员 1python manage.py createsuperuser 在admin.py中注册model模型中的类 12from blog.models import BlogPostadmin.site.register(BlogPost)]]></content>
      <categories>
        <category>Django框架</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[教程3 Django操作Mysql(删除、修改数据)]]></title>
    <url>%2F2018%2F05%2F03%2Fdjango%2FA%20mysql%E6%93%8D%E4%BD%9C%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[Django框架,以MVT(mvc+T)模式高效开发web,超越spring系列的存在 Django操作Mysql(删除、修改数据)一.前期工作 生成app 命令行输入1&gt;python manage.py startapp webname 配置setting.py 123456789101112131415161718192021222324#数据库DATABASES = &#123; 'default': &#123; #'ENGINE': 'django.db.backends.sqlite3', #'NAME': os.path.join(BASE_DIR, 'db.sqlite3'), 'ENGINE': 'django.db.backends.mysql', 'NAME': 'testdata2', 'USER': 'root', 'PASSWORD': '121212', #数据库密码 'HOST': '127.0.0.1', 'PORT': '3306' &#125;&#125;#注册appINSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'web',] 配置init.py 123# 先安装pymysql包import pymysqlpymysql.install_as_MySQLdb() 二.MVC配置 model层(models.py) 建几个类就对应几张表 123456789101112131415from django.db import models# Create your models here.class Classes(models.Model): titile = models.CharField(max_length=32) m = models.ManyToManyField("Teachers")class Teachers(models.Model): name = models.CharField (max_length=32)class Student(models.Model): username = models.CharField(max_length=32) age = models.IntegerField() gender = models.BooleanField() cs = models.ForeignKey(Classes,on_delete=models.CASCADE,) views层(views.py) 先把views.py删除,用一个文件夹views替代，在文件夹下建立classes.py、students.py、teachers.py三个文件,分别代表三个视图 123456789101112131415161718192021222324252627282930313233343536#其中classes.py如下:from django.shortcuts import renderfrom django.shortcuts import redirectfrom web import modelsdef get_classes(request): cls_list = models.Classes.objects.all() return render(request, 'get_classes.html', &#123;'cls_list': cls_list&#125;)def add_classes(request): if request.method == "GET": return render(request, 'add_classes.html') elif request.method == 'POST': title = request.POST.get('titile') models.Classes.objects.create(titile=title) return redirect('/get_classes.html')def del_classes(request): nid = request.GET.get('nid') models.Classes.objects.filter(id=nid).delete() return redirect('/get_classes.html')def edit_classes(request): if request.method == 'GET': nid = request.GET.get('nid') obj = models.Classes.objects.filter(id=nid).first() return render(request, 'edit_classes.html', &#123;'obj': obj&#125;) elif request.method == 'POST': nid = request.GET.get('nid') title = request.POST.get('title') models.Classes.objects.filter(id=nid).update(titile=title) return redirect('/get_classes.html') control层(urls.py文件) 123456789101112from django.conf.urls import urlfrom django.contrib import adminfrom web.views import classesurlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^get_classes.html$', classes.get_classes), url(r'^add_classes.html$', classes.add_classes), url(r'^del_classes.html$', classes.del_classes), url(r'^edit_classes.html$', classes.edit_classes), url(r'',classes.get_classes),#首页默认页面] 三、模版层(templates) 先创建templates文件夹，在settings.py设置templates文件夹路径(参考上一讲) get_classes.html 123456789101112131415161718192021222324252627282930313233343536&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt; &lt;a href="/add_classes.html"&gt;添加&lt;/a&gt;&lt;/div&gt;&lt;div&gt; &lt;table border="1"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;ID&lt;/th&gt; &lt;th&gt;名称&lt;/th&gt; &lt;th&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &#123;% for row in cls_list %&#125; &lt;tr&gt; &lt;td&gt;&#123;&#123; row.id &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; row.titile &#125;&#125;&lt;/td&gt; &lt;td&gt; &lt;a href="/del_classes.html?nid=&#123;&#123; row.id &#125;&#125;"&gt;删除&lt;/a&gt; | &lt;a href="/edit_classes.html?nid=&#123;&#123; row.id &#125;&#125;"&gt;编辑&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &#123;% endfor %&#125; &lt;/tbody&gt; &lt;/table&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; add_classes.html 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action="add_classes.html" method="POST"&gt; &#123;% csrf_token %&#125; &lt;input type="text" name="titile" /&gt; &lt;input type="submit" value="提交" /&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; edit_classes.html 12345678910111213&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt; &lt;form action="/edit_classes.html?nid=&#123;&#123; obj.id &#125;&#125;" method="POST"&gt; &#123;% csrf_token %&#125; &lt;input type="text" name="title" value="&#123;&#123; obj.titile &#125;&#125;" /&gt; &lt;input type="submit" value="提交"/&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 四、其他 同步到数据库操作 命令行两步操作 123&gt;python manage.py makemigrate webname #输出modles到数据库到中间文件&gt;python namge.py migrate #同步到数据库 中文设置 Django和Mysql本身默认数据库编码不能识别中文数据，需将设置 1.setting.py文件 1234567891011121314151617DATABASES = &#123; 'default': &#123; #'ENGINE': 'django.db.backends.sqlite3', #'NAME': os.path.join(BASE_DIR, 'db.sqlite3'), 'ENGINE': 'django.db.backends.mysql', 'NAME': 'testdata3', 'USER': 'root', 'PASSWORD': '121212', #数据库密码 'HOST': '127.0.0.1', 'PORT': '3306', 'CHARSET':'utf8', 'COLLATION':'utf8_general_ci', &#125;&#125;//增加CHARSET字段//增加增加COLLATION字段 2. mysql设置 通过设置设置编码utf-8支持中文 1234567891011121314151617&gt;show create database xxx//查看xxx数据库编码&gt;show create table xxx//查看表xxx编码&gt;alter table table_name convert to character set utf8;//更改表编码&gt;create database xxx character set utf8//创建数据库xxx时设定编码&gt;alter database xxx character set utf8;//修改数据库xxx时设定编码&gt;insert into xxx values ("小明")；//测试中文 参考https://www.cnblogs.com/nulige/p/6529175.html]]></content>
      <categories>
        <category>Django框架</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3. Python函数]]></title>
    <url>%2F2017%2F12%2F02%2FPython%2F3.%20%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[第三章 函数 Python原创教程，持续更新 3.1 函数本质 函数，也称方法，是一系列运算集合,一个函数本质由以下要素构成: 名字 参数 运算流程(方法体内) 返回值 其中参数和返回值是可选的1234567891011121314151617181920# 无参数，无返回值def fun1(): print("hello world")# 有两个参数x，ydef fun2(x,y): z=x+y print(z) # 无参数，有返回值 def fun3(): z=100 return z # 有参数，有返回值(最常见的函数)def fun4(x,y,z): w=x+y*z return w]]></content>
      <categories>
        <category>Python教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.Python变量]]></title>
    <url>%2F2017%2F12%2F01%2FPython%2F1.Python%E5%8F%98%E9%87%8F(%E5%8C%85%E5%90%AB1.1%E5%92%8C1.2)%2F</url>
    <content type="text"><![CDATA[Python 原创基础教程 第一章 变量1.1 前言学习一门编程语言，首先要知道编程语言的作用，编程语言简单来说，就是用来写程序的，程序是计算机应用的载体，程序员通过编写程序进而操作计算机。 这里和我们平时操作计算机不同，我们操作计算机更多的是使用程序，但编写程序的目的更多是制作程序，所以有必要更全面深入的了解计算机。 计算机本质就是完成数据的计算，这里包括对数据的存储，对数据的计算，最后把计算的结果进行传输，对应这些功能的计算机三大部件如下： 计算 存储 IO cpu:运算器ALU cpu寄存器 - - 高速缓存 - - 内存: 物理内存、虚拟内存 - - 外存：硬盘、移动存储(U盘，移动硬盘)、ROM BIOS - 计算、存储、IO称为CPU三大核心部件，也是编程所主要涉及到的三大部件。其中程序语言的变量是放在计算机存储的部件中，循环和判断等流程控制语句是靠cpu去完成相应控制和计算。 1.2 基础变量介绍变量是编程语言存储数据的方式，编程语言中把变量按不同类型进行分类，每一种变量存储不同类型的数据，不同的变量是不同的数据结构。 数据结构是计算机存储数据时，数据的组成方式，也是计算机软件开发的基础学科。 基础变量是最基本的数据结构，常见的有数字(包括整数，浮点数)，字符串，数组等。 python中定义基础变量不需要声明类型（系统自动判断），每个变量使用前必须被赋值 123456789counter = 100 # 整型变量#其他语言要指定变量类型:int counter = 100miles = 1000.0 # 浮点型变量name = "runoob" # 字符串# 输出变量print(counter)print(miles)print(name) 1.3 基础数据类型 数字(包括整型和浮点型) 字符串 用单引号，或者双引号扩起来 12345678n1 = 123n2 = 123.123s1 = 'abc's2 = "abc"n1 #python通过‘#’号注释代码n2 print(s1) #在python中通过print()函数可以输出变量，直接输出亦可print(s2) 列表 列表是集合类数据结构，类似数组，它主要存储多个数据，每个数据也称为一个元素。列表内数组的元素类型可以不同,用中括号定义。 1l1 = [1,"2a",3] 列表里面的元素也可以是列表，这样就构成多维列表 12345# 列生成表达式# 生成m*n行列表# test = [[0 for i in range(m)] for j in range(n)]test = [[0 for i in range(5)] for j in range(5)] #生成5*5的列表，元素值都是0 元组 元组类似列表，但元组里的元素不可改变，但可以包含可变对象，例如列表。元组用小括号定义。 1tup1 = ('physics', 'chemistry', 1997, 2000); 集合 是一种无序且不重复的序列，基本功能是成员包含测试或者去重，可以使用大括号或者set（）生成元组。 123a=&#123;1,2,3&#125;b=&#123;1,2,3,3&#125;#结果相同 字典 列表是有序对象的结合，字典是无序对象的集合。字典通过键值存取数据，列表通过位移偏移量存取。 a.键必须唯一 b.键必须是不可变数据类型 c.通过大括号和“：”来定义字典，或通过下标索引定义 12345dict1 = &#123;'name': 'runoob','code':1, 'site': 'www'&#125;dict2 = &#123;&#125;dict2['one'] = "a1" # 为字典dict2添加键为字符串“one”，值为字符串“a1”的值dict[2] = 'a2' # 为字典dict2添加键为数字2，值为字字符串“2”的值 d. 其他构建字典的方法 12345678&gt;&gt;&gt;dict([('Runoob', 1), ('Google', 2), ('Taobao', 3)])&#123;'Taobao': 3, 'Runoob': 1, 'Google': 2&#125; &gt;&gt;&gt; &#123;x: x**2 for x in (2, 4, 6)&#125;&#123;2: 4, 4: 16, 6: 36&#125; &gt;&gt;&gt; dict(Runoob=1, Google=2, Taobao=3)&#123;'Taobao': 3, 'Runoob': 1, 'Google': 2&#125; e. 字典结构自带的常用函数 1.get()：获得键的值2.items()：以列表方式获得字典 12345dict1 = &#123;'name': 'runoob','code':1, 'site': 'www'&#125;dict1.get('name') #获取字典dict1中键为字符串'name'的值，效果等同于dict1['name']list = dict1.items() #返回字典的列表格式，并把它赋值给list变量 1.3.1 数据类型转换 不同数据类型之间，有的可以相互转换，有的不能,python常用自带函数进行转换，常见实例如下: 12345678910#1x = '178' #将字符串中的数字转换为整形y = int(x)# x = '178a'# y =int(x)# 报错,字符型不能转换为int#2x2 = 'abcd'y2 =list(x2) #将字符串转换为list 1.3.2 列表详解 列表是python中最常见的数据结构，类似数组。其中一些自带的函数具有代表性，用于其他各类数据结构中。 包括列表的添加，删除，索引，切片 123456789101112131415161718192021222324252627la = [1,'a',&#123;'a'&#125;,&#123;1:'a'&#125;,True,[1,2],1]#常见操作len(la)la.count('1')la.index('a')la+lala*3#添加删除操作la.append('b')la.extend('abc')la.insert(3,'xxx')la.remove(1)la.remove(la[0])la.pop()del la[2] 其中切片和索引是列表操作的精髓，其同样可以用到字符串和很多类似的一维数据结构中 1234567891011121314151617la[0] #第1个元素la[1]la[-1] #倒数第1个元素la[2:5] #第2到第4个元素la[2:] #第2到最后一个元素(终点默认，不包括最后一个)la[:5] #第1个元素到最后1个元素(起点默认)la[2:6:2] #2到5个元素，步跳为2la[::2] #第一个到最后一个元素，步跳为2(起点和终点默认)la[::-1] #列表反转，步跳为-1 列表推导，一种通过循环来定义数据的方式 123a = [1,2,3]b = [a*60 for i in a] 1.3.3 字符串的其他操作 分割字符串split() 12345678s1 = 'a:b'x,y=s.split(':')s2 = 'a:b:c'x,y,z=s.split(':',2) #第二个参数代表两个分割(分为三个部分)，默认是一个分割xyz 列表插入函数,join() 12345678#'x'.join(list)#表示把x插入到list的每个元素之间，形成一个字符串#1x3 =['1','a','b','2']y3 =''.join(x3)y3&gt;&gt;&gt; '1ab2' #输出字符串]]></content>
      <categories>
        <category>Python教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.Python流程控制]]></title>
    <url>%2F2017%2F12%2F01%2FPython%2F2.%20Python%20%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[第二章 流程控制 Python原创教程，持续更新 2.1 简介 流程控制指程序设计中语言最基础的运行流程,主要包括三种结构，顺序结构，分支结构，循环结构。 每种结构的实现语句在所有编程语言中都大致相同，主要是分支结构的if判断语句，和循环结构的while语句和for语句。 顺序结构 正常程序的顺序 分支结构 if判断语句 循环结构 while循环语句 for循环语句 2.2 if语句2.2.1 逻辑表达式 逻辑表达式是条件判断的方法。通过逻辑运算符两边数字等于、大于、小于或不等于等。若关系式条件成立，则返回bool值true，否则返回bool值false 逻辑运算符主要有: 123456789101112&gt; 大于# 5 &gt; 4# 条件成立，返回ture&lt; 小于# 5 &lt; 4# 条件不成立，返回false== 等于&gt;= 大于或等于&lt;= 小于或等于!= 不等于 2.2.2 if判断语句判断语句通过逻辑表达式(condition)的返回值，选择语句往返回值true处执行或false处执行 12345678910# 公式if 条件判断: 表达式 # 若 条件判断 返回值为true执行 表达式elif condition_2: statement_block_2 # 若condition_2返回值为true执行statement_block_2else: statement_block_3 # # 若condition_3返回值为flase执行statement_block_3 1234567# 示例var1 = 100if var1&gt;100: print ("1 - if 表达式条件为 true") print (var1)else: print(var1+"&lt;100") 2.3 while语句2.3.1 while循环 循环是重复执行某一段代码的程序语句，一般通过条件判断的结果执行循环，当条件为true时执行循环，当条件为false时循环结束。 python中没有do..while循环 1234567# 公式while 判断语句： 判断成立就执行循环语句#while惯例是提前定义一个变量，用于执行while的判断，并在循环语句中改变这个变量,以便判断语句能在循环一定次数后停止 12345678# 用while求一个1，2，3...100相加的结果sum = 0n = 1 # 提前定义的变量 while counter &lt;= 100: sum = sum + counter counter += 1 #通过自加改变这个变量,自加到100时循环停止 print("1 到 %d 之和为: %d" % (n,sum)) 2.3.2 while..else循环123456count = 0while count &lt; 5: print (count, " 小于 5") count = count + 1else: print (count, " 大于或等于 5") while简单形式12345flag = 1 while (flag): print ('欢迎访问菜鸟教程!') print ("Good bye!") 2.4 for循环123456for &lt;variable&gt; in &lt;sequence&gt;: &lt;statements&gt;else: &lt;statements&gt;#&lt;variable&gt;是自定义的变量#&lt;sequence&gt;是一组数，可以是集合，列表，元祖等 range(函数):生成一组数 12345678range(10)#数字0-9range(10,15)#数字10-15range(10,100,5)#生成10-100的数，每个数相差(步调为)5 for实例 1234567# 1for x in [1,2,3,4,5]: print(x) # 2for y in range(10,100,5) print(x)]]></content>
      <categories>
        <category>Python教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树&相关算法]]></title>
    <url>%2F2017%2F12%2F01%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%26%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95%2F%E4%BA%8C%E5%8F%89%E6%A0%91%2F</url>
    <content type="text"><![CDATA[python实战基础《数据结构和算法》 类实现 定义类 123456789class Node(): def __init__(self,left=None,right=Node,data=0): self.left=left self.right=right self.data=data class Tree(): def __init__(self,root=0): self.root=root 生产一个二叉树 1234567891011n1=Node(data=1)n2=Node(n1,None,2) //左儿子n1，右没有儿子n2n3=Node(data=3)n4=Node(data=4)n5=Node(n3,n4,5)n6=Node(n2,n5,6)n7=Node(n6,None,7)n8=Node(data=8)root=Node(n7,n8,'root')bt=Tree(root) 生成二叉树 123456789101112131415161718192021class BTree(): def __init__(self, root=0): self.root = root def is_empty(self): if self.root is None: return True else: return False def create(self): temp = input('enter a value:') if temp is '#': return 0 treenode = Node(data=temp) if self.root is None: self.root = treenode treenode.left = self.create() treenode.right = self.create() 二叉树的遍历 前序遍历（根-左-右）a.递归123456def pre_order(tree): if tree==None: return 0 print(tree.data) pre_order(tree.left) pre_order(tree.right） b.用栈 12345678910111213def front_stack(tree): """利用堆栈实现树的先序遍历""" if tree == None: return myStack = [] node = tree while node or myStack: while node: #从根节点开始，一直找它的左子树 pre(node.date), myStack.append(node) node = node.lchild node = myStack.pop() #while结束表示当前节点node为空，即前一个节点没有左子树了 node = node.rchild]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>基础算法</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[glance]]></title>
    <url>%2F2017%2F12%2F01%2Fopenstack%2Fglance%2F</url>
    <content type="text"><![CDATA[openstack教程系列 glanceOpenStack Image Service（Glance）是IaaS的核心组件 1.简介 openstack目的是为用户创建一定配置需求的虚拟机 openstack用image创建以及重构虚拟机 openstack允许用户upload一定数量的image供创建虚拟机使用，至于image的数量，则有用户相关的tenant的quota来限定。 2.镜像状态 quewed:镜像的初始化状态 saving：数据上传的中间状态 active：镜像上传成功后的状态 -killed:错误镜像的状态，镜像不可读 -deleted：镜像不可用，且在一定时间后自动清空，类似“回收站”的文件 3.对比进程状态3.1 进程&amp;线程 进程（process） 和线程（thread）是操作系统的基本概念 计算机的核心是CPU，它承担了所有的计算任务。就像一座工厂，时刻在运行。 假定工厂的电力有限，一次只能供给一个车间使用。也就是说，一个车间开工的时候，其他车间都必须停工。背后的含义就是，单个CPU一次只能运行一个任务。 进程就好比工厂的车间，它代表CPU所能处理的单个任务。任一时刻，CPU总是运行一个进程，其他进程处于非运行状态。 一个车间里，可以有很多工人。他们协同完成一个任务。线程就好比车间里的工人。一个进程可以包括多个线程。 车间的空间是工人们共享的，比如许多房间是每个工人都可以进出的。这象征一个进程的内存空间是共享的，每个线程都可以使用这些共享内存。 相关知识 CPU中，进程是资源的最小单位，线程是执行的最小单位 一个线程使用某一共享内存时，其他线程必须等它结束，才能使用这一块内存。 一个防止共享内存使用出错的方法。是上锁，先用的线程上锁，后面的线程排队，等锁打开再进去。这就叫“互斥锁”（Mutual exclusion，缩写 Mutex），防止多个线程同时读写某一块内存区域。 线程池与上面的原理类似，只能同时n个线程使用，大于n的在后面排队。这时的解决方法，就是在门口挂n把钥匙。进去的人就取一把钥匙，出来时再把钥匙挂回原处。后到的人发现钥匙架空了，就知道必须在门口排队等着了。这种做法叫做“信号量”（Semaphore），用来保证多个线程不会互相冲突。 举例 开个QQ，开了一个进程；开了迅雷，开了一个进程。 在QQ的这个进程里，传输文字开一个线程、传输语音开了一个线程、弹出对话框又开了一个线程。 所以运行某个软件，相当于开了一个进程。在这个软件运行的过程里（在这个进程里），多个工作支撑的完成QQ的运行。 3.2 进程状态 参考：http://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>云平台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高数基础]]></title>
    <url>%2F2017%2F11%2F22%2Fmath%2F%E9%AB%98%E6%95%B0%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[高数基础 导数a.y’=dy/dx b.y’的值为曲线在该点切线的斜率 极值在数学分析中，函数的最大值和最小值（最大值和最小值）被统称为极值（极数），是给定范围内的函数的最大值和最小值（本地 或相对极值）或函数的整个定义域（全局或绝对极值）。 a.求导数$f’(x)=0$的根（值） b.该点为极值（一定范围内） 单调性分为单调递增和单调递减 a.当f’(x)&gt;0$时，函数单调递增 b.当$f’(x)&lt;0$时，函数单调递减 连续性]]></content>
      <categories>
        <category>高数基础</category>
      </categories>
      <tags>
        <tag>公式</tag>
        <tag>高数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初等函数图形]]></title>
    <url>%2F2017%2F11%2F22%2Fmath%2F%E5%9B%BE%E5%BD%A2%2F</url>
    <content type="text"><![CDATA[图形 1.直线a.斜率（切线）b.截距c.直线上的点d.平行，相交 2.圆锥曲线2.1椭圆椭圆（Ellipse）是平面内到定点F1、F2的距离之和等于常数（大于|F1F2|）的动点P的轨迹，F1、F2称为椭圆的两个焦点。其数学表达式为：|PF1|+|PF2|=2a（2a&gt;|F1F2|）。 a.设椭圆中心点为(h,k)椭圆公式为:$\frac{(x-h)^2}{a^2}+\frac{(y-k)^2}{b^2}=1$(焦点在a，b中的较大的点)b.其中$c^2=a^2-b^2$(2c为两焦点的距离，简称焦距)c.离心率e=c/a,其中$e\in(0,1)$,椭圆越扁，离心率越大; 2.2抛物线平面内，到定点与定直线的距离相等的点的轨迹叫做抛物线。其中定点叫抛物线的焦点，定直线叫抛物线的准线。 标准方程：特点： 2.3双曲线平面内与两个定点F1,F2的距离的差的绝对值等于一个常数(常数为2a，小于|F1F2|)的轨迹称为双曲线;平面内到两定点的距离差的绝对值为定长的点的轨迹叫做双曲线 a.│|MF1|-|MF2│|=2ab.准线 x=±$a^2$/c(焦点在x轴)c.实轴：曲线在焦点所在轴的交点虚轴：相对实轴的相对轴（无交点）（a-&gt;实轴点，b-&gt;虚轴点，c-&gt;焦点。）$a^2$+$b^2$=$c^2$d.渐近线：把双曲线等式右边的1换成0，就是渐进线 三角形s=1/2ah(a是底，h是高)s=1/2ac*sin b(b角对应的边为b) 正弦定理$\frac{sinA}{a}=\frac{sinB}{b}=\frac{sinC}{c}$其中a、b、c为边，A、B、C为边对应的角 余玹定理cos a= $\frac{a^2+b^2+c^2}{2bc} $ 最小正周期a.三角函数相加最小正周期是各个函数的周期的最小公倍数b.三角函数相乘时要化简]]></content>
      <categories>
        <category>高数基础</category>
      </categories>
      <tags>
        <tag>公式</tag>
        <tag>高数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[概率]]></title>
    <url>%2F2017%2F11%2F22%2Fmath%2F%E6%A6%82%E7%8E%87%2F</url>
    <content type="text"><![CDATA[概率 排列$ A_n^m = \frac{n!}{(n-m)!} $ 组合a. $ C_n^m = \frac{n!}{m!(n-m)!} $ b.$ C_n^m =C_n^t (t=n-m)$ c.$ C_{n+1}^m = C_n^m + C_n^{m-1}$ d.$ C_n^0+C_n^1+\ldots +C_n^n = 2^n $ e.$ C_n^m = \frac{A_n^m}{m!} $ 等差数列通项公式：$a_n = a_1 + (n-1)*d$求和公式：$S=\frac{n(a_1+a_n)}{2}$ 样本方差总体各单位变量值与其算术平均数的离差的平方，然后再对此变量取平均数，就叫做样本方差。样本方差用来表示一列数的变异程度。]]></content>
      <categories>
        <category>高数基础</category>
      </categories>
      <tags>
        <tag>公式</tag>
        <tag>高数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初等函数]]></title>
    <url>%2F2017%2F11%2F22%2Fmath%2F%E5%88%9D%E7%AD%89%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[初等函数 三角函数 常用公式$sina^2+cos^2=1 $ $tana^2+1=seca^2$ $1+cot^2=csca^2$ 角度转换／／2／／3／／4 奇偶关系除了$cos a$是偶函数外，其他三个是奇函数 二倍角关系／／二倍角1 和差角公式／／2 正切函数$\tan a$//正切 余切函数$cos a$／／余切 对数函数$y=\log_ax$／／ 幂函数$y=x^a $(a为有理数) y=x ,y=$x^3$为奇函数 y=$x^2$,y=$x^4$为偶函数 指数函数$y=a^x$(a为常数，且 a&gt;0,a$\neq$1)定义域为R,常数是指固定不变的数值]]></content>
      <categories>
        <category>高数基础</category>
      </categories>
      <tags>
        <tag>公式</tag>
        <tag>高数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[游泳自学教程]]></title>
    <url>%2F2017%2F11%2F20%2F%E6%97%A5%E8%AE%B0%2F%E5%85%B3%E4%BA%8E%E6%B8%B8%E6%B3%B3%2F</url>
    <content type="text"><![CDATA[游泳的自学教程前言 ~游泳的前世今生感性地说游泳，除了星光和大海、就是对水的热爱。一种在船尾看着尾随鱼群想跳下去的冲动，一种搏击海浪的激情。 作为从小游泳游到大的人，可以说直到现在游的并不好。从小学花几百块和表哥参加师大的暑期的游泳班，到学校组织夏立营被同班的游泳好手淹个半死。很长时间并没有学会游泳。 直到有一天，在澄江。一个之前小时候双脚踩进青苔石块，就想伸手捞鱼的地方，一个后来偶然发现有着渔舟唱晚、天水一线的地方。瞬间学会了游泳。 可以说我对游泳的感觉是一直不会，一直再固执的坚持游，毕竟不太会游也可以游，主要目的是减肥。 总结下来，很多年因为偶然和勤奋等多种因素，还是长进不少。这里打算写一份课外教程，分享一些自学游泳的感悟。 !学游泳的keypointsa.学会总在一瞬间： 游泳很具实践性，也就是本能，这也是为什么小孩更容易学会的原因。当然，像我这样也属于后天才逐渐掌握，就是也有理论的作用。 对于成年人来学游泳，必要的是多游，多练，当你掌握了一个关键技巧后，你的游泳技术就会上一个台阶 b.必要的技巧: 1.水中平衡（这点非常重要）： 123是入门的标志，因为掌握水中的平衡是区别你在水中是**竖着**走还是**横着**走的关键，也是通俗说的是否会“换气”、和是否怕“淹水”等问题的解决的标志。 2.学青蛙或小狗一样在水中前进 12也是“蛙泳”和“自由泳”的学样式学法，通过根据动物在水中的动作，进行模仿学样，得到 **横着** 在水中前进的方法 3.改进姿势 123毕竟我们和动物结构是有区别的、动物的很多动作我们不能完全模仿，也不适合人，这时候就需要逐步“微调”，逐渐得到适合人且效率与舒适兼顾的游泳姿势。 4.体能 123这其实很好理解，也比较简单。就像跑步，体能不好，怎么跑？也是大多数热爱游泳的一个目的吧，锻炼身体，增强体能。 5.身体协调 1234这是一个调节，就是游泳中每个动作的改进和适应，需要身体其它部位的协调，这在游泳中显得特别突出。因为游泳是**全身性运动**，你手在动的时候其他部位也在动。有时你觉得手的姿势不对，你调整手的姿势，但是你之前的动作和身体其他部位的动作（例如腿部）动作是协调的。这时挑战需要特别注意身体协调的配套适应改进。 c.其他 我基本是自学的蛙泳和自由泳，蛙泳游的时间比较长，基本能保证正常速度在水中游蛙泳半个小时不会累。自由泳是研究生期间看一些教程和自己规划点练习学会的，前期游的不好，很累，现在能保证比蛙泳略快的前提下游20分钟不会感觉累。 之后如果有时间的话，我会针对以上5点，把自己游泳的心得整理出来，作为自学游泳的一个教程，分享给想自学游泳或者准备自学游泳的同学们。]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>运动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nova组件相关技术]]></title>
    <url>%2F2017%2F11%2F20%2Fopenstack%2Fnova%2F</url>
    <content type="text"><![CDATA[一、RabbitMQ个组件通过消息队列实现通讯 二、AMQP协议RabbiteMQ是其中一个实现1.多信道 2.异步 三层实现1.传输层帧处理、信道复用、错误检测、数据表示 2.会话层负责客户端至服务器的通讯，包括可靠性、同步机制、和错误处理 3.模型层定义一套命令，客户端使用这些命令来实现这些功能 对比TCP/IP五层协议1.物理层IEEE 802.1-802.2 2.数据链路层：PPPEthernet：局域网通信标准 3.网络层（关于路由）：IPARP:地址解析协议RARPICMP 4.传输层TCP:提供ip环境下的可靠传输UDP 5.应用层(表示层、会话层) HTTP FTP NFS SNMP SMTP:(simple mail transfer protocol),由源地址到目的地址的邮件传送规则 DNS：(domain namesystem),ip地址和域名映射的一个分布式数据库 Telnet 三、Nova-Scheduler过滤（filter）：过滤不能满足条件的节点 计算权值（weight）：通过“重要性”计算出哪个节点调度 类比学习《操作系统》中的进程调度1.什么是进程（与线程的区别） 2.进程的三种状态 3.进程调度的算法 a.先进先出 b.短进程优先 c.轮询(按钟表时间分配给进程)]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>云平台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Devstack集成安装（ubuntu下）]]></title>
    <url>%2F2017%2F11%2F20%2Fopenstack%2FDevstack%2F</url>
    <content type="text"><![CDATA[Ubuntu 16.04下安装openstack教程（使用Devstack） 安装前的准备1.下载安装虚拟机vm 2.安装ubuntu16.04 3.安装git 1$ apt install git 一、基本步骤1.添加用户（Devstack要以非root用户运行，但需要sudo权限） 1$ sudo useradd -s /bin/bash -d /opt/stack -m stack //关于useradd命令的参数意义如下，供参考：1234567891011121314151617181920212223-c&lt;备注&gt;：加上备注文字。备注文字会保存在passwd的备注栏位中；**-d&lt;登入目录&gt;：指定用户登入时的启始目录；** -D：变更预设值；-e&lt;有效期限&gt;：指定帐号的有效期限； -f&lt;缓冲天数&gt;：指定在密码过期后多少天即关闭该帐号； -g&lt;群组&gt;：指定用户所属的群组； -G&lt;群组&gt;：指定用户所属的附加群组； **-m：自动建立用户的登入目录；** -M：不要自动建立用户的登入目录； -n：取消建立以用户名称为名的群组；-r：建立系统帐号； **-s：指定用户登入后所使用的shell；**-u：指定用户id。 2.给予stack用户sudo权限123$ echo "stack ALL=(ALL) NOPASSWD: ALL" | sudo tee /etc/sudoers.d/stack$ sudo su - stack//这里注意区别su -和su，带-是指切换用户的时候同时切换shell环境 3.下载Devstack 12$ git clone https://git.openstack.org/openstack-dev/devstack$ cd devstack 4.创建local.conf配置文件 用来预置openstack root密码注：conf读写权限默认无法写入，用chmod更改1234567$vi conf//以下写入conf[[local|localrc]]ADMIN_PASSWORD=secretDATABASE_PASSWORD=$ADMIN_PASSWORDRABBIT_PASSWORD=$ADMIN_PASSWORDSERVICE_PASSWORD=$ADMIN_PASSWORD 注：安装时刚开始会叫设置各组件安装密码，建议设置成一样的方便记忆 12./stack.sh//启动脚本开始安装 二、安装过程：安装大约持续一个小时。 之后组件keystone、glance、nova、cinder、neutron和 horizon安装成功。 客户机可访问外网，网络设置为Floating IPs。 可通过web浏览器访问horizon ，链接为http://9.115.112.111/dashboard 亦可访问keystone，链接为http://9.115.112.111/identity/ 可在shell中执行1source openrc 然后使用openstack命令行工具管理Devstack。 目录/opt/stack/tempest下存放了用来测试openstack平台的测试用例。 三、常用错误解决办法http://blog.csdn.net/xiongchun11/article/details/52679110 (遇到问题，把问题解决继续./stack.sh) 1.permission deniedsudo chown stack:stack 文件绝对路径 a.在安装各组建时容易报这个错误,把组建的文件名更改组和用户即可 2.devstack could not determine a suitable url这一般是ip问题，在配置文件conf中添加host_ip(内网) https://docs.openstack.org/devstack/latest/]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>云平台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openStack网络组件]]></title>
    <url>%2F2017%2F11%2F20%2Fopenstack%2F%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[概述 一、发展历程第一个版本 nova-network123452010年openstack第一个版本网络组件为：nova-network功能：网络管理，包括ip分配、组网、以及网络模型等。 提供主要模型有： 1234567891011a.扁平网络(flat network)：创建虚拟主机时，组件会从预定子网中取一个空闲ip，并将网络信息写入虚拟主机的配置文件。* 在同一个子网中的虚拟主机可以相互ping通a+:带DHCP的flat newwork：在子网中自动为虚拟主机分配ip和物理地址b.vlan网络():vlan的意思是Virtual Local Area Network,就是虚拟局域网 第二个版本 Quantum随Openstack的Folsom版本发布 1.提供给租户api,使得租户能控制两层网络，管理ip地址 2.支持插件式网络组件，像Open vSwitch,Cisco,Linux Bridge,Nicira NVP 3.支持不同层的网络 4.支持隧道技术 隧道技术（Tunneling）是一种通过使用互联网络的基础设施在网络之间传递数据的方式。使用隧道传递的数据（或负载）可以是不同协议的数据帧或包。隧道协议将其它协议的数据帧或包重新封装然后通过隧道发送。新的帧头提供路由信息，以便通过互联网传递被封装的负载数据。 5.支持3层转发和多重路由 6.提供负载均衡api（试用） 第三版 NeutronQuantum这名字侵权，更名为Neutron 1.提供更为稳定的负载均衡api 2.支持端到端的IPSec VPN 3.面向租户的防火墙服务注：截止2017.11,很多openstack云还在用nova-network，因为它简单，稳定。 Neutron构成1.APIa.插件的“零件” b.网络、子网、端口的查询 c.增加、删除、更新的操作 2.插件存储当前逻辑网络的配置信息 a.可以用SQLlite和MySQL b.存储逻辑网络和物理网络的对应关系 c.与交换机通信实现对应关系 3.Open vSmitch:开放虚拟交换 虚拟交换就是利用虚拟平台，通过软件的方式形成交换机部件。 跟传统的物理交换机相比，虚拟交换机同样具备众多优点，一是配置更加灵活。一台普通的服务器可以配置出数十台甚至上百台虚拟交换机，且端口数目可以灵活选择。 例如，VMware的ESX一台服务器可以仿真出248台虚拟交换机，且每台交换机预设虚拟端口即可达56个；二是成本更加低廉，通过虚拟交换往往可以获得昂贵的普通交换机才能达到的性能 OpenvSmitch需要访问的表： Tables_in_neutron agents allowedaddresspairs dnsnameservers externalnetworks extradhcpopts floatingips ipallocationpools ipallocations ipavailabilityranges networkdhcpagentbindings networks ovs_network_bindings ovs_tunnel_allocations ovs_tunnel_endpoints ovs_vlan_allocations portbindingports ports quotas routerl3agentbindings routerroutes routers securitygroupportbindings securitygrouprules securitygroups subnetroutes subnets Neutron 结构图 ovs &amp; ovnhttp://blog.csdn.net/cusor/article/details/18213977]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>云平台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openStack集成安装]]></title>
    <url>%2F2017%2F11%2F20%2Fopenstack%2FopenStack%E9%9B%86%E6%88%90%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[官方文档https://docs.openstack.org/pike/ 使用Devstack组件keystone、glance、nova、cinder、neutron和 horizon安装成功 http://blog.csdn.net/ysbj123/article/details/77771065 http://blog.csdn.net/mygrus/article/details/53816022 使用Fuelhttps://www.cnblogs.com/dongdongwq/p/5627532.html http://blog.csdn.net/qq_21398167/article/details/51611487 使用Packstack (CentOS)https://wiki.openstack.org/wiki/Packstack https://github.com/openstack/packstack http://blog.csdn.net/violet_echo_0908/article/details/52049372 使用openshithttp://blog.csdn.net/justinshane/article/details/50097839]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>云平台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Packstack集成安装(CentOS 7)]]></title>
    <url>%2F2017%2F11%2F20%2Fopenstack%2FPackstak%E9%9B%86%E6%88%90%E5%AE%89%E8%A3%85(CentOS)%2F</url>
    <content type="text"><![CDATA[Packstack 集成安装(CentOS 7)CentOS, Red Hat Enterprise Linux (RHEL)两个版本可用 安装前准备(部署在一台主机上)a.一键安装,首选保证centOS能上网 b.虚拟机主机硬件设置中cpu打开VT-X c.同步系统时间 d.虚拟机主机硬件设置内存8g以上 1.首先安装yum若报错：1Ropodate is over 2 weeks old 解决： 123456yum clean allyum updateyum makecache //将源更新保存至本地缓存 2.安装packstack源和命令12345$ sudo yum install -y http://rdo.fedorapeople.org/rdo-release.rpm//用于配置安装源$ sudo yum install -y openstack-packstack//安装packstack命令 3.安装1$ packstack --allinone 4.常见错误1.apply puppet controller.pp卡住 解决：同步系统时间 12345678$ yum instal ntp ntp date//安装网络时间协议$ ntpdate cn.pool.ntp.org// 同步系统时间$ hwclock --systohc//写入硬件（否则下次重启失效）]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>云平台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keystone(v3) 简介]]></title>
    <url>%2F2017%2F11%2F20%2Fopenstack%2Fkeystone%2F</url>
    <content type="text"><![CDATA[keystone(v3) 简介 核心概念User(用户):服务的用户，可以是人、系统或服务，只要是openstack服务的对象都可以称为用户。 Tenant(租户)：可以理解为人、项目或者组织拥有资源的集合，在一个租户中可以拥有很多个用户，这些用户可以根据权限划分使用租户的资源。 Role(角色)：用于分配操作的权限，角色可以指定给用户，用户会获得对应该角色的权限。 Token(认证)：指的是一串比特值或者字符串，用来作为访问资源的记号。token中含有可访问资源的范围 keystone交互过程 首先用户向Keystone提供自己的身份验证信息，如用户名和密码。Keystone 会从数据库中读取数据对其验证，如验证通过，会向用户返回一个 token，此后用户所有的请求都会使用该token进行身份验证。如用户向 Nova 申请虚拟机服务，nova 会将用户提供的 token 发给 Keystone 进行验证，Keystone会根据token判断用户是否拥有进行此项操作的权限，若验证通过那么nova会向其提供相对应的服务。其它组件和 Keystone 的交互也是如此。 在 Keystone V3 之前，用户的权限管理以每一个用户为单位，需要对每一个用户进行角色分配，并不存在一种对一组用户进行统一管理的方案，这给系统管理员带来了额外的工作和不便。此外，Keystone V3 之前的版本中，资源分配是以 Tenant 为单位的，这不太符合现实世界中的层级关系。如一个公司在 Openstack 中拥有两个不同的项目，他需要管理两个 Tenant 来分别对应这两个项目，并对这两个 Tenant 中的用户分别分配角色。 keystone v3为了更加符合现实世界和云服务的映射，将 Tenant 改为 Project 并在其上添加 Domain 的概念 graph TD A[Tenant] --&gt;|改为| B(Project) B --&gt; C(Domain) B --&gt; D(Group) graph LR; A—&gt;B; A—&gt;C; B—&gt;D; C—&gt;D; V3 利用 Domain 实现真正的多租户（multi-tenancy）架构，Domain 担任 Project 的高层容器。云服务的客户是 Domain 的所有者，他们可以在自己的 Domain 中创建多个 Projects、Users、Groups 和 Roles。通过引入 Domain，云服务客户可以对其拥有的多个 Project 进行统一管理，而不必再向过去那样对每一个 Project 进行单独管理。 域(Domain):比Project更高级的容器，云服务客服是Domain的拥有者，一个Domain可以创建多Project、Users、Groups和Roles。通过Domain对所拥有的多个Project统一管理，不必对每个Project单独管理。 组(Group):是一组User容器,通过给Group分配角色，在用一组的用户就有Group所有角色的权限 keystone v3 各组件关系 UUID FRENET]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>云平台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sql基础教程1]]></title>
    <url>%2F2017%2F11%2F09%2Fsql%2Fsql_1%2F</url>
    <content type="text"><![CDATA[针对常用命令直接实践掌握 一、基础命令1.启动登录12service mysqld start //启动mysqlmysql -u root -p password //登陆root password 2.建立新用户(grant命令)格式：grant all privileges on 数据库.* to 用户名@登录主机 identified by “密码”； 12grant all privileges on shopex.* to test@localhost identified by "1234"; 增加一个用户test密码为”1234”,让他只可以在localhost上登录，并可以对数据库Shopex进行所有的操作（localhost指本地主机，即MYSQL数据库所在的那台主机） 3.操作数据库1234567891011121314create database student_management;//创建数据库show databases;use student_management;show table;create table student_info(stu_id int,name varchar(8),sex varchar(4),class varchar(16));//创建student_info表create table teacher_info(tea_id int primary key,name varchar(8),sex varchar(4) check(sex=’男’ or sex=’女’),join_time date,nationality varchar(8) default ’汉族’)//主键、约束、默认值desc student_info;//查看表结构 二、对表数据操作1.增删改12345678insert into student_info values(20080201,’张帅’,’男’,’计算机软件’);//增加一行数据update student_info set class=’计算机软件’ where name=’王青’;//修改一行数据delete from student_info where name=’张玲’;//删除一行数据 2.查询1234567891011select * from student_info order by stu_id;//order by子句：按顺序排序select stu_id,class from student_info where name=’李飞’;//where子句：过滤记录select count(*) from student_info;//count()函数：计数select name from student_info where name like '张%';//like操作符:模式（模糊）匹配,"%"符号用于在模式的前后定义通配符（缺省字母） 三、对表结构操作1234567891011121314151617181920alter table student_info add tel_num int(11);//添加字段alter table student_info change name stu_name varchar(8);//修改字段名称alter table student_info modify stu_id int primary key;//修改字段属性alter tavle student_info modify tel_num int(22);//同上alter table student_info drop column tel_num;//删除字段drop table course_info;//删除表drop database student_management;//删除数据库]]></content>
      <categories>
        <category>sql</category>
      </categories>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数学公式]]></title>
    <url>%2F2017%2F11%2F08%2Fmath%2F%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Latex编辑方式 1.$\log_2 10$ \log_2 10 2.$\sin x$ \sin x 3.$\frac{7x+5}{1+y^2}$ \frac{7x+5}{1+y^2} 4.$s=\sum_1^n{n_i}$ s=\sum_1^n{n_i} 5.$\int_{1}^{a}$ \int_{1}^{a} 6.$\infty$ \infty 7.$\sqrt[x+1]{x^2}$ \sqrt[x+1]{x^2} hexo配置方法a.直接在主题中的配置mathjax，把flase改为ture即可b.不用像网上说的那样安装math，更换渲染引擎，复杂且各种bug，归其原因：引擎和math包是安装在hexo下，但是hexo主题next已集成了math和引擎（就像两个配置文件，两个node.modules）,hexo安装的包理论上没什么用，除非不用next自带的,其他主题也是一样的道理。]]></content>
      <categories>
        <category>高数基础</category>
      </categories>
      <tags>
        <tag>公式</tag>
        <tag>高数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sql_2]]></title>
    <url>%2F2017%2F11%2F07%2Fsql%2Fsql_2%2F</url>
    <content type="text"><![CDATA[查询_2 1. 聚合函数计算列中的值，返回一个单一的值 SUM() 求总和 MIN() 最小值 MAX() 最大值 AVG() 平均值 count() 返回行数 first() last() 2. join (inner join,left join,right join)12345SELECT Websites.id, Websites.name, access_log.count, access_log.dateFROM WebsitesINNER JOIN access_logON Websites.id=access_log.site_id;//把两张表拼起来查询 3. group by 语句结合聚合函数使用 12345678910SELECT site_id, SUM(access_log.count) AS numsFROM access_log GROUP BY site_id;//按某一字段，聚合其他字段数据后显示新表SELECT Websites.name,COUNT(access_log.aid) AS nums FROM access_logLEFT JOIN WebsitesON access_log.site_id=Websites.idGROUP BY Websites.name;// 4. having 子句1234567891011121314SELECT Websites.name, Websites.url, SUM(access_log.count) AS nums FROM (access_logINNER JOIN WebsitesON access_log.site_id=Websites.id)GROUP BY Websites.nameHAVING SUM(access_log.count) &gt; 200;//having的作用在于对group by后的数据进行筛选，类似where，而where不能用聚合函数 SELECT Websites.name, SUM(access_log.count) AS nums FROM WebsitesINNER JOIN access_logON Websites.id=access_log.site_idWHERE Websites.alexa &lt; 200 GROUP BY Websites.nameHAVING SUM(access_log.count) &gt; 200;]]></content>
      <categories>
        <category>sql</category>
      </categories>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于大学城 和 青春]]></title>
    <url>%2F2017%2F10%2F01%2F%E6%97%A5%E8%AE%B0%2F%E5%A4%A7%E5%AD%A6%E5%9F%8E%E4%B8%8E%E9%9D%92%E6%98%A5%2F</url>
    <content type="text"><![CDATA[关于大学城 和 青春 诗 &nbsp; 和 &nbsp; 远方 &emsp;&emsp;到重庆大学城不知不觉已经半年。说起大学城，基本每个城市都一样，隔一到两条街就是一个学校，是个有着无数且只有学校的地方。聊以慰藉的，是校里校外宽敞的公路，优美的绿化，还有一两个热闹的商街。。&emsp;&emsp;当然，更多的是大面积未开发的区域，类似高速公路的环山的风景，还有一望无际类似田野的乡村，于是“城乡结合部”，“村里”这些描述偏僻的词语。&emsp;&emsp;再后来，对大学城空旷和荒凉有了更明确的看法。城市要发展，也注定是一个缓慢的过程。&emsp;&emsp;一代又一代的年轻人，大学不过就是人生的一段路，人生的起点。当我们站在大学城一望无际的土地上，是否会有对未来的憧憬而有点激情澎湃呢。&emsp;&emsp;诚然，变革和发展必然伴随痛苦，在此为之无悔地奋斗，奉献青春，我觉得，是幸运地。脚下的土地，月光下天边的星空，会因我们的努力而改变。我们未来的时光，艰苦漫长，但不再迷茫。&emsp;&emsp;这片土地伴随着你，无论好与坏，相聚离愁。&emsp;&emsp;不如在这片土地，这段时光，不畏惧，不退缩，尽全力，做想做的事，做该做的梦。&emsp;&emsp;终有一天，当你离开大学城时， 我想这就是对青春最好的注脚。]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[about Markdown]]></title>
    <url>%2F2017%2F10%2F01%2F%E5%85%B6%E4%BB%96%2Fabout%20markdown%2F</url>
    <content type="text"><![CDATA[Markdown 语法和 MWeb 写作使用说明Markdown 的设计哲学 Markdown 的目標是實現「易讀易寫」。不過最需要強調的便是它的可讀性。一份使用 Markdown 格式撰寫的文件應該可以直接以純文字發佈，並且看起來不會像是由許多標籤或是格式指令所構成。Markdown 的語法有個主要的目的：用來作為一種網路內容的寫作用語言。 本文约定如果有写 效果如下：， 在 MWeb 编辑状态下只有用 CMD + 4 或 CMD + R 预览才可以看效果。 标题Markdown 语法： 123# 第一级标题 `&lt;h1&gt;` ## 第二级标题 `&lt;h2&gt;` ###### 第六级标题 `&lt;h6&gt;` 效果如下： 第一级标题 &lt;h1&gt;第二级标题 &lt;h2&gt;第六级标题 &lt;h6&gt;强调Markdown 语法： 12345*这些文字会生成`&lt;em&gt;`*_这些文字会生成`&lt;u&gt;`_**这些文字会生成`&lt;strong&gt;`**__这些文字会生成`&lt;strong&gt;`__ 在 MWeb 中的快捷键为： CMD + U、CMD + I、CMD + B效果如下： 这些文字会生成&lt;em&gt;这些文字会生成&lt;u&gt; 这些文字会生成&lt;strong&gt;这些文字会生成&lt;strong&gt; 换行四个及以上空格加回车。如果不想打这么多空格，只要回车就为换行，请勾选：Preferences - Themes - Translate newlines to &lt;br&gt; tags 列表无序列表Markdown 语法： 1234* 项目一 无序列表 `* + 空格键`* 项目二* 项目二的子项目一 无序列表 `TAB + * + 空格键`* 项目二的子项目二 在 MWeb 中的快捷键为： Option + U效果如下： 项目一 无序列表 * + 空格键 项目二 项目二的子项目一 无序列表 TAB + * + 空格键 项目二的子项目二 有序列表Markdown 语法： 123451. 项目一 有序列表 `数字 + . + 空格键`2. 项目二 3. 项目三1. 项目三的子项目一 有序列表 `TAB + 数字 + . + 空格键`2. 项目三的子项目二 效果如下： 项目一 有序列表 数字 + . + 空格键 项目二 项目三 项目三的子项目一 有序列表 TAB + 数字 + . + 空格键 项目三的子项目二 任务列表（Task lists）Markdown 语法： 12- [ ] 任务一 未做任务 `- + 空格 + [ ]`- [x] 任务二 已做任务 `- + 空格 + [x]` 效果如下： [ ] 任务一 未做任务 - + 空格 + [ ] [x] 任务二 已做任务 - + 空格 + [x] 图片Markdown 语法： 12![GitHub set up](http://zh.mweb.im/asset/img/set-up-git.gif)格式: ![Alt Text](url) Control + Shift + I 可插入Markdown语法。如果是 MWeb 的文档库中的文档，还可以用拖放图片、CMD + V 粘贴、CMD + Option + I 导入这三种方式来增加图片。效果如下： MWeb 引入的特别的语法来设置图片宽度，方法是在图片描述后加 -w + 图片宽度 即可，比如说要设置上面的图片的宽度为 140，语法如下： 链接Markdown 语法： 123email &lt;example@example.com&gt;[GitHub](http://github.com)自动生成连接 &lt;http://www.github.com/&gt; Control + Shift + L 可插入Markdown语法。如果是 MWeb 的文档库中的文档，拖放或CMD + Option + I 导入非图片时，会生成连接。效果如下： Email 连接： &#x65;&#120;&#97;&#x6d;&#112;&#108;&#x65;&#x40;&#x65;&#120;&#x61;&#109;&#112;&#x6c;&#101;&#46;&#x63;&#x6f;&#x6d;连接标题Github网站自动生成连接像： http://www.github.com/ 这样 区块引用Markdown 语法： 123某某说:&gt; 第一行引用&gt; 第二行费用文字 CMD + Shift + B 可插入Markdown语法。效果如下： 某某说: 第一行引用第二行费用文字 行内代码Markdown 语法： 1像这样即可：`&lt;addr&gt;` `code` CMD + K 可插入Markdown语法。效果如下： 像这样即可：&lt;addr&gt; code 多行或者一段代码Markdown 语法： 123456function fancyAlert(arg) &#123; if(arg) &#123; $.facebox(&#123;div:'#foo'&#125;) &#125;&#125; CMD + Shift + K 可插入Markdown语法。效果如下： 123456function fancyAlert(arg) &#123; if(arg) &#123; $.facebox(&#123;div:'#foo'&#125;) &#125;&#125; 顺序图或流程图Markdown 语法： 123张三-&gt;李四: 嘿，小四儿, 写博客了没?Note right of 李四: 李四愣了一下，说：李四--&gt;张三: 忙得吐血，哪有时间写。 &lt;div id=&quot;flowchart-0&quot; class=&quot;flow-chart&quot;&gt;&lt;/div&gt; 效果如下（ Preferences - Themes - Enable sequence &amp; flow chart 才会看到效果 ）： 123张三-&gt;李四: 嘿，小四儿, 写博客了没?Note right of 李四: 李四愣了一下，说：李四--&gt;张三: 忙得吐血，哪有时间写。 更多请参考：http://bramp.github.io/js-sequence-diagrams/, http://adrai.github.io/flowchart.js/ 表格Markdown 语法： 1234第一格表头 | 第二格表头--------- | -------------内容单元格 第一列第一格 | 内容单元格第二列第一格内容单元格 第一列第二格 多加文字 | 内容单元格第二列第二格 效果如下： 第一格表头 第二格表头 内容单元格 第一列第一格 内容单元格第二列第一格 内容单元格 第一列第二格 多加文字 内容单元格第二列第二格 删除线Markdown 语法： 加删除线像这样用： 删除这些 效果如下： 加删除线像这样用： 删除这些 分隔线以下三种方式都可以生成分隔线： 效果如下： MathJaxMarkdown 语法： 12345678块级公式：$$ x = \dfrac&#123;-b \pm \sqrt&#123;b^2 - 4ac&#125;&#125;&#123;2a&#125; $$\\[ \frac&#123;1&#125;&#123;\Bigl(\sqrt&#123;\phi \sqrt&#123;5&#125;&#125;-\phi\Bigr) e^&#123;\frac25 \pi&#125;&#125; =1+\frac&#123;e^&#123;-2\pi&#125;&#125; &#123;1+\frac&#123;e^&#123;-4\pi&#125;&#125; &#123;1+\frac&#123;e^&#123;-6\pi&#125;&#125;&#123;1+\frac&#123;e^&#123;-8\pi&#125;&#125; &#123;1+\ldots&#125; &#125; &#125; &#125; \\]行内公式： $\Gamma(n) = (n-1)!\quad\forall n\in\mathbb N$ 效果如下（Preferences - Themes - Enable MathJax 才会看到效果）： 块级公式： x = \dfrac{-b \pm \sqrt{b^2 - 4ac}}{2a}\[ \frac{1}{\Bigl(\sqrt{\phi \sqrt{5}}-\phi\Bigr) e^{\frac25 \pi}} =1+\frac{e^{-2\pi}} {1+\frac{e^{-4\pi}} {1+\frac{e^{-6\pi}}{1+\frac{e^{-8\pi}} {1+\ldots} } } } \] 行内公式： $\Gamma(n) = (n-1)!\quad\forall n\in\mathbb N$ 脚注（Footnote）Markdown 语法： 1这是一个脚注：[^sample_footnote] 效果如下： 这是一个脚注：sample_footnote sample_footnote. 这里是脚注信息 &#8617; 注释和阅读更多 Actions-&gt;Insert Read More Comment 或者 Command + .注 阅读更多的功能只用在生成网站或博客时，插入时注意要后空一行。 TOCMarkdown 语法： 1[TOC] 效果如下： [TOC] st=>start: 开始 e=>end: 结束 op=>operation: 我的操作 cond=>condition: 确认？ st->op->cond cond(yes)->e cond(no)->op{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);st=>start: 开始 e=>end: 结束 op=>operation: 我的操作 cond=>condition: 确认？ st->op->cond cond(yes)->e cond(no)->op{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-1-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-1", options);]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F10%2F01%2F%E5%85%B6%E4%BB%96%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment othersBase (top) 佐天泪子 (xiān qún kuáng mó) 超電磁砲 (レールガン) flow 公式块级公式： x = \dfrac{-b \pm \sqrt{b^2 - 4ac}}{2a}\[ \frac{1}{\Bigl(\sqrt{\phi \sqrt{5}}-\phi\Bigr) e^{\frac25 \pi}} =1+\frac{e^{-2\pi}} {1+\frac{e^{-4\pi}} {1+\frac{e^{-6\pi}}{1+\frac{e^{-8\pi}} {1+\ldots} } } } \] 头部要有mathjax: true 行内公式： $\Gamma(n) = (n-1)!\quad\forall n\in\mathbb N$ sequence123张三-&gt;李四: 嘿，小四儿, 写博客了没?Note right of 李四: 李四愣了一下，说：李四--&gt;张三: 忙得吐血，哪有时间写。 st=>start: 开始 e=>end: 结束 op=>operation: 我的操作 cond=>condition: 确认？ st->op->cond cond(yes)->e cond(no)->op{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <tags>
        <tag>MD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有生以来第一次被如此期待]]></title>
    <url>%2F2011%2F03%2F27%2F%E6%97%A5%E8%AE%B0%2F%E7%81%8C%E7%AF%AE%E9%AB%98%E6%89%8B%E8%AF%BB%E5%90%8E%E6%84%9F%2F</url>
    <content type="text"><![CDATA[有生以来第一次被如此期待评灌篮高手 SLAM DUNK完全版————《why walk when you can fly》 &emsp;&emsp;又一次重温经典，又一次的感动。。 &emsp;&emsp;我可以感觉到血液的沸腾。。 &emsp;&emsp;&emsp;&emsp;我的思绪回到了小学。。。 &emsp;&emsp;记得第一次看灌篮高手时，我尽然分错了主角，把仙道当成了主角，不过那时还是很欣赏樱木、流川枫，他们都很有天分。可是就不明白为什么他们非要互相敌对，后来明白的时候，真期待他们的联手，相信他们的联手绝对是一个黄金搭档，就像乔丹和皮蓬一样。 &emsp;&emsp;后来迷上了灌篮高手，当然也就分清主角了。每日都要守在电视机旁观看，我好像进入了电视中，和他们活在了一起，我迷失在现实世界中，而到了他们的世界。 &emsp;&emsp;我把周围的一切、同学、朋友 都按照他们的外貌、性格和感觉分成动画中的角色。 &emsp;&emsp;也因为灌篮高手，我打了几年篮球， &emsp;&emsp;小学生的篮球可能就是随便玩玩，没什么技术含量。 &emsp;&emsp;但是我很怀念那段时间，我们十几个同学周末的时候一起去打篮球的场景， &emsp;&emsp;那时候，灌篮高手很火，甚至我们的班主任女老师 也非常喜欢看灌篮高手。 我们同学打篮球的时候，也会把自己当成 动画中的角色。 当然多数都是自称 天才，樱木或者流川枫， 我在篮球场的时候，真的把自己当成了他们。 我幻想着自己有一天会成为世界篮球界的焦点，说不定我真是一个篮球天才呢。 就像我现在一样，当我看越狱的那段时间，我多数时间是把自己想象成 迈克尔-斯科菲尔德，我的外貌变成了他的，我想象自己用他的眼睛来看待这个世界。 时间流逝、几年没动过篮球，这个梦也深深的埋在了我的心里的一个角落。我有点害怕去寻找他，我不敢正视这个梦想。 就像我以前提到过，我们看电影、动画、小说，多数是为了满足我们潜意识的需要。现实中做不到，就在这些地方寻求。 正因如此，我更加迷恋灌篮高手了， 我不知道，他们是因果关系，还是相等关系。 每当我感到空虚失落的时候，就想重温一下《灌篮高手》 被如此期待……是有生以来……第一次。。 这是我们的天才选手—樱木花道 在全国大赛中对决 山王时，被安西教练委以重任时说的一句话（你是我们反败为胜的王牌！） 短短的几分钟，太多的经典镜头， 记得，樱木开始打篮球，并不是喜欢篮球运动，相反他还很讨厌篮球，也正因为讨厌，才和队长赤木有了一场精彩对决（哈哈，我想到了 赤木裤子被扒下的场景） 但是，在对决山王的时候，樱木为了抢下一个要落入边界的球，飞身跳过去，身体砸在了桌子上， 可是为这一球，差点断送了 樱木的 篮球生涯。 樱木感觉到了背部的疼痛， 樱木陷入了回想，他的第一次比赛，和赤木的对决、两万球特训，这些场景在樱木的脑海里回荡。 樱木站起来了，来到了晴子的身旁，说出了他对篮球的喜爱 “我非常喜欢，这次不是说谎” 故事结尾，也成全了我们大多数人的心愿，看到了 樱木 和 流川枫的 联手。 因为他们的联手最后才赢得胜利，完美绝杀山王。比分79-78 黄金搭档诞生的时刻。 故事结束了，我抑制不了我的情绪，写下此文….]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
</search>
